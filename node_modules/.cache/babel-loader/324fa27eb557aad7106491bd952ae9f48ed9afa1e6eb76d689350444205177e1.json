{"ast":null,"code":"import { __assign } from \"tslib\";\nimport { SENSITIVE_STRING, isa as __isa } from \"@aws-sdk/smithy-client\";\nexport var BufferingHints;\n(function (BufferingHints) {\n  BufferingHints.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  BufferingHints.isa = function (o) {\n    return __isa(o, \"BufferingHints\");\n  };\n})(BufferingHints || (BufferingHints = {}));\nexport var CloudWatchLoggingOptions;\n(function (CloudWatchLoggingOptions) {\n  CloudWatchLoggingOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  CloudWatchLoggingOptions.isa = function (o) {\n    return __isa(o, \"CloudWatchLoggingOptions\");\n  };\n})(CloudWatchLoggingOptions || (CloudWatchLoggingOptions = {}));\nexport var CompressionFormat;\n(function (CompressionFormat) {\n  CompressionFormat[\"GZIP\"] = \"GZIP\";\n  CompressionFormat[\"HADOOP_SNAPPY\"] = \"HADOOP_SNAPPY\";\n  CompressionFormat[\"SNAPPY\"] = \"Snappy\";\n  CompressionFormat[\"UNCOMPRESSED\"] = \"UNCOMPRESSED\";\n  CompressionFormat[\"ZIP\"] = \"ZIP\";\n})(CompressionFormat || (CompressionFormat = {}));\nexport var ConcurrentModificationException;\n(function (ConcurrentModificationException) {\n  ConcurrentModificationException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ConcurrentModificationException.isa = function (o) {\n    return __isa(o, \"ConcurrentModificationException\");\n  };\n})(ConcurrentModificationException || (ConcurrentModificationException = {}));\nexport var ContentEncoding;\n(function (ContentEncoding) {\n  ContentEncoding[\"GZIP\"] = \"GZIP\";\n  ContentEncoding[\"NONE\"] = \"NONE\";\n})(ContentEncoding || (ContentEncoding = {}));\nexport var CopyCommand;\n(function (CopyCommand) {\n  CopyCommand.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  CopyCommand.isa = function (o) {\n    return __isa(o, \"CopyCommand\");\n  };\n})(CopyCommand || (CopyCommand = {}));\nexport var CreateDeliveryStreamInput;\n(function (CreateDeliveryStreamInput) {\n  CreateDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.RedshiftDestinationConfiguration && {\n      RedshiftDestinationConfiguration: RedshiftDestinationConfiguration.filterSensitiveLog(obj.RedshiftDestinationConfiguration)\n    }), obj.HttpEndpointDestinationConfiguration && {\n      HttpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration.filterSensitiveLog(obj.HttpEndpointDestinationConfiguration)\n    });\n  };\n  CreateDeliveryStreamInput.isa = function (o) {\n    return __isa(o, \"CreateDeliveryStreamInput\");\n  };\n})(CreateDeliveryStreamInput || (CreateDeliveryStreamInput = {}));\nexport var CreateDeliveryStreamOutput;\n(function (CreateDeliveryStreamOutput) {\n  CreateDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  CreateDeliveryStreamOutput.isa = function (o) {\n    return __isa(o, \"CreateDeliveryStreamOutput\");\n  };\n})(CreateDeliveryStreamOutput || (CreateDeliveryStreamOutput = {}));\nexport var DataFormatConversionConfiguration;\n(function (DataFormatConversionConfiguration) {\n  DataFormatConversionConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  DataFormatConversionConfiguration.isa = function (o) {\n    return __isa(o, \"DataFormatConversionConfiguration\");\n  };\n})(DataFormatConversionConfiguration || (DataFormatConversionConfiguration = {}));\nexport var DeleteDeliveryStreamInput;\n(function (DeleteDeliveryStreamInput) {\n  DeleteDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  DeleteDeliveryStreamInput.isa = function (o) {\n    return __isa(o, \"DeleteDeliveryStreamInput\");\n  };\n})(DeleteDeliveryStreamInput || (DeleteDeliveryStreamInput = {}));\nexport var DeleteDeliveryStreamOutput;\n(function (DeleteDeliveryStreamOutput) {\n  DeleteDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  DeleteDeliveryStreamOutput.isa = function (o) {\n    return __isa(o, \"DeleteDeliveryStreamOutput\");\n  };\n})(DeleteDeliveryStreamOutput || (DeleteDeliveryStreamOutput = {}));\nexport var DeliveryStreamDescription;\n(function (DeliveryStreamDescription) {\n  DeliveryStreamDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.Destinations && {\n      Destinations: obj.Destinations.map(function (item) {\n        return DestinationDescription.filterSensitiveLog(item);\n      })\n    });\n  };\n  DeliveryStreamDescription.isa = function (o) {\n    return __isa(o, \"DeliveryStreamDescription\");\n  };\n})(DeliveryStreamDescription || (DeliveryStreamDescription = {}));\nexport var DeliveryStreamEncryptionConfiguration;\n(function (DeliveryStreamEncryptionConfiguration) {\n  DeliveryStreamEncryptionConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  DeliveryStreamEncryptionConfiguration.isa = function (o) {\n    return __isa(o, \"DeliveryStreamEncryptionConfiguration\");\n  };\n})(DeliveryStreamEncryptionConfiguration || (DeliveryStreamEncryptionConfiguration = {}));\nexport var DeliveryStreamEncryptionConfigurationInput;\n(function (DeliveryStreamEncryptionConfigurationInput) {\n  DeliveryStreamEncryptionConfigurationInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  DeliveryStreamEncryptionConfigurationInput.isa = function (o) {\n    return __isa(o, \"DeliveryStreamEncryptionConfigurationInput\");\n  };\n})(DeliveryStreamEncryptionConfigurationInput || (DeliveryStreamEncryptionConfigurationInput = {}));\nexport var DeliveryStreamEncryptionStatus;\n(function (DeliveryStreamEncryptionStatus) {\n  DeliveryStreamEncryptionStatus[\"DISABLED\"] = \"DISABLED\";\n  DeliveryStreamEncryptionStatus[\"DISABLING\"] = \"DISABLING\";\n  DeliveryStreamEncryptionStatus[\"DISABLING_FAILED\"] = \"DISABLING_FAILED\";\n  DeliveryStreamEncryptionStatus[\"ENABLED\"] = \"ENABLED\";\n  DeliveryStreamEncryptionStatus[\"ENABLING\"] = \"ENABLING\";\n  DeliveryStreamEncryptionStatus[\"ENABLING_FAILED\"] = \"ENABLING_FAILED\";\n})(DeliveryStreamEncryptionStatus || (DeliveryStreamEncryptionStatus = {}));\nexport var DeliveryStreamFailureType;\n(function (DeliveryStreamFailureType) {\n  DeliveryStreamFailureType[\"CREATE_ENI_FAILED\"] = \"CREATE_ENI_FAILED\";\n  DeliveryStreamFailureType[\"CREATE_KMS_GRANT_FAILED\"] = \"CREATE_KMS_GRANT_FAILED\";\n  DeliveryStreamFailureType[\"DELETE_ENI_FAILED\"] = \"DELETE_ENI_FAILED\";\n  DeliveryStreamFailureType[\"DISABLED_KMS_KEY\"] = \"DISABLED_KMS_KEY\";\n  DeliveryStreamFailureType[\"ENI_ACCESS_DENIED\"] = \"ENI_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"INVALID_KMS_KEY\"] = \"INVALID_KMS_KEY\";\n  DeliveryStreamFailureType[\"KMS_ACCESS_DENIED\"] = \"KMS_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"KMS_KEY_NOT_FOUND\"] = \"KMS_KEY_NOT_FOUND\";\n  DeliveryStreamFailureType[\"KMS_OPT_IN_REQUIRED\"] = \"KMS_OPT_IN_REQUIRED\";\n  DeliveryStreamFailureType[\"RETIRE_KMS_GRANT_FAILED\"] = \"RETIRE_KMS_GRANT_FAILED\";\n  DeliveryStreamFailureType[\"SECURITY_GROUP_ACCESS_DENIED\"] = \"SECURITY_GROUP_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"SECURITY_GROUP_NOT_FOUND\"] = \"SECURITY_GROUP_NOT_FOUND\";\n  DeliveryStreamFailureType[\"SUBNET_ACCESS_DENIED\"] = \"SUBNET_ACCESS_DENIED\";\n  DeliveryStreamFailureType[\"SUBNET_NOT_FOUND\"] = \"SUBNET_NOT_FOUND\";\n  DeliveryStreamFailureType[\"UNKNOWN_ERROR\"] = \"UNKNOWN_ERROR\";\n})(DeliveryStreamFailureType || (DeliveryStreamFailureType = {}));\nexport var DeliveryStreamStatus;\n(function (DeliveryStreamStatus) {\n  DeliveryStreamStatus[\"ACTIVE\"] = \"ACTIVE\";\n  DeliveryStreamStatus[\"CREATING\"] = \"CREATING\";\n  DeliveryStreamStatus[\"CREATING_FAILED\"] = \"CREATING_FAILED\";\n  DeliveryStreamStatus[\"DELETING\"] = \"DELETING\";\n  DeliveryStreamStatus[\"DELETING_FAILED\"] = \"DELETING_FAILED\";\n})(DeliveryStreamStatus || (DeliveryStreamStatus = {}));\nexport var DescribeDeliveryStreamInput;\n(function (DescribeDeliveryStreamInput) {\n  DescribeDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  DescribeDeliveryStreamInput.isa = function (o) {\n    return __isa(o, \"DescribeDeliveryStreamInput\");\n  };\n})(DescribeDeliveryStreamInput || (DescribeDeliveryStreamInput = {}));\nexport var DescribeDeliveryStreamOutput;\n(function (DescribeDeliveryStreamOutput) {\n  DescribeDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.DeliveryStreamDescription && {\n      DeliveryStreamDescription: DeliveryStreamDescription.filterSensitiveLog(obj.DeliveryStreamDescription)\n    });\n  };\n  DescribeDeliveryStreamOutput.isa = function (o) {\n    return __isa(o, \"DescribeDeliveryStreamOutput\");\n  };\n})(DescribeDeliveryStreamOutput || (DescribeDeliveryStreamOutput = {}));\nexport var Deserializer;\n(function (Deserializer) {\n  Deserializer.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  Deserializer.isa = function (o) {\n    return __isa(o, \"Deserializer\");\n  };\n})(Deserializer || (Deserializer = {}));\nexport var DestinationDescription;\n(function (DestinationDescription) {\n  DestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.RedshiftDestinationDescription && {\n      RedshiftDestinationDescription: RedshiftDestinationDescription.filterSensitiveLog(obj.RedshiftDestinationDescription)\n    }), obj.HttpEndpointDestinationDescription && {\n      HttpEndpointDestinationDescription: HttpEndpointDestinationDescription.filterSensitiveLog(obj.HttpEndpointDestinationDescription)\n    });\n  };\n  DestinationDescription.isa = function (o) {\n    return __isa(o, \"DestinationDescription\");\n  };\n})(DestinationDescription || (DestinationDescription = {}));\nexport var ElasticsearchBufferingHints;\n(function (ElasticsearchBufferingHints) {\n  ElasticsearchBufferingHints.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ElasticsearchBufferingHints.isa = function (o) {\n    return __isa(o, \"ElasticsearchBufferingHints\");\n  };\n})(ElasticsearchBufferingHints || (ElasticsearchBufferingHints = {}));\nexport var ElasticsearchDestinationConfiguration;\n(function (ElasticsearchDestinationConfiguration) {\n  ElasticsearchDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ElasticsearchDestinationConfiguration.isa = function (o) {\n    return __isa(o, \"ElasticsearchDestinationConfiguration\");\n  };\n})(ElasticsearchDestinationConfiguration || (ElasticsearchDestinationConfiguration = {}));\nexport var ElasticsearchDestinationDescription;\n(function (ElasticsearchDestinationDescription) {\n  ElasticsearchDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ElasticsearchDestinationDescription.isa = function (o) {\n    return __isa(o, \"ElasticsearchDestinationDescription\");\n  };\n})(ElasticsearchDestinationDescription || (ElasticsearchDestinationDescription = {}));\nexport var ElasticsearchDestinationUpdate;\n(function (ElasticsearchDestinationUpdate) {\n  ElasticsearchDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ElasticsearchDestinationUpdate.isa = function (o) {\n    return __isa(o, \"ElasticsearchDestinationUpdate\");\n  };\n})(ElasticsearchDestinationUpdate || (ElasticsearchDestinationUpdate = {}));\nexport var ElasticsearchRetryOptions;\n(function (ElasticsearchRetryOptions) {\n  ElasticsearchRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ElasticsearchRetryOptions.isa = function (o) {\n    return __isa(o, \"ElasticsearchRetryOptions\");\n  };\n})(ElasticsearchRetryOptions || (ElasticsearchRetryOptions = {}));\nexport var EncryptionConfiguration;\n(function (EncryptionConfiguration) {\n  EncryptionConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  EncryptionConfiguration.isa = function (o) {\n    return __isa(o, \"EncryptionConfiguration\");\n  };\n})(EncryptionConfiguration || (EncryptionConfiguration = {}));\nexport var ExtendedS3DestinationConfiguration;\n(function (ExtendedS3DestinationConfiguration) {\n  ExtendedS3DestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ExtendedS3DestinationConfiguration.isa = function (o) {\n    return __isa(o, \"ExtendedS3DestinationConfiguration\");\n  };\n})(ExtendedS3DestinationConfiguration || (ExtendedS3DestinationConfiguration = {}));\nexport var ExtendedS3DestinationDescription;\n(function (ExtendedS3DestinationDescription) {\n  ExtendedS3DestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ExtendedS3DestinationDescription.isa = function (o) {\n    return __isa(o, \"ExtendedS3DestinationDescription\");\n  };\n})(ExtendedS3DestinationDescription || (ExtendedS3DestinationDescription = {}));\nexport var ExtendedS3DestinationUpdate;\n(function (ExtendedS3DestinationUpdate) {\n  ExtendedS3DestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ExtendedS3DestinationUpdate.isa = function (o) {\n    return __isa(o, \"ExtendedS3DestinationUpdate\");\n  };\n})(ExtendedS3DestinationUpdate || (ExtendedS3DestinationUpdate = {}));\nexport var FailureDescription;\n(function (FailureDescription) {\n  FailureDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  FailureDescription.isa = function (o) {\n    return __isa(o, \"FailureDescription\");\n  };\n})(FailureDescription || (FailureDescription = {}));\nexport var HiveJsonSerDe;\n(function (HiveJsonSerDe) {\n  HiveJsonSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  HiveJsonSerDe.isa = function (o) {\n    return __isa(o, \"HiveJsonSerDe\");\n  };\n})(HiveJsonSerDe || (HiveJsonSerDe = {}));\nexport var HttpEndpointBufferingHints;\n(function (HttpEndpointBufferingHints) {\n  HttpEndpointBufferingHints.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  HttpEndpointBufferingHints.isa = function (o) {\n    return __isa(o, \"HttpEndpointBufferingHints\");\n  };\n})(HttpEndpointBufferingHints || (HttpEndpointBufferingHints = {}));\nexport var HttpEndpointCommonAttribute;\n(function (HttpEndpointCommonAttribute) {\n  HttpEndpointCommonAttribute.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.AttributeName && {\n      AttributeName: SENSITIVE_STRING\n    }), obj.AttributeValue && {\n      AttributeValue: SENSITIVE_STRING\n    });\n  };\n  HttpEndpointCommonAttribute.isa = function (o) {\n    return __isa(o, \"HttpEndpointCommonAttribute\");\n  };\n})(HttpEndpointCommonAttribute || (HttpEndpointCommonAttribute = {}));\nexport var HttpEndpointConfiguration;\n(function (HttpEndpointConfiguration) {\n  HttpEndpointConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.AccessKey && {\n      AccessKey: SENSITIVE_STRING\n    }), obj.Url && {\n      Url: SENSITIVE_STRING\n    });\n  };\n  HttpEndpointConfiguration.isa = function (o) {\n    return __isa(o, \"HttpEndpointConfiguration\");\n  };\n})(HttpEndpointConfiguration || (HttpEndpointConfiguration = {}));\nexport var HttpEndpointDescription;\n(function (HttpEndpointDescription) {\n  HttpEndpointDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.Url && {\n      Url: SENSITIVE_STRING\n    });\n  };\n  HttpEndpointDescription.isa = function (o) {\n    return __isa(o, \"HttpEndpointDescription\");\n  };\n})(HttpEndpointDescription || (HttpEndpointDescription = {}));\nexport var HttpEndpointDestinationConfiguration;\n(function (HttpEndpointDestinationConfiguration) {\n  HttpEndpointDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration)\n    }), obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration)\n    });\n  };\n  HttpEndpointDestinationConfiguration.isa = function (o) {\n    return __isa(o, \"HttpEndpointDestinationConfiguration\");\n  };\n})(HttpEndpointDestinationConfiguration || (HttpEndpointDestinationConfiguration = {}));\nexport var HttpEndpointDestinationDescription;\n(function (HttpEndpointDestinationDescription) {\n  HttpEndpointDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration)\n    }), obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointDescription.filterSensitiveLog(obj.EndpointConfiguration)\n    });\n  };\n  HttpEndpointDestinationDescription.isa = function (o) {\n    return __isa(o, \"HttpEndpointDestinationDescription\");\n  };\n})(HttpEndpointDestinationDescription || (HttpEndpointDestinationDescription = {}));\nexport var HttpEndpointDestinationUpdate;\n(function (HttpEndpointDestinationUpdate) {\n  HttpEndpointDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration)\n    }), obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration)\n    });\n  };\n  HttpEndpointDestinationUpdate.isa = function (o) {\n    return __isa(o, \"HttpEndpointDestinationUpdate\");\n  };\n})(HttpEndpointDestinationUpdate || (HttpEndpointDestinationUpdate = {}));\nexport var HttpEndpointRequestConfiguration;\n(function (HttpEndpointRequestConfiguration) {\n  HttpEndpointRequestConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.CommonAttributes && {\n      CommonAttributes: obj.CommonAttributes.map(function (item) {\n        return HttpEndpointCommonAttribute.filterSensitiveLog(item);\n      })\n    });\n  };\n  HttpEndpointRequestConfiguration.isa = function (o) {\n    return __isa(o, \"HttpEndpointRequestConfiguration\");\n  };\n})(HttpEndpointRequestConfiguration || (HttpEndpointRequestConfiguration = {}));\nexport var HttpEndpointRetryOptions;\n(function (HttpEndpointRetryOptions) {\n  HttpEndpointRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  HttpEndpointRetryOptions.isa = function (o) {\n    return __isa(o, \"HttpEndpointRetryOptions\");\n  };\n})(HttpEndpointRetryOptions || (HttpEndpointRetryOptions = {}));\nexport var InputFormatConfiguration;\n(function (InputFormatConfiguration) {\n  InputFormatConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  InputFormatConfiguration.isa = function (o) {\n    return __isa(o, \"InputFormatConfiguration\");\n  };\n})(InputFormatConfiguration || (InputFormatConfiguration = {}));\nexport var InvalidArgumentException;\n(function (InvalidArgumentException) {\n  InvalidArgumentException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  InvalidArgumentException.isa = function (o) {\n    return __isa(o, \"InvalidArgumentException\");\n  };\n})(InvalidArgumentException || (InvalidArgumentException = {}));\nexport var InvalidKMSResourceException;\n(function (InvalidKMSResourceException) {\n  InvalidKMSResourceException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  InvalidKMSResourceException.isa = function (o) {\n    return __isa(o, \"InvalidKMSResourceException\");\n  };\n})(InvalidKMSResourceException || (InvalidKMSResourceException = {}));\nexport var KeyType;\n(function (KeyType) {\n  KeyType[\"AWS_OWNED_CMK\"] = \"AWS_OWNED_CMK\";\n  KeyType[\"CUSTOMER_MANAGED_CMK\"] = \"CUSTOMER_MANAGED_CMK\";\n})(KeyType || (KeyType = {}));\nexport var KinesisStreamSourceConfiguration;\n(function (KinesisStreamSourceConfiguration) {\n  KinesisStreamSourceConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  KinesisStreamSourceConfiguration.isa = function (o) {\n    return __isa(o, \"KinesisStreamSourceConfiguration\");\n  };\n})(KinesisStreamSourceConfiguration || (KinesisStreamSourceConfiguration = {}));\nexport var KinesisStreamSourceDescription;\n(function (KinesisStreamSourceDescription) {\n  KinesisStreamSourceDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  KinesisStreamSourceDescription.isa = function (o) {\n    return __isa(o, \"KinesisStreamSourceDescription\");\n  };\n})(KinesisStreamSourceDescription || (KinesisStreamSourceDescription = {}));\nexport var KMSEncryptionConfig;\n(function (KMSEncryptionConfig) {\n  KMSEncryptionConfig.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  KMSEncryptionConfig.isa = function (o) {\n    return __isa(o, \"KMSEncryptionConfig\");\n  };\n})(KMSEncryptionConfig || (KMSEncryptionConfig = {}));\nexport var LimitExceededException;\n(function (LimitExceededException) {\n  LimitExceededException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  LimitExceededException.isa = function (o) {\n    return __isa(o, \"LimitExceededException\");\n  };\n})(LimitExceededException || (LimitExceededException = {}));\nexport var ListDeliveryStreamsInput;\n(function (ListDeliveryStreamsInput) {\n  ListDeliveryStreamsInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ListDeliveryStreamsInput.isa = function (o) {\n    return __isa(o, \"ListDeliveryStreamsInput\");\n  };\n})(ListDeliveryStreamsInput || (ListDeliveryStreamsInput = {}));\nexport var ListDeliveryStreamsOutput;\n(function (ListDeliveryStreamsOutput) {\n  ListDeliveryStreamsOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ListDeliveryStreamsOutput.isa = function (o) {\n    return __isa(o, \"ListDeliveryStreamsOutput\");\n  };\n})(ListDeliveryStreamsOutput || (ListDeliveryStreamsOutput = {}));\nexport var ListTagsForDeliveryStreamInput;\n(function (ListTagsForDeliveryStreamInput) {\n  ListTagsForDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ListTagsForDeliveryStreamInput.isa = function (o) {\n    return __isa(o, \"ListTagsForDeliveryStreamInput\");\n  };\n})(ListTagsForDeliveryStreamInput || (ListTagsForDeliveryStreamInput = {}));\nexport var ListTagsForDeliveryStreamOutput;\n(function (ListTagsForDeliveryStreamOutput) {\n  ListTagsForDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ListTagsForDeliveryStreamOutput.isa = function (o) {\n    return __isa(o, \"ListTagsForDeliveryStreamOutput\");\n  };\n})(ListTagsForDeliveryStreamOutput || (ListTagsForDeliveryStreamOutput = {}));\nexport var OpenXJsonSerDe;\n(function (OpenXJsonSerDe) {\n  OpenXJsonSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  OpenXJsonSerDe.isa = function (o) {\n    return __isa(o, \"OpenXJsonSerDe\");\n  };\n})(OpenXJsonSerDe || (OpenXJsonSerDe = {}));\nexport var OrcCompression;\n(function (OrcCompression) {\n  OrcCompression[\"NONE\"] = \"NONE\";\n  OrcCompression[\"SNAPPY\"] = \"SNAPPY\";\n  OrcCompression[\"ZLIB\"] = \"ZLIB\";\n})(OrcCompression || (OrcCompression = {}));\nexport var OrcFormatVersion;\n(function (OrcFormatVersion) {\n  OrcFormatVersion[\"V0_11\"] = \"V0_11\";\n  OrcFormatVersion[\"V0_12\"] = \"V0_12\";\n})(OrcFormatVersion || (OrcFormatVersion = {}));\nexport var OrcSerDe;\n(function (OrcSerDe) {\n  OrcSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  OrcSerDe.isa = function (o) {\n    return __isa(o, \"OrcSerDe\");\n  };\n})(OrcSerDe || (OrcSerDe = {}));\nexport var OutputFormatConfiguration;\n(function (OutputFormatConfiguration) {\n  OutputFormatConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  OutputFormatConfiguration.isa = function (o) {\n    return __isa(o, \"OutputFormatConfiguration\");\n  };\n})(OutputFormatConfiguration || (OutputFormatConfiguration = {}));\nexport var ParquetCompression;\n(function (ParquetCompression) {\n  ParquetCompression[\"GZIP\"] = \"GZIP\";\n  ParquetCompression[\"SNAPPY\"] = \"SNAPPY\";\n  ParquetCompression[\"UNCOMPRESSED\"] = \"UNCOMPRESSED\";\n})(ParquetCompression || (ParquetCompression = {}));\nexport var ParquetSerDe;\n(function (ParquetSerDe) {\n  ParquetSerDe.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ParquetSerDe.isa = function (o) {\n    return __isa(o, \"ParquetSerDe\");\n  };\n})(ParquetSerDe || (ParquetSerDe = {}));\nexport var ParquetWriterVersion;\n(function (ParquetWriterVersion) {\n  ParquetWriterVersion[\"V1\"] = \"V1\";\n  ParquetWriterVersion[\"V2\"] = \"V2\";\n})(ParquetWriterVersion || (ParquetWriterVersion = {}));\nexport var ProcessingConfiguration;\n(function (ProcessingConfiguration) {\n  ProcessingConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ProcessingConfiguration.isa = function (o) {\n    return __isa(o, \"ProcessingConfiguration\");\n  };\n})(ProcessingConfiguration || (ProcessingConfiguration = {}));\nexport var Processor;\n(function (Processor) {\n  Processor.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  Processor.isa = function (o) {\n    return __isa(o, \"Processor\");\n  };\n})(Processor || (Processor = {}));\nexport var ProcessorParameter;\n(function (ProcessorParameter) {\n  ProcessorParameter.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ProcessorParameter.isa = function (o) {\n    return __isa(o, \"ProcessorParameter\");\n  };\n})(ProcessorParameter || (ProcessorParameter = {}));\nexport var ProcessorParameterName;\n(function (ProcessorParameterName) {\n  ProcessorParameterName[\"BUFFER_INTERVAL_IN_SECONDS\"] = \"BufferIntervalInSeconds\";\n  ProcessorParameterName[\"BUFFER_SIZE_IN_MB\"] = \"BufferSizeInMBs\";\n  ProcessorParameterName[\"LAMBDA_ARN\"] = \"LambdaArn\";\n  ProcessorParameterName[\"LAMBDA_NUMBER_OF_RETRIES\"] = \"NumberOfRetries\";\n  ProcessorParameterName[\"ROLE_ARN\"] = \"RoleArn\";\n})(ProcessorParameterName || (ProcessorParameterName = {}));\nexport var PutRecordBatchInput;\n(function (PutRecordBatchInput) {\n  PutRecordBatchInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  PutRecordBatchInput.isa = function (o) {\n    return __isa(o, \"PutRecordBatchInput\");\n  };\n})(PutRecordBatchInput || (PutRecordBatchInput = {}));\nexport var PutRecordBatchOutput;\n(function (PutRecordBatchOutput) {\n  PutRecordBatchOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  PutRecordBatchOutput.isa = function (o) {\n    return __isa(o, \"PutRecordBatchOutput\");\n  };\n})(PutRecordBatchOutput || (PutRecordBatchOutput = {}));\nexport var PutRecordBatchResponseEntry;\n(function (PutRecordBatchResponseEntry) {\n  PutRecordBatchResponseEntry.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  PutRecordBatchResponseEntry.isa = function (o) {\n    return __isa(o, \"PutRecordBatchResponseEntry\");\n  };\n})(PutRecordBatchResponseEntry || (PutRecordBatchResponseEntry = {}));\nexport var PutRecordInput;\n(function (PutRecordInput) {\n  PutRecordInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  PutRecordInput.isa = function (o) {\n    return __isa(o, \"PutRecordInput\");\n  };\n})(PutRecordInput || (PutRecordInput = {}));\nexport var PutRecordOutput;\n(function (PutRecordOutput) {\n  PutRecordOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  PutRecordOutput.isa = function (o) {\n    return __isa(o, \"PutRecordOutput\");\n  };\n})(PutRecordOutput || (PutRecordOutput = {}));\nexport var _Record;\n(function (_Record) {\n  _Record.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  _Record.isa = function (o) {\n    return __isa(o, \"Record\");\n  };\n})(_Record || (_Record = {}));\nexport var RedshiftDestinationConfiguration;\n(function (RedshiftDestinationConfiguration) {\n  RedshiftDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.Username && {\n      Username: SENSITIVE_STRING\n    }), obj.Password && {\n      Password: SENSITIVE_STRING\n    });\n  };\n  RedshiftDestinationConfiguration.isa = function (o) {\n    return __isa(o, \"RedshiftDestinationConfiguration\");\n  };\n})(RedshiftDestinationConfiguration || (RedshiftDestinationConfiguration = {}));\nexport var RedshiftDestinationDescription;\n(function (RedshiftDestinationDescription) {\n  RedshiftDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign(__assign({}, obj), obj.Username && {\n      Username: SENSITIVE_STRING\n    });\n  };\n  RedshiftDestinationDescription.isa = function (o) {\n    return __isa(o, \"RedshiftDestinationDescription\");\n  };\n})(RedshiftDestinationDescription || (RedshiftDestinationDescription = {}));\nexport var RedshiftDestinationUpdate;\n(function (RedshiftDestinationUpdate) {\n  RedshiftDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.Username && {\n      Username: SENSITIVE_STRING\n    }), obj.Password && {\n      Password: SENSITIVE_STRING\n    });\n  };\n  RedshiftDestinationUpdate.isa = function (o) {\n    return __isa(o, \"RedshiftDestinationUpdate\");\n  };\n})(RedshiftDestinationUpdate || (RedshiftDestinationUpdate = {}));\nexport var RedshiftRetryOptions;\n(function (RedshiftRetryOptions) {\n  RedshiftRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  RedshiftRetryOptions.isa = function (o) {\n    return __isa(o, \"RedshiftRetryOptions\");\n  };\n})(RedshiftRetryOptions || (RedshiftRetryOptions = {}));\nexport var ResourceInUseException;\n(function (ResourceInUseException) {\n  ResourceInUseException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ResourceInUseException.isa = function (o) {\n    return __isa(o, \"ResourceInUseException\");\n  };\n})(ResourceInUseException || (ResourceInUseException = {}));\nexport var ResourceNotFoundException;\n(function (ResourceNotFoundException) {\n  ResourceNotFoundException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ResourceNotFoundException.isa = function (o) {\n    return __isa(o, \"ResourceNotFoundException\");\n  };\n})(ResourceNotFoundException || (ResourceNotFoundException = {}));\nexport var S3DestinationConfiguration;\n(function (S3DestinationConfiguration) {\n  S3DestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  S3DestinationConfiguration.isa = function (o) {\n    return __isa(o, \"S3DestinationConfiguration\");\n  };\n})(S3DestinationConfiguration || (S3DestinationConfiguration = {}));\nexport var S3DestinationDescription;\n(function (S3DestinationDescription) {\n  S3DestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  S3DestinationDescription.isa = function (o) {\n    return __isa(o, \"S3DestinationDescription\");\n  };\n})(S3DestinationDescription || (S3DestinationDescription = {}));\nexport var S3DestinationUpdate;\n(function (S3DestinationUpdate) {\n  S3DestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  S3DestinationUpdate.isa = function (o) {\n    return __isa(o, \"S3DestinationUpdate\");\n  };\n})(S3DestinationUpdate || (S3DestinationUpdate = {}));\nexport var SchemaConfiguration;\n(function (SchemaConfiguration) {\n  SchemaConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  SchemaConfiguration.isa = function (o) {\n    return __isa(o, \"SchemaConfiguration\");\n  };\n})(SchemaConfiguration || (SchemaConfiguration = {}));\nexport var Serializer;\n(function (Serializer) {\n  Serializer.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  Serializer.isa = function (o) {\n    return __isa(o, \"Serializer\");\n  };\n})(Serializer || (Serializer = {}));\nexport var ServiceUnavailableException;\n(function (ServiceUnavailableException) {\n  ServiceUnavailableException.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  ServiceUnavailableException.isa = function (o) {\n    return __isa(o, \"ServiceUnavailableException\");\n  };\n})(ServiceUnavailableException || (ServiceUnavailableException = {}));\nexport var SourceDescription;\n(function (SourceDescription) {\n  SourceDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  SourceDescription.isa = function (o) {\n    return __isa(o, \"SourceDescription\");\n  };\n})(SourceDescription || (SourceDescription = {}));\nexport var SplunkDestinationConfiguration;\n(function (SplunkDestinationConfiguration) {\n  SplunkDestinationConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  SplunkDestinationConfiguration.isa = function (o) {\n    return __isa(o, \"SplunkDestinationConfiguration\");\n  };\n})(SplunkDestinationConfiguration || (SplunkDestinationConfiguration = {}));\nexport var SplunkDestinationDescription;\n(function (SplunkDestinationDescription) {\n  SplunkDestinationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  SplunkDestinationDescription.isa = function (o) {\n    return __isa(o, \"SplunkDestinationDescription\");\n  };\n})(SplunkDestinationDescription || (SplunkDestinationDescription = {}));\nexport var SplunkDestinationUpdate;\n(function (SplunkDestinationUpdate) {\n  SplunkDestinationUpdate.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  SplunkDestinationUpdate.isa = function (o) {\n    return __isa(o, \"SplunkDestinationUpdate\");\n  };\n})(SplunkDestinationUpdate || (SplunkDestinationUpdate = {}));\nexport var SplunkRetryOptions;\n(function (SplunkRetryOptions) {\n  SplunkRetryOptions.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  SplunkRetryOptions.isa = function (o) {\n    return __isa(o, \"SplunkRetryOptions\");\n  };\n})(SplunkRetryOptions || (SplunkRetryOptions = {}));\nexport var StartDeliveryStreamEncryptionInput;\n(function (StartDeliveryStreamEncryptionInput) {\n  StartDeliveryStreamEncryptionInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  StartDeliveryStreamEncryptionInput.isa = function (o) {\n    return __isa(o, \"StartDeliveryStreamEncryptionInput\");\n  };\n})(StartDeliveryStreamEncryptionInput || (StartDeliveryStreamEncryptionInput = {}));\nexport var StartDeliveryStreamEncryptionOutput;\n(function (StartDeliveryStreamEncryptionOutput) {\n  StartDeliveryStreamEncryptionOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  StartDeliveryStreamEncryptionOutput.isa = function (o) {\n    return __isa(o, \"StartDeliveryStreamEncryptionOutput\");\n  };\n})(StartDeliveryStreamEncryptionOutput || (StartDeliveryStreamEncryptionOutput = {}));\nexport var StopDeliveryStreamEncryptionInput;\n(function (StopDeliveryStreamEncryptionInput) {\n  StopDeliveryStreamEncryptionInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  StopDeliveryStreamEncryptionInput.isa = function (o) {\n    return __isa(o, \"StopDeliveryStreamEncryptionInput\");\n  };\n})(StopDeliveryStreamEncryptionInput || (StopDeliveryStreamEncryptionInput = {}));\nexport var StopDeliveryStreamEncryptionOutput;\n(function (StopDeliveryStreamEncryptionOutput) {\n  StopDeliveryStreamEncryptionOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  StopDeliveryStreamEncryptionOutput.isa = function (o) {\n    return __isa(o, \"StopDeliveryStreamEncryptionOutput\");\n  };\n})(StopDeliveryStreamEncryptionOutput || (StopDeliveryStreamEncryptionOutput = {}));\nexport var Tag;\n(function (Tag) {\n  Tag.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  Tag.isa = function (o) {\n    return __isa(o, \"Tag\");\n  };\n})(Tag || (Tag = {}));\nexport var TagDeliveryStreamInput;\n(function (TagDeliveryStreamInput) {\n  TagDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  TagDeliveryStreamInput.isa = function (o) {\n    return __isa(o, \"TagDeliveryStreamInput\");\n  };\n})(TagDeliveryStreamInput || (TagDeliveryStreamInput = {}));\nexport var TagDeliveryStreamOutput;\n(function (TagDeliveryStreamOutput) {\n  TagDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  TagDeliveryStreamOutput.isa = function (o) {\n    return __isa(o, \"TagDeliveryStreamOutput\");\n  };\n})(TagDeliveryStreamOutput || (TagDeliveryStreamOutput = {}));\nexport var UntagDeliveryStreamInput;\n(function (UntagDeliveryStreamInput) {\n  UntagDeliveryStreamInput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  UntagDeliveryStreamInput.isa = function (o) {\n    return __isa(o, \"UntagDeliveryStreamInput\");\n  };\n})(UntagDeliveryStreamInput || (UntagDeliveryStreamInput = {}));\nexport var UntagDeliveryStreamOutput;\n(function (UntagDeliveryStreamOutput) {\n  UntagDeliveryStreamOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  UntagDeliveryStreamOutput.isa = function (o) {\n    return __isa(o, \"UntagDeliveryStreamOutput\");\n  };\n})(UntagDeliveryStreamOutput || (UntagDeliveryStreamOutput = {}));\nexport var UpdateDestinationInput;\n(function (UpdateDestinationInput) {\n  UpdateDestinationInput.filterSensitiveLog = function (obj) {\n    return __assign(__assign(__assign({}, obj), obj.HttpEndpointDestinationUpdate && {\n      HttpEndpointDestinationUpdate: HttpEndpointDestinationUpdate.filterSensitiveLog(obj.HttpEndpointDestinationUpdate)\n    }), obj.RedshiftDestinationUpdate && {\n      RedshiftDestinationUpdate: RedshiftDestinationUpdate.filterSensitiveLog(obj.RedshiftDestinationUpdate)\n    });\n  };\n  UpdateDestinationInput.isa = function (o) {\n    return __isa(o, \"UpdateDestinationInput\");\n  };\n})(UpdateDestinationInput || (UpdateDestinationInput = {}));\nexport var UpdateDestinationOutput;\n(function (UpdateDestinationOutput) {\n  UpdateDestinationOutput.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  UpdateDestinationOutput.isa = function (o) {\n    return __isa(o, \"UpdateDestinationOutput\");\n  };\n})(UpdateDestinationOutput || (UpdateDestinationOutput = {}));\nexport var VpcConfiguration;\n(function (VpcConfiguration) {\n  VpcConfiguration.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  VpcConfiguration.isa = function (o) {\n    return __isa(o, \"VpcConfiguration\");\n  };\n})(VpcConfiguration || (VpcConfiguration = {}));\nexport var VpcConfigurationDescription;\n(function (VpcConfigurationDescription) {\n  VpcConfigurationDescription.filterSensitiveLog = function (obj) {\n    return __assign({}, obj);\n  };\n  VpcConfigurationDescription.isa = function (o) {\n    return __isa(o, \"VpcConfigurationDescription\");\n  };\n})(VpcConfigurationDescription || (VpcConfigurationDescription = {}));","map":{"version":3,"names":["SENSITIVE_STRING","isa","__isa","BufferingHints","filterSensitiveLog","obj","__assign","o","CloudWatchLoggingOptions","CompressionFormat","ConcurrentModificationException","ContentEncoding","CopyCommand","CreateDeliveryStreamInput","RedshiftDestinationConfiguration","HttpEndpointDestinationConfiguration","CreateDeliveryStreamOutput","DataFormatConversionConfiguration","DeleteDeliveryStreamInput","DeleteDeliveryStreamOutput","DeliveryStreamDescription","Destinations","map","item","DestinationDescription","DeliveryStreamEncryptionConfiguration","DeliveryStreamEncryptionConfigurationInput","DeliveryStreamEncryptionStatus","DeliveryStreamFailureType","DeliveryStreamStatus","DescribeDeliveryStreamInput","DescribeDeliveryStreamOutput","Deserializer","RedshiftDestinationDescription","HttpEndpointDestinationDescription","ElasticsearchBufferingHints","ElasticsearchDestinationConfiguration","ElasticsearchDestinationDescription","ElasticsearchDestinationUpdate","ElasticsearchRetryOptions","EncryptionConfiguration","ExtendedS3DestinationConfiguration","ExtendedS3DestinationDescription","ExtendedS3DestinationUpdate","FailureDescription","HiveJsonSerDe","HttpEndpointBufferingHints","HttpEndpointCommonAttribute","AttributeName","AttributeValue","HttpEndpointConfiguration","AccessKey","Url","HttpEndpointDescription","EndpointConfiguration","RequestConfiguration","HttpEndpointRequestConfiguration","HttpEndpointDestinationUpdate","CommonAttributes","HttpEndpointRetryOptions","InputFormatConfiguration","InvalidArgumentException","InvalidKMSResourceException","KeyType","KinesisStreamSourceConfiguration","KinesisStreamSourceDescription","KMSEncryptionConfig","LimitExceededException","ListDeliveryStreamsInput","ListDeliveryStreamsOutput","ListTagsForDeliveryStreamInput","ListTagsForDeliveryStreamOutput","OpenXJsonSerDe","OrcCompression","OrcFormatVersion","OrcSerDe","OutputFormatConfiguration","ParquetCompression","ParquetSerDe","ParquetWriterVersion","ProcessingConfiguration","Processor","ProcessorParameter","ProcessorParameterName","PutRecordBatchInput","PutRecordBatchOutput","PutRecordBatchResponseEntry","PutRecordInput","PutRecordOutput","_Record","Username","Password","RedshiftDestinationUpdate","RedshiftRetryOptions","ResourceInUseException","ResourceNotFoundException","S3DestinationConfiguration","S3DestinationDescription","S3DestinationUpdate","SchemaConfiguration","Serializer","ServiceUnavailableException","SourceDescription","SplunkDestinationConfiguration","SplunkDestinationDescription","SplunkDestinationUpdate","SplunkRetryOptions","StartDeliveryStreamEncryptionInput","StartDeliveryStreamEncryptionOutput","StopDeliveryStreamEncryptionInput","StopDeliveryStreamEncryptionOutput","Tag","TagDeliveryStreamInput","TagDeliveryStreamOutput","UntagDeliveryStreamInput","UntagDeliveryStreamOutput","UpdateDestinationInput","UpdateDestinationOutput","VpcConfiguration","VpcConfigurationDescription"],"sources":["/Users/ericli/node_modules/@aws-sdk/client-firehose/models/index.ts"],"sourcesContent":["import { SENSITIVE_STRING, SmithyException as __SmithyException, isa as __isa } from \"@aws-sdk/smithy-client\";\nimport { MetadataBearer as $MetadataBearer } from \"@aws-sdk/types\";\n\n/**\n * <p>Describes hints for the buffering to perform before delivering data to the\n *          destination. These options are treated as hints, and therefore Kinesis Data Firehose might\n *          choose to use different values when it is optimal. The <code>SizeInMBs</code> and\n *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n *          one of them, you must also provide a value for the other.</p>\n */\nexport interface BufferingHints {\n  __type?: \"BufferingHints\";\n  /**\n   * <p>Buffer incoming data to the specified size, in MiBs, before delivering it to the\n   *          destination. The default value is 5. This parameter is optional but if you specify a value\n   *          for it, you must also specify a value for <code>IntervalInSeconds</code>, and vice\n   *          versa.</p>\n   *          <p>We recommend setting this parameter to a value greater than the amount of data you\n   *          typically ingest into the delivery stream in 10 seconds. For example, if you typically\n   *          ingest data at 1 MiB/sec, the value should be 10 MiB or higher.</p>\n   */\n  SizeInMBs?: number;\n\n  /**\n   * <p>Buffer incoming data for the specified period of time, in seconds, before delivering\n   *          it to the destination. The default value is 300. This parameter is optional but if you\n   *          specify a value for it, you must also specify a value for <code>SizeInMBs</code>, and vice\n   *          versa.</p>\n   */\n  IntervalInSeconds?: number;\n}\n\nexport namespace BufferingHints {\n  export const filterSensitiveLog = (obj: BufferingHints): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is BufferingHints => __isa(o, \"BufferingHints\");\n}\n\n/**\n * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n */\nexport interface CloudWatchLoggingOptions {\n  __type?: \"CloudWatchLoggingOptions\";\n  /**\n   * <p>The CloudWatch log stream name for logging. This value is required if CloudWatch\n   *          logging is enabled.</p>\n   */\n  LogStreamName?: string;\n\n  /**\n   * <p>Enables or disables CloudWatch logging.</p>\n   */\n  Enabled?: boolean;\n\n  /**\n   * <p>The CloudWatch group name for logging. This value is required if CloudWatch logging\n   *          is enabled.</p>\n   */\n  LogGroupName?: string;\n}\n\nexport namespace CloudWatchLoggingOptions {\n  export const filterSensitiveLog = (obj: CloudWatchLoggingOptions): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is CloudWatchLoggingOptions => __isa(o, \"CloudWatchLoggingOptions\");\n}\n\nexport enum CompressionFormat {\n  GZIP = \"GZIP\",\n  HADOOP_SNAPPY = \"HADOOP_SNAPPY\",\n  SNAPPY = \"Snappy\",\n  UNCOMPRESSED = \"UNCOMPRESSED\",\n  ZIP = \"ZIP\",\n}\n\n/**\n * <p>Another modification has already happened. Fetch <code>VersionId</code> again and use\n *          it to update the destination.</p>\n */\nexport interface ConcurrentModificationException extends __SmithyException, $MetadataBearer {\n  name: \"ConcurrentModificationException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ConcurrentModificationException {\n  export const filterSensitiveLog = (obj: ConcurrentModificationException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ConcurrentModificationException => __isa(o, \"ConcurrentModificationException\");\n}\n\nexport enum ContentEncoding {\n  GZIP = \"GZIP\",\n  NONE = \"NONE\",\n}\n\n/**\n * <p>Describes a <code>COPY</code> command for Amazon Redshift.</p>\n */\nexport interface CopyCommand {\n  __type?: \"CopyCommand\";\n  /**\n   * <p>The name of the target table. The table must already exist in the database.</p>\n   */\n  DataTableName: string | undefined;\n\n  /**\n   * <p>Optional parameters to use with the Amazon Redshift <code>COPY</code> command. For\n   *          more information, see the \"Optional Parameters\" section of <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_COPY.html\">Amazon Redshift COPY command</a>. Some possible\n   *          examples that would apply to Kinesis Data Firehose are as follows:</p>\n   *          <p>\n   *             <code>delimiter '\\t' lzop;</code> - fields are delimited with \"\\t\" (TAB character) and\n   *          compressed using lzop.</p>\n   *          <p>\n   *             <code>delimiter '|'</code> - fields are delimited with \"|\" (this is the default\n   *          delimiter).</p>\n   *          <p>\n   *             <code>delimiter '|' escape</code> - the delimiter should be escaped.</p>\n   *          <p>\n   *             <code>fixedwidth 'venueid:3,venuename:25,venuecity:12,venuestate:2,venueseats:6'</code> -\n   *          fields are fixed width in the source, with each width specified after every column in the\n   *          table.</p>\n   *          <p>\n   *             <code>JSON 's3://mybucket/jsonpaths.txt'</code> - data is in JSON format, and the path\n   *          specified is the format of the data.</p>\n   *          <p>For more examples, see <a href=\"https://docs.aws.amazon.com/redshift/latest/dg/r_COPY_command_examples.html\">Amazon Redshift COPY command\n   *             examples</a>.</p>\n   */\n  CopyOptions?: string;\n\n  /**\n   * <p>A comma-separated list of column names.</p>\n   */\n  DataTableColumns?: string;\n}\n\nexport namespace CopyCommand {\n  export const filterSensitiveLog = (obj: CopyCommand): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is CopyCommand => __isa(o, \"CopyCommand\");\n}\n\nexport interface CreateDeliveryStreamInput {\n  __type?: \"CreateDeliveryStreamInput\";\n  /**\n   * <p>The destination in Amazon Redshift. You can specify only one destination.</p>\n   */\n  RedshiftDestinationConfiguration?: RedshiftDestinationConfiguration;\n\n  /**\n   * <p>[Deprecated]\n   *          The destination in Amazon S3. You can specify only one destination.</p>\n   */\n  S3DestinationConfiguration?: S3DestinationConfiguration;\n\n  /**\n   * <p>The delivery stream type. This parameter can be one of the following\n   *          values:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>DirectPut</code>: Provider applications access the delivery stream\n   *                directly.</p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data\n   *                stream as a source.</p>\n   *             </li>\n   *          </ul>\n   */\n  DeliveryStreamType?: DeliveryStreamType | string;\n\n  /**\n   * <p>The destination in Splunk. You can specify only one destination.</p>\n   */\n  SplunkDestinationConfiguration?: SplunkDestinationConfiguration;\n\n  /**\n   * <p>The name of the delivery stream. This name must be unique per AWS account in the same\n   *          AWS Region. If the delivery streams are in different accounts or different Regions, you can\n   *          have multiple delivery streams with the same name.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>When a Kinesis data stream is used as the source for the delivery stream, a <a>KinesisStreamSourceConfiguration</a> containing the Kinesis data stream Amazon\n   *          Resource Name (ARN) and the role ARN for the source stream.</p>\n   */\n  KinesisStreamSourceConfiguration?: KinesisStreamSourceConfiguration;\n\n  /**\n   * <p>The destination in Amazon ES. You can specify only one destination.</p>\n   */\n  ElasticsearchDestinationConfiguration?: ElasticsearchDestinationConfiguration;\n\n  /**\n   * <p>Used to specify the type and Amazon Resource Name (ARN) of the KMS key needed for\n   *          Server-Side Encryption (SSE).</p>\n   */\n  DeliveryStreamEncryptionConfigurationInput?: DeliveryStreamEncryptionConfigurationInput;\n\n  /**\n   * <p>Enables configuring Kinesis Firehose to deliver data to any HTTP endpoint destination.\n   *          You can specify only one destination.</p>\n   */\n  HttpEndpointDestinationConfiguration?: HttpEndpointDestinationConfiguration;\n\n  /**\n   * <p>A set of tags to assign to the delivery stream. A tag is a key-value pair that you can\n   *          define and assign to AWS resources. Tags are metadata. For example, you can add friendly\n   *          names and descriptions or other types of information that can help you distinguish the\n   *          delivery stream. For more information about tags, see <a href=\"https://docs.aws.amazon.com/awsaccountbilling/latest/aboutv2/cost-alloc-tags.html\">Using Cost Allocation Tags</a> in the AWS Billing and Cost Management User\n   *          Guide.</p>\n   *\n   *          <p>You can specify up to 50 tags when creating a delivery stream.</p>\n   */\n  Tags?: Tag[];\n\n  /**\n   * <p>The destination in Amazon S3. You can specify only one destination.</p>\n   */\n  ExtendedS3DestinationConfiguration?: ExtendedS3DestinationConfiguration;\n}\n\nexport namespace CreateDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: CreateDeliveryStreamInput): any => ({\n    ...obj,\n    ...(obj.RedshiftDestinationConfiguration && {\n      RedshiftDestinationConfiguration: RedshiftDestinationConfiguration.filterSensitiveLog(\n        obj.RedshiftDestinationConfiguration\n      ),\n    }),\n    ...(obj.HttpEndpointDestinationConfiguration && {\n      HttpEndpointDestinationConfiguration: HttpEndpointDestinationConfiguration.filterSensitiveLog(\n        obj.HttpEndpointDestinationConfiguration\n      ),\n    }),\n  });\n  export const isa = (o: any): o is CreateDeliveryStreamInput => __isa(o, \"CreateDeliveryStreamInput\");\n}\n\nexport interface CreateDeliveryStreamOutput {\n  __type?: \"CreateDeliveryStreamOutput\";\n  /**\n   * <p>The ARN of the delivery stream.</p>\n   */\n  DeliveryStreamARN?: string;\n}\n\nexport namespace CreateDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: CreateDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is CreateDeliveryStreamOutput => __isa(o, \"CreateDeliveryStreamOutput\");\n}\n\n/**\n * <p>Specifies that you want Kinesis Data Firehose to convert data from the JSON format to\n *          the Parquet or ORC format before writing it to Amazon S3. Kinesis Data Firehose uses the\n *          serializer and deserializer that you specify, in addition to the column information from\n *          the AWS Glue table, to deserialize your input data from JSON and then serialize it to the\n *          Parquet or ORC format. For more information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/record-format-conversion.html\">Kinesis Data Firehose Record Format Conversion</a>.</p>\n */\nexport interface DataFormatConversionConfiguration {\n  __type?: \"DataFormatConversionConfiguration\";\n  /**\n   * <p>Specifies the serializer that you want Kinesis Data Firehose to use to convert the\n   *          format of your data to the Parquet or ORC format. This parameter is required if\n   *             <code>Enabled</code> is set to true.</p>\n   */\n  OutputFormatConfiguration?: OutputFormatConfiguration;\n\n  /**\n   * <p>Defaults to <code>true</code>. Set it to <code>false</code> if you want to disable\n   *          format conversion while preserving the configuration details.</p>\n   */\n  Enabled?: boolean;\n\n  /**\n   * <p>Specifies the deserializer that you want Kinesis Data Firehose to use to convert the\n   *          format of your data from JSON. This parameter is required if <code>Enabled</code> is set to\n   *          true.</p>\n   */\n  InputFormatConfiguration?: InputFormatConfiguration;\n\n  /**\n   * <p>Specifies the AWS Glue Data Catalog table that contains the column information. This\n   *          parameter is required if <code>Enabled</code> is set to true.</p>\n   */\n  SchemaConfiguration?: SchemaConfiguration;\n}\n\nexport namespace DataFormatConversionConfiguration {\n  export const filterSensitiveLog = (obj: DataFormatConversionConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is DataFormatConversionConfiguration => __isa(o, \"DataFormatConversionConfiguration\");\n}\n\nexport interface DeleteDeliveryStreamInput {\n  __type?: \"DeleteDeliveryStreamInput\";\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>Set this to true if you want to delete the delivery stream even if Kinesis Data Firehose\n   *          is unable to retire the grant for the CMK. Kinesis Data Firehose might be unable to retire\n   *          the grant due to a customer error, such as when the CMK or the grant are in an invalid\n   *          state. If you force deletion, you can then use the <a href=\"https://docs.aws.amazon.com/kms/latest/APIReference/API_RevokeGrant.html\">RevokeGrant</a> operation to revoke the grant you gave to Kinesis Data Firehose. If\n   *          a failure to retire the grant happens due to an AWS KMS issue, Kinesis Data Firehose keeps\n   *          retrying the delete operation.</p>\n   *          <p>The default value is false.</p>\n   */\n  AllowForceDelete?: boolean;\n}\n\nexport namespace DeleteDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: DeleteDeliveryStreamInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is DeleteDeliveryStreamInput => __isa(o, \"DeleteDeliveryStreamInput\");\n}\n\nexport interface DeleteDeliveryStreamOutput {\n  __type?: \"DeleteDeliveryStreamOutput\";\n}\n\nexport namespace DeleteDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: DeleteDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is DeleteDeliveryStreamOutput => __isa(o, \"DeleteDeliveryStreamOutput\");\n}\n\n/**\n * <p>Contains information about a delivery stream.</p>\n */\nexport interface DeliveryStreamDescription {\n  __type?: \"DeliveryStreamDescription\";\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>The destinations.</p>\n   */\n  Destinations: DestinationDescription[] | undefined;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the delivery stream. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  DeliveryStreamARN: string | undefined;\n\n  /**\n   * <p>The delivery stream type. This can be one of the following values:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>DirectPut</code>: Provider applications access the delivery stream\n   *                directly.</p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data\n   *                stream as a source.</p>\n   *             </li>\n   *          </ul>\n   */\n  DeliveryStreamType: DeliveryStreamType | string | undefined;\n\n  /**\n   * <p>Each time the destination is updated for a delivery stream, the version ID is\n   *          changed, and the current version ID is required when updating the destination. This is so\n   *          that the service knows it is applying the changes to the correct version of the delivery\n   *          stream.</p>\n   */\n  VersionId: string | undefined;\n\n  /**\n   * <p>The status of the delivery stream. If the status of a delivery stream is\n   *             <code>CREATING_FAILED</code>, this status doesn't change, and you can't invoke\n   *             <code>CreateDeliveryStream</code> again on it. However, you can invoke the <a>DeleteDeliveryStream</a> operation to delete it.</p>\n   */\n  DeliveryStreamStatus: DeliveryStreamStatus | string | undefined;\n\n  /**\n   * <p>The date and time that the delivery stream was created.</p>\n   */\n  CreateTimestamp?: Date;\n\n  /**\n   * <p>Indicates whether there are more destinations available to list.</p>\n   */\n  HasMoreDestinations: boolean | undefined;\n\n  /**\n   * <p>Provides details in case one of the following operations fails due to an error related\n   *          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,\n   *             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>\n   */\n  FailureDescription?: FailureDescription;\n\n  /**\n   * <p>Indicates the server-side encryption (SSE) status for the delivery stream.</p>\n   */\n  DeliveryStreamEncryptionConfiguration?: DeliveryStreamEncryptionConfiguration;\n\n  /**\n   * <p>The date and time that the delivery stream was last updated.</p>\n   */\n  LastUpdateTimestamp?: Date;\n\n  /**\n   * <p>If the <code>DeliveryStreamType</code> parameter is\n   *             <code>KinesisStreamAsSource</code>, a <a>SourceDescription</a> object\n   *          describing the source Kinesis data stream.</p>\n   */\n  Source?: SourceDescription;\n}\n\nexport namespace DeliveryStreamDescription {\n  export const filterSensitiveLog = (obj: DeliveryStreamDescription): any => ({\n    ...obj,\n    ...(obj.Destinations && {\n      Destinations: obj.Destinations.map((item) => DestinationDescription.filterSensitiveLog(item)),\n    }),\n  });\n  export const isa = (o: any): o is DeliveryStreamDescription => __isa(o, \"DeliveryStreamDescription\");\n}\n\n/**\n * <p>Contains information about the server-side encryption (SSE) status for the delivery\n *          stream, the type customer master key (CMK) in use, if any, and the ARN of the CMK. You can\n *          get <code>DeliveryStreamEncryptionConfiguration</code> by invoking the <a>DescribeDeliveryStream</a> operation. </p>\n */\nexport interface DeliveryStreamEncryptionConfiguration {\n  __type?: \"DeliveryStreamEncryptionConfiguration\";\n  /**\n   * <p>Provides details in case one of the following operations fails due to an error related\n   *          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,\n   *             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>\n   */\n  FailureDescription?: FailureDescription;\n\n  /**\n   * <p>If <code>KeyType</code> is <code>CUSTOMER_MANAGED_CMK</code>, this field contains the\n   *          ARN of the customer managed CMK. If <code>KeyType</code> is <code>AWS_OWNED_CMK</code>,\n   *             <code>DeliveryStreamEncryptionConfiguration</code> doesn't contain a value for\n   *             <code>KeyARN</code>.</p>\n   */\n  KeyARN?: string;\n\n  /**\n   * <p>Indicates the type of customer master key (CMK) that is used for encryption. The default\n   *          setting is <code>AWS_OWNED_CMK</code>. For more information about CMKs, see <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys\">Customer Master Keys (CMKs)</a>.</p>\n   */\n  KeyType?: KeyType | string;\n\n  /**\n   * <p>This is the server-side encryption (SSE) status for the delivery stream. For a full\n   *          description of the different values of this status, see <a>StartDeliveryStreamEncryption</a> and <a>StopDeliveryStreamEncryption</a>. If this status is <code>ENABLING_FAILED</code>\n   *          or <code>DISABLING_FAILED</code>, it is the status of the most recent attempt to enable or\n   *          disable SSE, respectively.</p>\n   */\n  Status?: DeliveryStreamEncryptionStatus | string;\n}\n\nexport namespace DeliveryStreamEncryptionConfiguration {\n  export const filterSensitiveLog = (obj: DeliveryStreamEncryptionConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is DeliveryStreamEncryptionConfiguration =>\n    __isa(o, \"DeliveryStreamEncryptionConfiguration\");\n}\n\n/**\n * <p>Specifies the type and Amazon Resource Name (ARN) of the CMK to use for Server-Side\n *          Encryption (SSE). </p>\n */\nexport interface DeliveryStreamEncryptionConfigurationInput {\n  __type?: \"DeliveryStreamEncryptionConfigurationInput\";\n  /**\n   * <p>Indicates the type of customer master key (CMK) to use for encryption. The default\n   *          setting is <code>AWS_OWNED_CMK</code>. For more information about CMKs, see <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/concepts.html#master_keys\">Customer Master Keys (CMKs)</a>. When you invoke <a>CreateDeliveryStream</a> or <a>StartDeliveryStreamEncryption</a> with\n   *             <code>KeyType</code> set to CUSTOMER_MANAGED_CMK, Kinesis Data Firehose invokes the\n   *          Amazon KMS operation <a href=\"https://docs.aws.amazon.com/kms/latest/APIReference/API_CreateGrant.html\">CreateGrant</a> to create a grant that allows the Kinesis Data Firehose service to\n   *          use the customer managed CMK to perform encryption and decryption. Kinesis Data Firehose\n   *          manages that grant. </p>\n   *          <p>When you invoke <a>StartDeliveryStreamEncryption</a> to change the CMK for a\n   *          delivery stream that is encrypted with a customer managed CMK, Kinesis Data Firehose\n   *          schedules the grant it had on the old CMK for retirement.</p>\n   *          <p>You can use a CMK of type CUSTOMER_MANAGED_CMK to encrypt up to 500 delivery streams. If\n   *          a <a>CreateDeliveryStream</a> or <a>StartDeliveryStreamEncryption</a>\n   *          operation exceeds this limit, Kinesis Data Firehose throws a\n   *             <code>LimitExceededException</code>. </p>\n   *          <important>\n   *             <p>To encrypt your delivery stream, use symmetric CMKs. Kinesis Data Firehose doesn't\n   *             support asymmetric CMKs. For information about symmetric and asymmetric CMKs, see <a href=\"https://docs.aws.amazon.com/kms/latest/developerguide/symm-asymm-concepts.html\">About Symmetric and Asymmetric CMKs</a> in the AWS Key Management Service\n   *             developer guide.</p>\n   *          </important>\n   */\n  KeyType: KeyType | string | undefined;\n\n  /**\n   * <p>If you set <code>KeyType</code> to <code>CUSTOMER_MANAGED_CMK</code>, you must specify\n   *          the Amazon Resource Name (ARN) of the CMK. If you set <code>KeyType</code> to\n   *             <code>AWS_OWNED_CMK</code>, Kinesis Data Firehose uses a service-account CMK.</p>\n   */\n  KeyARN?: string;\n}\n\nexport namespace DeliveryStreamEncryptionConfigurationInput {\n  export const filterSensitiveLog = (obj: DeliveryStreamEncryptionConfigurationInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is DeliveryStreamEncryptionConfigurationInput =>\n    __isa(o, \"DeliveryStreamEncryptionConfigurationInput\");\n}\n\nexport enum DeliveryStreamEncryptionStatus {\n  DISABLED = \"DISABLED\",\n  DISABLING = \"DISABLING\",\n  DISABLING_FAILED = \"DISABLING_FAILED\",\n  ENABLED = \"ENABLED\",\n  ENABLING = \"ENABLING\",\n  ENABLING_FAILED = \"ENABLING_FAILED\",\n}\n\nexport enum DeliveryStreamFailureType {\n  CREATE_ENI_FAILED = \"CREATE_ENI_FAILED\",\n  CREATE_KMS_GRANT_FAILED = \"CREATE_KMS_GRANT_FAILED\",\n  DELETE_ENI_FAILED = \"DELETE_ENI_FAILED\",\n  DISABLED_KMS_KEY = \"DISABLED_KMS_KEY\",\n  ENI_ACCESS_DENIED = \"ENI_ACCESS_DENIED\",\n  INVALID_KMS_KEY = \"INVALID_KMS_KEY\",\n  KMS_ACCESS_DENIED = \"KMS_ACCESS_DENIED\",\n  KMS_KEY_NOT_FOUND = \"KMS_KEY_NOT_FOUND\",\n  KMS_OPT_IN_REQUIRED = \"KMS_OPT_IN_REQUIRED\",\n  RETIRE_KMS_GRANT_FAILED = \"RETIRE_KMS_GRANT_FAILED\",\n  SECURITY_GROUP_ACCESS_DENIED = \"SECURITY_GROUP_ACCESS_DENIED\",\n  SECURITY_GROUP_NOT_FOUND = \"SECURITY_GROUP_NOT_FOUND\",\n  SUBNET_ACCESS_DENIED = \"SUBNET_ACCESS_DENIED\",\n  SUBNET_NOT_FOUND = \"SUBNET_NOT_FOUND\",\n  UNKNOWN_ERROR = \"UNKNOWN_ERROR\",\n}\n\nexport enum DeliveryStreamStatus {\n  ACTIVE = \"ACTIVE\",\n  CREATING = \"CREATING\",\n  CREATING_FAILED = \"CREATING_FAILED\",\n  DELETING = \"DELETING\",\n  DELETING_FAILED = \"DELETING_FAILED\",\n}\n\nexport type DeliveryStreamType = \"DirectPut\" | \"KinesisStreamAsSource\";\n\nexport interface DescribeDeliveryStreamInput {\n  __type?: \"DescribeDeliveryStreamInput\";\n  /**\n   * <p>The limit on the number of destinations to return. You can have one destination per\n   *          delivery stream.</p>\n   */\n  Limit?: number;\n\n  /**\n   * <p>The ID of the destination to start returning the destination information. Kinesis\n   *          Data Firehose supports one destination per delivery stream.</p>\n   */\n  ExclusiveStartDestinationId?: string;\n\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace DescribeDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: DescribeDeliveryStreamInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is DescribeDeliveryStreamInput => __isa(o, \"DescribeDeliveryStreamInput\");\n}\n\nexport interface DescribeDeliveryStreamOutput {\n  __type?: \"DescribeDeliveryStreamOutput\";\n  /**\n   * <p>Information about the delivery stream.</p>\n   */\n  DeliveryStreamDescription: DeliveryStreamDescription | undefined;\n}\n\nexport namespace DescribeDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: DescribeDeliveryStreamOutput): any => ({\n    ...obj,\n    ...(obj.DeliveryStreamDescription && {\n      DeliveryStreamDescription: DeliveryStreamDescription.filterSensitiveLog(obj.DeliveryStreamDescription),\n    }),\n  });\n  export const isa = (o: any): o is DescribeDeliveryStreamOutput => __isa(o, \"DescribeDeliveryStreamOutput\");\n}\n\n/**\n * <p>The deserializer you want Kinesis Data Firehose to use for converting the input data\n *          from JSON. Kinesis Data Firehose then serializes the data to its final format using the\n *             <a>Serializer</a>. Kinesis Data Firehose supports two types of deserializers:\n *          the <a href=\"https://cwiki.apache.org/confluence/display/Hive/LanguageManual+DDL#LanguageManualDDL-JSON\">Apache Hive JSON SerDe</a> and the <a href=\"https://github.com/rcongiu/Hive-JSON-Serde\">OpenX JSON SerDe</a>.</p>\n */\nexport interface Deserializer {\n  __type?: \"Deserializer\";\n  /**\n   * <p>The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing\n   *          data, which means converting it from the JSON format in preparation for serializing it to\n   *          the Parquet or ORC format. This is one of two deserializers you can choose, depending on\n   *          which one offers the functionality you need. The other option is the OpenX SerDe.</p>\n   */\n  HiveJsonSerDe?: HiveJsonSerDe;\n\n  /**\n   * <p>The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means\n   *          converting it from the JSON format in preparation for serializing it to the Parquet or ORC\n   *          format. This is one of two deserializers you can choose, depending on which one offers the\n   *          functionality you need. The other option is the native Hive / HCatalog JsonSerDe.</p>\n   */\n  OpenXJsonSerDe?: OpenXJsonSerDe;\n}\n\nexport namespace Deserializer {\n  export const filterSensitiveLog = (obj: Deserializer): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is Deserializer => __isa(o, \"Deserializer\");\n}\n\n/**\n * <p>Describes the destination for a delivery stream.</p>\n */\nexport interface DestinationDescription {\n  __type?: \"DestinationDescription\";\n  /**\n   * <p>The destination in Amazon Redshift.</p>\n   */\n  RedshiftDestinationDescription?: RedshiftDestinationDescription;\n\n  /**\n   * <p>The ID of the destination.</p>\n   */\n  DestinationId: string | undefined;\n\n  /**\n   * <p>Describes the specified HTTP endpoint destination.</p>\n   */\n  HttpEndpointDestinationDescription?: HttpEndpointDestinationDescription;\n\n  /**\n   * <p>The destination in Amazon ES.</p>\n   */\n  ElasticsearchDestinationDescription?: ElasticsearchDestinationDescription;\n\n  /**\n   * <p>The destination in Splunk.</p>\n   */\n  SplunkDestinationDescription?: SplunkDestinationDescription;\n\n  /**\n   * <p>[Deprecated] The destination in Amazon S3.</p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The destination in Amazon S3.</p>\n   */\n  ExtendedS3DestinationDescription?: ExtendedS3DestinationDescription;\n}\n\nexport namespace DestinationDescription {\n  export const filterSensitiveLog = (obj: DestinationDescription): any => ({\n    ...obj,\n    ...(obj.RedshiftDestinationDescription && {\n      RedshiftDestinationDescription: RedshiftDestinationDescription.filterSensitiveLog(\n        obj.RedshiftDestinationDescription\n      ),\n    }),\n    ...(obj.HttpEndpointDestinationDescription && {\n      HttpEndpointDestinationDescription: HttpEndpointDestinationDescription.filterSensitiveLog(\n        obj.HttpEndpointDestinationDescription\n      ),\n    }),\n  });\n  export const isa = (o: any): o is DestinationDescription => __isa(o, \"DestinationDescription\");\n}\n\n/**\n * <p>Describes the buffering to perform before delivering data to the Amazon ES\n *          destination.</p>\n */\nexport interface ElasticsearchBufferingHints {\n  __type?: \"ElasticsearchBufferingHints\";\n  /**\n   * <p>Buffer incoming data to the specified size, in MBs, before delivering it to the\n   *          destination. The default value is 5.</p>\n   *          <p>We recommend setting this parameter to a value greater than the amount of data you\n   *          typically ingest into the delivery stream in 10 seconds. For example, if you typically\n   *          ingest data at 1 MB/sec, the value should be 10 MB or higher.</p>\n   */\n  SizeInMBs?: number;\n\n  /**\n   * <p>Buffer incoming data for the specified period of time, in seconds, before delivering\n   *          it to the destination. The default value is 300 (5 minutes).</p>\n   */\n  IntervalInSeconds?: number;\n}\n\nexport namespace ElasticsearchBufferingHints {\n  export const filterSensitiveLog = (obj: ElasticsearchBufferingHints): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ElasticsearchBufferingHints => __isa(o, \"ElasticsearchBufferingHints\");\n}\n\n/**\n * <p>Describes the configuration of a destination in Amazon ES.</p>\n */\nexport interface ElasticsearchDestinationConfiguration {\n  __type?: \"ElasticsearchDestinationConfiguration\";\n  /**\n   * <p>The Elasticsearch index name.</p>\n   */\n  IndexName: string | undefined;\n\n  /**\n   * <p>The endpoint to use when communicating with the cluster. Specify either this\n   *             <code>ClusterEndpoint</code> or the <code>DomainARN</code> field.</p>\n   */\n  ClusterEndpoint?: string;\n\n  /**\n   * <p>The configuration for the backup Amazon S3 location.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The buffering options. If no value is specified, the default values for\n   *             <code>ElasticsearchBufferingHints</code> are used.</p>\n   */\n  BufferingHints?: ElasticsearchBufferingHints;\n\n  /**\n   * <p>The details of the VPC of the Amazon ES destination.</p>\n   */\n  VpcConfiguration?: VpcConfiguration;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon ES. The default value is 300 (5 minutes).</p>\n   */\n  RetryOptions?: ElasticsearchRetryOptions;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per\n   *          index. If you try to specify a new type for an existing index that already has another\n   *          type, Kinesis Data Firehose returns an error during run time.</p>\n   *\n   *          <p>For Elasticsearch 7.x, don't specify a <code>TypeName</code>.</p>\n   */\n  TypeName?: string;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose\n   *          for calling the Amazon ES Configuration API and for indexing documents. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant Kinesis Data\n   *             Firehose Access to an Amazon S3 Destination</a> and <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The Elasticsearch index rotation period. Index rotation appends a timestamp to the\n   *             <code>IndexName</code> to facilitate the expiration of old data. For more information,\n   *          see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation\">Index Rotation for the\n   *             Amazon ES Destination</a>. The default value is<code>OneDay</code>.</p>\n   */\n  IndexRotationPeriod?: ElasticsearchIndexRotationPeriod | string;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Defines how documents should be delivered to Amazon S3. When it is set to\n   *             <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any documents that could\n   *          not be indexed to the configured Amazon S3 destination, with\n   *             <code>elasticsearch-failed/</code> appended to the key prefix. When set to\n   *             <code>AllDocuments</code>, Kinesis Data Firehose delivers all incoming records to Amazon\n   *          S3, and also writes failed documents with <code>elasticsearch-failed/</code> appended to\n   *          the prefix. For more information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-s3-backup\">Amazon S3 Backup for the\n   *             Amazon ES Destination</a>. Default value is\n   *          <code>FailedDocumentsOnly</code>.</p>\n   *          <p>You can't change this backup mode after you create the delivery stream. </p>\n   */\n  S3BackupMode?: ElasticsearchS3BackupMode | string;\n\n  /**\n   * <p>The ARN of the Amazon ES domain. The IAM role must have permissions\n   *             for<code>DescribeElasticsearchDomain</code>, <code>DescribeElasticsearchDomains</code>,\n   *          and <code>DescribeElasticsearchDomainConfig</code>after assuming the role specified in\n   *             <b>RoleARN</b>. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   *\n   *          <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>\n   */\n  DomainARN?: string;\n}\n\nexport namespace ElasticsearchDestinationConfiguration {\n  export const filterSensitiveLog = (obj: ElasticsearchDestinationConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ElasticsearchDestinationConfiguration =>\n    __isa(o, \"ElasticsearchDestinationConfiguration\");\n}\n\n/**\n * <p>The destination description in Amazon ES.</p>\n */\nexport interface ElasticsearchDestinationDescription {\n  __type?: \"ElasticsearchDestinationDescription\";\n  /**\n   * <p>The Amazon CloudWatch logging options.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The Elasticsearch index name.</p>\n   */\n  IndexName?: string;\n\n  /**\n   * <p>The details of the VPC of the Amazon ES destination.</p>\n   */\n  VpcConfigurationDescription?: VpcConfigurationDescription;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The buffering options.</p>\n   */\n  BufferingHints?: ElasticsearchBufferingHints;\n\n  /**\n   * <p>The Amazon S3 backup mode.</p>\n   */\n  S3BackupMode?: ElasticsearchS3BackupMode | string;\n\n  /**\n   * <p>The Elasticsearch index rotation period</p>\n   */\n  IndexRotationPeriod?: ElasticsearchIndexRotationPeriod | string;\n\n  /**\n   * <p>The endpoint to use when communicating with the cluster. Kinesis Data Firehose uses\n   *          either this <code>ClusterEndpoint</code> or the <code>DomainARN</code> field to send data\n   *          to Amazon ES.</p>\n   */\n  ClusterEndpoint?: string;\n\n  /**\n   * <p>The Elasticsearch type name. This applies to Elasticsearch 6.x and lower versions.\n   *          For Elasticsearch 7.x, there's no value for <code>TypeName</code>.</p>\n   */\n  TypeName?: string;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the Amazon ES domain. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   *\n   *          <p>Kinesis Data Firehose uses either <code>ClusterEndpoint</code> or <code>DomainARN</code>\n   *          to send data to Amazon ES.</p>\n   */\n  DomainARN?: string;\n\n  /**\n   * <p>The Amazon ES retry options.</p>\n   */\n  RetryOptions?: ElasticsearchRetryOptions;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n}\n\nexport namespace ElasticsearchDestinationDescription {\n  export const filterSensitiveLog = (obj: ElasticsearchDestinationDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ElasticsearchDestinationDescription =>\n    __isa(o, \"ElasticsearchDestinationDescription\");\n}\n\n/**\n * <p>Describes an update for a destination in Amazon ES.</p>\n */\nexport interface ElasticsearchDestinationUpdate {\n  __type?: \"ElasticsearchDestinationUpdate\";\n  /**\n   * <p>The Elasticsearch type name. For Elasticsearch 6.x, there can be only one type per\n   *          index. If you try to specify a new type for an existing index that already has another\n   *          type, Kinesis Data Firehose returns an error during runtime.</p>\n   *\n   *          <p>If you upgrade Elasticsearch from 6.x to 7.x and dont update your delivery stream,\n   *          Kinesis Data Firehose still delivers data to Elasticsearch with the old index name and type\n   *          name. If you want to update your delivery stream with a new index name, provide an empty\n   *          string for <code>TypeName</code>. </p>\n   */\n  TypeName?: string;\n\n  /**\n   * <p>The endpoint to use when communicating with the cluster. Specify either this\n   *             <code>ClusterEndpoint</code> or the <code>DomainARN</code> field.</p>\n   */\n  ClusterEndpoint?: string;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the IAM role to be assumed by Kinesis Data Firehose\n   *          for calling the Amazon ES Configuration API and for indexing documents. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/controlling-access.html#using-iam-s3\">Grant Kinesis Data\n   *             Firehose Access to an Amazon S3 Destination</a> and <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the Amazon ES domain. The IAM role must have permissions\n   *             for<code>DescribeElasticsearchDomain</code>, <code>DescribeElasticsearchDomains</code>,\n   *          and <code>DescribeElasticsearchDomainConfig</code>after assuming the IAM role specified in\n   *             <code>RoleARN</code>. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   *\n   *          <p>Specify either <code>ClusterEndpoint</code> or <code>DomainARN</code>.</p>\n   */\n  DomainARN?: string;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon ES. The default value is 300 (5 minutes).</p>\n   */\n  RetryOptions?: ElasticsearchRetryOptions;\n\n  /**\n   * <p>The Elasticsearch index name.</p>\n   */\n  IndexName?: string;\n\n  /**\n   * <p>The buffering options. If no value is specified,\n   *             <code>ElasticsearchBufferingHints</code> object default values are used. </p>\n   */\n  BufferingHints?: ElasticsearchBufferingHints;\n\n  /**\n   * <p>The Elasticsearch index rotation period. Index rotation appends a timestamp to\n   *             <code>IndexName</code> to facilitate the expiration of old data. For more information,\n   *          see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/basic-deliver.html#es-index-rotation\">Index Rotation for the\n   *             Amazon ES Destination</a>. Default value is<code>OneDay</code>.</p>\n   */\n  IndexRotationPeriod?: ElasticsearchIndexRotationPeriod | string;\n}\n\nexport namespace ElasticsearchDestinationUpdate {\n  export const filterSensitiveLog = (obj: ElasticsearchDestinationUpdate): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ElasticsearchDestinationUpdate => __isa(o, \"ElasticsearchDestinationUpdate\");\n}\n\nexport type ElasticsearchIndexRotationPeriod = \"NoRotation\" | \"OneDay\" | \"OneHour\" | \"OneMonth\" | \"OneWeek\";\n\n/**\n * <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver\n *          documents to Amazon ES.</p>\n */\nexport interface ElasticsearchRetryOptions {\n  __type?: \"ElasticsearchRetryOptions\";\n  /**\n   * <p>After an initial failure to deliver to Amazon ES, the total amount of time during\n   *          which Kinesis Data Firehose retries delivery (including the first attempt). After this time\n   *          has elapsed, the failed documents are written to Amazon S3. Default value is 300 seconds (5\n   *          minutes). A value of 0 (zero) results in no retries.</p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace ElasticsearchRetryOptions {\n  export const filterSensitiveLog = (obj: ElasticsearchRetryOptions): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ElasticsearchRetryOptions => __isa(o, \"ElasticsearchRetryOptions\");\n}\n\nexport type ElasticsearchS3BackupMode = \"AllDocuments\" | \"FailedDocumentsOnly\";\n\n/**\n * <p>Describes the encryption for a destination in Amazon S3.</p>\n */\nexport interface EncryptionConfiguration {\n  __type?: \"EncryptionConfiguration\";\n  /**\n   * <p>The encryption key.</p>\n   */\n  KMSEncryptionConfig?: KMSEncryptionConfig;\n\n  /**\n   * <p>Specifically override existing encryption information to ensure that no encryption is\n   *          used.</p>\n   */\n  NoEncryptionConfig?: NoEncryptionConfig | string;\n}\n\nexport namespace EncryptionConfiguration {\n  export const filterSensitiveLog = (obj: EncryptionConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is EncryptionConfiguration => __isa(o, \"EncryptionConfiguration\");\n}\n\n/**\n * <p>Describes the configuration of a destination in Amazon S3.</p>\n */\nexport interface ExtendedS3DestinationConfiguration {\n  __type?: \"ExtendedS3DestinationConfiguration\";\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupConfiguration?: S3DestinationConfiguration;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The Amazon S3 backup mode. After you create a delivery stream, you can update it to\n   *          enable Amazon S3 backup if it is disabled. If backup is enabled, you can't update the\n   *          delivery stream to disable it. </p>\n   */\n  S3BackupMode?: S3BackupMode | string;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The serializer, deserializer, and schema for converting data from the JSON format to\n   *          the Parquet or ORC format before writing it to Amazon S3.</p>\n   */\n  DataFormatConversionConfiguration?: DataFormatConversionConfiguration;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The buffering option.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *          UNCOMPRESSED.</p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n}\n\nexport namespace ExtendedS3DestinationConfiguration {\n  export const filterSensitiveLog = (obj: ExtendedS3DestinationConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ExtendedS3DestinationConfiguration =>\n    __isa(o, \"ExtendedS3DestinationConfiguration\");\n}\n\n/**\n * <p>Describes a destination in Amazon S3.</p>\n */\nexport interface ExtendedS3DestinationDescription {\n  __type?: \"ExtendedS3DestinationDescription\";\n  /**\n   * <p>The buffering option.</p>\n   */\n  BufferingHints: BufferingHints | undefined;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration: EncryptionConfiguration | undefined;\n\n  /**\n   * <p>The Amazon S3 backup mode.</p>\n   */\n  S3BackupMode?: S3BackupMode | string;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   */\n  CompressionFormat: CompressionFormat | string | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupDescription?: S3DestinationDescription;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The serializer, deserializer, and schema for converting data from the JSON format to\n   *          the Parquet or ORC format before writing it to Amazon S3.</p>\n   */\n  DataFormatConversionConfiguration?: DataFormatConversionConfiguration;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n}\n\nexport namespace ExtendedS3DestinationDescription {\n  export const filterSensitiveLog = (obj: ExtendedS3DestinationDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ExtendedS3DestinationDescription => __isa(o, \"ExtendedS3DestinationDescription\");\n}\n\n/**\n * <p>Describes an update for a destination in Amazon S3.</p>\n */\nexport interface ExtendedS3DestinationUpdate {\n  __type?: \"ExtendedS3DestinationUpdate\";\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The buffering option.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The Amazon S3 destination for backup.</p>\n   */\n  S3BackupUpdate?: S3DestinationUpdate;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>. </p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The serializer, deserializer, and schema for converting data from the JSON format to\n   *          the Parquet or ORC format before writing it to Amazon S3.</p>\n   */\n  DataFormatConversionConfiguration?: DataFormatConversionConfiguration;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>You can update a delivery stream to enable Amazon S3 backup if it is disabled. If\n   *          backup is enabled, you can't update the delivery stream to disable it. </p>\n   */\n  S3BackupMode?: S3BackupMode | string;\n}\n\nexport namespace ExtendedS3DestinationUpdate {\n  export const filterSensitiveLog = (obj: ExtendedS3DestinationUpdate): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ExtendedS3DestinationUpdate => __isa(o, \"ExtendedS3DestinationUpdate\");\n}\n\n/**\n * <p>Provides details in case one of the following operations fails due to an error related\n *          to KMS: <a>CreateDeliveryStream</a>, <a>DeleteDeliveryStream</a>,\n *             <a>StartDeliveryStreamEncryption</a>, <a>StopDeliveryStreamEncryption</a>.</p>\n */\nexport interface FailureDescription {\n  __type?: \"FailureDescription\";\n  /**\n   * <p>The type of error that caused the failure.</p>\n   */\n  Type: DeliveryStreamFailureType | string | undefined;\n\n  /**\n   * <p>A message providing details about the error that caused the failure.</p>\n   */\n  Details: string | undefined;\n}\n\nexport namespace FailureDescription {\n  export const filterSensitiveLog = (obj: FailureDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is FailureDescription => __isa(o, \"FailureDescription\");\n}\n\nexport type HECEndpointType = \"Event\" | \"Raw\";\n\n/**\n * <p>The native Hive / HCatalog JsonSerDe. Used by Kinesis Data Firehose for deserializing\n *          data, which means converting it from the JSON format in preparation for serializing it to\n *          the Parquet or ORC format. This is one of two deserializers you can choose, depending on\n *          which one offers the functionality you need. The other option is the OpenX SerDe.</p>\n */\nexport interface HiveJsonSerDe {\n  __type?: \"HiveJsonSerDe\";\n  /**\n   * <p>Indicates how you want Kinesis Data Firehose to parse the date and timestamps that\n   *          may be present in your input data JSON. To specify these format strings, follow the pattern\n   *          syntax of JodaTime's DateTimeFormat format strings. For more information, see <a href=\"https://www.joda.org/joda-time/apidocs/org/joda/time/format/DateTimeFormat.html\">Class DateTimeFormat</a>. You can also use the special value <code>millis</code> to\n   *          parse timestamps in epoch milliseconds. If you don't specify a format, Kinesis Data\n   *          Firehose uses <code>java.sql.Timestamp::valueOf</code> by default.</p>\n   */\n  TimestampFormats?: string[];\n}\n\nexport namespace HiveJsonSerDe {\n  export const filterSensitiveLog = (obj: HiveJsonSerDe): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is HiveJsonSerDe => __isa(o, \"HiveJsonSerDe\");\n}\n\n/**\n * <p>Describes the buffering options that can be applied before data is delivered to the HTTP\n *          endpoint destination. Kinesis Data Firehose treats these options as hints, and it might\n *          choose to use more optimal values. The <code>SizeInMBs</code> and\n *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n *          one of them, you must also provide a value for the other. </p>\n */\nexport interface HttpEndpointBufferingHints {\n  __type?: \"HttpEndpointBufferingHints\";\n  /**\n   * <p>Buffer incoming data for the specified period of time, in seconds, before delivering it\n   *          to the destination. The default value is 300 (5 minutes). </p>\n   */\n  IntervalInSeconds?: number;\n\n  /**\n   * <p>Buffer incoming data to the specified size, in MBs, before delivering it to the\n   *          destination. The default value is 5. </p>\n   *          <p>We recommend setting this parameter to a value greater than the amount of data you\n   *          typically ingest into the delivery stream in 10 seconds. For example, if you typically\n   *          ingest data at 1 MB/sec, the value should be 10 MB or higher. </p>\n   */\n  SizeInMBs?: number;\n}\n\nexport namespace HttpEndpointBufferingHints {\n  export const filterSensitiveLog = (obj: HttpEndpointBufferingHints): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is HttpEndpointBufferingHints => __isa(o, \"HttpEndpointBufferingHints\");\n}\n\n/**\n * <p>Describes the metadata that's delivered to the specified HTTP endpoint\n *          destination.</p>\n */\nexport interface HttpEndpointCommonAttribute {\n  __type?: \"HttpEndpointCommonAttribute\";\n  /**\n   * <p>The name of the HTTP endpoint common attribute.</p>\n   */\n  AttributeName: string | undefined;\n\n  /**\n   * <p>The value of the HTTP endpoint common attribute.</p>\n   */\n  AttributeValue: string | undefined;\n}\n\nexport namespace HttpEndpointCommonAttribute {\n  export const filterSensitiveLog = (obj: HttpEndpointCommonAttribute): any => ({\n    ...obj,\n    ...(obj.AttributeName && { AttributeName: SENSITIVE_STRING }),\n    ...(obj.AttributeValue && { AttributeValue: SENSITIVE_STRING }),\n  });\n  export const isa = (o: any): o is HttpEndpointCommonAttribute => __isa(o, \"HttpEndpointCommonAttribute\");\n}\n\n/**\n * <p>Describes the configuration of the HTTP endpoint to which Kinesis Firehose delivers\n *          data.</p>\n */\nexport interface HttpEndpointConfiguration {\n  __type?: \"HttpEndpointConfiguration\";\n  /**\n   * <p>The access key required for Kinesis Firehose to authenticate with the HTTP endpoint\n   *          selected as the destination.</p>\n   */\n  AccessKey?: string;\n\n  /**\n   * <p>The URL of the HTTP endpoint selected as the destination.</p>\n   */\n  Url: string | undefined;\n\n  /**\n   * <p>The name of the HTTP endpoint selected as the destination.</p>\n   */\n  Name?: string;\n}\n\nexport namespace HttpEndpointConfiguration {\n  export const filterSensitiveLog = (obj: HttpEndpointConfiguration): any => ({\n    ...obj,\n    ...(obj.AccessKey && { AccessKey: SENSITIVE_STRING }),\n    ...(obj.Url && { Url: SENSITIVE_STRING }),\n  });\n  export const isa = (o: any): o is HttpEndpointConfiguration => __isa(o, \"HttpEndpointConfiguration\");\n}\n\n/**\n * <p>Describes the HTTP endpoint selected as the destination. </p>\n */\nexport interface HttpEndpointDescription {\n  __type?: \"HttpEndpointDescription\";\n  /**\n   * <p>The name of the HTTP endpoint selected as the destination.</p>\n   */\n  Name?: string;\n\n  /**\n   * <p>The URL of the HTTP endpoint selected as the destination.</p>\n   */\n  Url?: string;\n}\n\nexport namespace HttpEndpointDescription {\n  export const filterSensitiveLog = (obj: HttpEndpointDescription): any => ({\n    ...obj,\n    ...(obj.Url && { Url: SENSITIVE_STRING }),\n  });\n  export const isa = (o: any): o is HttpEndpointDescription => __isa(o, \"HttpEndpointDescription\");\n}\n\n/**\n * <p>Describes the configuration of the HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointDestinationConfiguration {\n  __type?: \"HttpEndpointDestinationConfiguration\";\n  /**\n   * <p>Describes a data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n   *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n   *          receipt from the specified HTTP endpoint destination.</p>\n   */\n  RetryOptions?: HttpEndpointRetryOptions;\n\n  /**\n   * <p>The configuration of the HTTP endpoint selected as the destination.</p>\n   */\n  EndpointConfiguration: HttpEndpointConfiguration | undefined;\n\n  /**\n   * <p>The configuration of the requeste sent to the HTTP endpoint specified as the\n   *          destination.</p>\n   */\n  RequestConfiguration?: HttpEndpointRequestConfiguration;\n\n  /**\n   * <p>Describes the S3 bucket backup options for the data that Kinesis Data Firehose delivers\n   *          to the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or\n   *          only the documents that Kinesis Data Firehose could not deliver to the specified HTTP\n   *          endpoint destination (<code>FailedDataOnly</code>).</p>\n   */\n  S3BackupMode?: HttpEndpointS3BackupMode | string;\n\n  /**\n   * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery\n   *          stream needs.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Describes the configuration of a destination in Amazon S3.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The buffering options that can be used before data is delivered to the specified\n   *          destination. Kinesis Data Firehose treats these options as hints, and it might choose to\n   *          use more optimal values. The <code>SizeInMBs</code> and <code>IntervalInSeconds</code>\n   *          parameters are optional. However, if you specify a value for one of them, you must also\n   *          provide a value for the other. </p>\n   */\n  BufferingHints?: HttpEndpointBufferingHints;\n}\n\nexport namespace HttpEndpointDestinationConfiguration {\n  export const filterSensitiveLog = (obj: HttpEndpointDestinationConfiguration): any => ({\n    ...obj,\n    ...(obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration),\n    }),\n    ...(obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration),\n    }),\n  });\n  export const isa = (o: any): o is HttpEndpointDestinationConfiguration =>\n    __isa(o, \"HttpEndpointDestinationConfiguration\");\n}\n\n/**\n * <p>Describes the HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointDestinationDescription {\n  __type?: \"HttpEndpointDestinationDescription\";\n  /**\n   * <p>Describes a destination in Amazon S3.</p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n\n  /**\n   * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n   *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n   *          receipt from the specified HTTP endpoint destination.</p>\n   */\n  RetryOptions?: HttpEndpointRetryOptions;\n\n  /**\n   * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>Describes a data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery\n   *          stream needs.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Describes the S3 bucket backup options for the data that Kinesis Firehose delivers to\n   *          the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or only\n   *          the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint\n   *          destination (<code>FailedDataOnly</code>).</p>\n   */\n  S3BackupMode?: HttpEndpointS3BackupMode | string;\n\n  /**\n   * <p>Describes buffering options that can be applied to the data before it is delivered to\n   *          the HTTPS endpoint destination. Kinesis Data Firehose teats these options as hints, and it\n   *          might choose to use more optimal values. The <code>SizeInMBs</code> and\n   *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n   *          one of them, you must also provide a value for the other. </p>\n   */\n  BufferingHints?: HttpEndpointBufferingHints;\n\n  /**\n   * <p>The configuration of request sent to the HTTP endpoint specified as the\n   *          destination.</p>\n   */\n  RequestConfiguration?: HttpEndpointRequestConfiguration;\n\n  /**\n   * <p>The configuration of the specified HTTP endpoint destination.</p>\n   */\n  EndpointConfiguration?: HttpEndpointDescription;\n}\n\nexport namespace HttpEndpointDestinationDescription {\n  export const filterSensitiveLog = (obj: HttpEndpointDestinationDescription): any => ({\n    ...obj,\n    ...(obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration),\n    }),\n    ...(obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointDescription.filterSensitiveLog(obj.EndpointConfiguration),\n    }),\n  });\n  export const isa = (o: any): o is HttpEndpointDestinationDescription =>\n    __isa(o, \"HttpEndpointDestinationDescription\");\n}\n\n/**\n * <p>Updates the specified HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointDestinationUpdate {\n  __type?: \"HttpEndpointDestinationUpdate\";\n  /**\n   * <p>Describes the configuration of the HTTP endpoint destination.</p>\n   */\n  EndpointConfiguration?: HttpEndpointConfiguration;\n\n  /**\n   * <p>Describes a data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n   *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n   *          receipt from the specified HTTP endpoint destination.</p>\n   */\n  RetryOptions?: HttpEndpointRetryOptions;\n\n  /**\n   * <p>Kinesis Data Firehose uses this IAM role for all the permissions that the delivery\n   *          stream needs.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Describes buffering options that can be applied to the data before it is delivered to\n   *          the HTTPS endpoint destination. Kinesis Data Firehose teats these options as hints, and it\n   *          might choose to use more optimal values. The <code>SizeInMBs</code> and\n   *             <code>IntervalInSeconds</code> parameters are optional. However, if specify a value for\n   *          one of them, you must also provide a value for the other. </p>\n   */\n  BufferingHints?: HttpEndpointBufferingHints;\n\n  /**\n   * <p>The configuration of the request sent to the HTTP endpoint specified as the\n   *          destination.</p>\n   */\n  RequestConfiguration?: HttpEndpointRequestConfiguration;\n\n  /**\n   * <p>Describes the Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>Describes the S3 bucket backup options for the data that Kinesis Firehose delivers to\n   *          the HTTP endpoint destination. You can back up all documents (<code>AllData</code>) or only\n   *          the documents that Kinesis Data Firehose could not deliver to the specified HTTP endpoint\n   *          destination (<code>FailedDataOnly</code>).</p>\n   */\n  S3BackupMode?: HttpEndpointS3BackupMode | string;\n\n  /**\n   * <p>Describes an update for a destination in Amazon S3.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n}\n\nexport namespace HttpEndpointDestinationUpdate {\n  export const filterSensitiveLog = (obj: HttpEndpointDestinationUpdate): any => ({\n    ...obj,\n    ...(obj.EndpointConfiguration && {\n      EndpointConfiguration: HttpEndpointConfiguration.filterSensitiveLog(obj.EndpointConfiguration),\n    }),\n    ...(obj.RequestConfiguration && {\n      RequestConfiguration: HttpEndpointRequestConfiguration.filterSensitiveLog(obj.RequestConfiguration),\n    }),\n  });\n  export const isa = (o: any): o is HttpEndpointDestinationUpdate => __isa(o, \"HttpEndpointDestinationUpdate\");\n}\n\n/**\n * <p>The configuration of the HTTP endpoint request.</p>\n */\nexport interface HttpEndpointRequestConfiguration {\n  __type?: \"HttpEndpointRequestConfiguration\";\n  /**\n   * <p>Kinesis Data Firehose uses the content encoding to compress the body of a request before\n   *          sending the request to the destination. For more information, see <a href=\"https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Encoding\">Content-Encoding</a> in MDN Web Docs, the official Mozilla documentation.</p>\n   */\n  ContentEncoding?: ContentEncoding | string;\n\n  /**\n   * <p>Describes the metadata sent to the HTTP endpoint destination.</p>\n   */\n  CommonAttributes?: HttpEndpointCommonAttribute[];\n}\n\nexport namespace HttpEndpointRequestConfiguration {\n  export const filterSensitiveLog = (obj: HttpEndpointRequestConfiguration): any => ({\n    ...obj,\n    ...(obj.CommonAttributes && {\n      CommonAttributes: obj.CommonAttributes.map((item) => HttpEndpointCommonAttribute.filterSensitiveLog(item)),\n    }),\n  });\n  export const isa = (o: any): o is HttpEndpointRequestConfiguration => __isa(o, \"HttpEndpointRequestConfiguration\");\n}\n\n/**\n * <p>Describes the retry behavior in case Kinesis Data Firehose is unable to deliver data to\n *          the specified HTTP endpoint destination, or if it doesn't receive a valid acknowledgment of\n *          receipt from the specified HTTP endpoint destination.</p>\n */\nexport interface HttpEndpointRetryOptions {\n  __type?: \"HttpEndpointRetryOptions\";\n  /**\n   * <p>The total amount of time that Kinesis Data Firehose spends on retries. This duration\n   *          starts after the initial attempt to send data to the custom destination via HTTPS endpoint\n   *          fails. It doesn't include the periods during which Kinesis Data Firehose waits for\n   *          acknowledgment from the specified destination after each attempt. </p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace HttpEndpointRetryOptions {\n  export const filterSensitiveLog = (obj: HttpEndpointRetryOptions): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is HttpEndpointRetryOptions => __isa(o, \"HttpEndpointRetryOptions\");\n}\n\nexport type HttpEndpointS3BackupMode = \"AllData\" | \"FailedDataOnly\";\n\n/**\n * <p>Specifies the deserializer you want to use to convert the format of the input data.\n *          This parameter is required if <code>Enabled</code> is set to true.</p>\n */\nexport interface InputFormatConfiguration {\n  __type?: \"InputFormatConfiguration\";\n  /**\n   * <p>Specifies which deserializer to use. You can choose either the Apache Hive JSON SerDe\n   *          or the OpenX JSON SerDe. If both are non-null, the server rejects the request.</p>\n   */\n  Deserializer?: Deserializer;\n}\n\nexport namespace InputFormatConfiguration {\n  export const filterSensitiveLog = (obj: InputFormatConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is InputFormatConfiguration => __isa(o, \"InputFormatConfiguration\");\n}\n\n/**\n * <p>The specified input parameter has a value that is not valid.</p>\n */\nexport interface InvalidArgumentException extends __SmithyException, $MetadataBearer {\n  name: \"InvalidArgumentException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace InvalidArgumentException {\n  export const filterSensitiveLog = (obj: InvalidArgumentException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is InvalidArgumentException => __isa(o, \"InvalidArgumentException\");\n}\n\n/**\n * <p>Kinesis Data Firehose throws this exception when an attempt to put records or to start\n *          or stop delivery stream encryption fails. This happens when the KMS service throws one of\n *          the following exception types: <code>AccessDeniedException</code>,\n *             <code>InvalidStateException</code>, <code>DisabledException</code>, or\n *             <code>NotFoundException</code>.</p>\n */\nexport interface InvalidKMSResourceException extends __SmithyException, $MetadataBearer {\n  name: \"InvalidKMSResourceException\";\n  $fault: \"client\";\n  code?: string;\n  message?: string;\n}\n\nexport namespace InvalidKMSResourceException {\n  export const filterSensitiveLog = (obj: InvalidKMSResourceException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is InvalidKMSResourceException => __isa(o, \"InvalidKMSResourceException\");\n}\n\nexport enum KeyType {\n  AWS_OWNED_CMK = \"AWS_OWNED_CMK\",\n  CUSTOMER_MANAGED_CMK = \"CUSTOMER_MANAGED_CMK\",\n}\n\n/**\n * <p>The stream and role Amazon Resource Names (ARNs) for a Kinesis data stream used as\n *          the source for a delivery stream.</p>\n */\nexport interface KinesisStreamSourceConfiguration {\n  __type?: \"KinesisStreamSourceConfiguration\";\n  /**\n   * <p>The ARN of the role that provides access to the source Kinesis data stream. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam\">AWS Identity and Access Management (IAM) ARN Format</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ARN of the source Kinesis data stream. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams\">Amazon Kinesis Data Streams ARN Format</a>.</p>\n   */\n  KinesisStreamARN: string | undefined;\n}\n\nexport namespace KinesisStreamSourceConfiguration {\n  export const filterSensitiveLog = (obj: KinesisStreamSourceConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is KinesisStreamSourceConfiguration => __isa(o, \"KinesisStreamSourceConfiguration\");\n}\n\n/**\n * <p>Details about a Kinesis data stream used as the source for a Kinesis Data Firehose\n *          delivery stream.</p>\n */\nexport interface KinesisStreamSourceDescription {\n  __type?: \"KinesisStreamSourceDescription\";\n  /**\n   * <p>Kinesis Data Firehose starts retrieving records from the Kinesis data stream starting\n   *          with this timestamp.</p>\n   */\n  DeliveryStartTimestamp?: Date;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the source Kinesis data stream. For more\n   *          information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-kinesis-streams\">Amazon Kinesis Data Streams ARN Format</a>.</p>\n   */\n  KinesisStreamARN?: string;\n\n  /**\n   * <p>The ARN of the role used by the source Kinesis data stream. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html#arn-syntax-iam\">AWS Identity and Access Management (IAM) ARN Format</a>.</p>\n   */\n  RoleARN?: string;\n}\n\nexport namespace KinesisStreamSourceDescription {\n  export const filterSensitiveLog = (obj: KinesisStreamSourceDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is KinesisStreamSourceDescription => __isa(o, \"KinesisStreamSourceDescription\");\n}\n\n/**\n * <p>Describes an encryption key for a destination in Amazon S3.</p>\n */\nexport interface KMSEncryptionConfig {\n  __type?: \"KMSEncryptionConfig\";\n  /**\n   * <p>The Amazon Resource Name (ARN) of the encryption key. Must belong to the same AWS\n   *          Region as the destination Amazon S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  AWSKMSKeyARN: string | undefined;\n}\n\nexport namespace KMSEncryptionConfig {\n  export const filterSensitiveLog = (obj: KMSEncryptionConfig): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is KMSEncryptionConfig => __isa(o, \"KMSEncryptionConfig\");\n}\n\n/**\n * <p>You have already reached the limit for a requested resource.</p>\n */\nexport interface LimitExceededException extends __SmithyException, $MetadataBearer {\n  name: \"LimitExceededException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace LimitExceededException {\n  export const filterSensitiveLog = (obj: LimitExceededException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is LimitExceededException => __isa(o, \"LimitExceededException\");\n}\n\nexport interface ListDeliveryStreamsInput {\n  __type?: \"ListDeliveryStreamsInput\";\n  /**\n   * <p>The list of delivery streams returned by this call to\n   *             <code>ListDeliveryStreams</code> will start with the delivery stream whose name comes\n   *          alphabetically immediately after the name you specify in\n   *             <code>ExclusiveStartDeliveryStreamName</code>.</p>\n   */\n  ExclusiveStartDeliveryStreamName?: string;\n\n  /**\n   * <p>The delivery stream type. This can be one of the following values:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>DirectPut</code>: Provider applications access the delivery stream\n   *                directly.</p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>KinesisStreamAsSource</code>: The delivery stream uses a Kinesis data\n   *                stream as a source.</p>\n   *             </li>\n   *          </ul>\n   *          <p>This parameter is optional. If this parameter is omitted, delivery streams of all\n   *          types are returned.</p>\n   */\n  DeliveryStreamType?: DeliveryStreamType | string;\n\n  /**\n   * <p>The maximum number of delivery streams to list. The default value is 10.</p>\n   */\n  Limit?: number;\n}\n\nexport namespace ListDeliveryStreamsInput {\n  export const filterSensitiveLog = (obj: ListDeliveryStreamsInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ListDeliveryStreamsInput => __isa(o, \"ListDeliveryStreamsInput\");\n}\n\nexport interface ListDeliveryStreamsOutput {\n  __type?: \"ListDeliveryStreamsOutput\";\n  /**\n   * <p>Indicates whether there are more delivery streams available to list.</p>\n   */\n  HasMoreDeliveryStreams: boolean | undefined;\n\n  /**\n   * <p>The names of the delivery streams.</p>\n   */\n  DeliveryStreamNames: string[] | undefined;\n}\n\nexport namespace ListDeliveryStreamsOutput {\n  export const filterSensitiveLog = (obj: ListDeliveryStreamsOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ListDeliveryStreamsOutput => __isa(o, \"ListDeliveryStreamsOutput\");\n}\n\nexport interface ListTagsForDeliveryStreamInput {\n  __type?: \"ListTagsForDeliveryStreamInput\";\n  /**\n   * <p>The key to use as the starting point for the list of tags. If you set this parameter,\n   *             <code>ListTagsForDeliveryStream</code> gets all tags that occur after\n   *             <code>ExclusiveStartTagKey</code>.</p>\n   */\n  ExclusiveStartTagKey?: string;\n\n  /**\n   * <p>The number of tags to return. If this number is less than the total number of tags\n   *          associated with the delivery stream, <code>HasMoreTags</code> is set to <code>true</code>\n   *          in the response. To list additional tags, set <code>ExclusiveStartTagKey</code> to the last\n   *          key in the response. </p>\n   */\n  Limit?: number;\n\n  /**\n   * <p>The name of the delivery stream whose tags you want to list.</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace ListTagsForDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: ListTagsForDeliveryStreamInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ListTagsForDeliveryStreamInput => __isa(o, \"ListTagsForDeliveryStreamInput\");\n}\n\nexport interface ListTagsForDeliveryStreamOutput {\n  __type?: \"ListTagsForDeliveryStreamOutput\";\n  /**\n   * <p>A list of tags associated with <code>DeliveryStreamName</code>, starting with the\n   *          first tag after <code>ExclusiveStartTagKey</code> and up to the specified\n   *             <code>Limit</code>.</p>\n   */\n  Tags: Tag[] | undefined;\n\n  /**\n   * <p>If this is <code>true</code> in the response, more tags are available. To list the\n   *          remaining tags, set <code>ExclusiveStartTagKey</code> to the key of the last tag returned\n   *          and call <code>ListTagsForDeliveryStream</code> again.</p>\n   */\n  HasMoreTags: boolean | undefined;\n}\n\nexport namespace ListTagsForDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: ListTagsForDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ListTagsForDeliveryStreamOutput => __isa(o, \"ListTagsForDeliveryStreamOutput\");\n}\n\nexport type NoEncryptionConfig = \"NoEncryption\";\n\n/**\n * <p>The OpenX SerDe. Used by Kinesis Data Firehose for deserializing data, which means\n *          converting it from the JSON format in preparation for serializing it to the Parquet or ORC\n *          format. This is one of two deserializers you can choose, depending on which one offers the\n *          functionality you need. The other option is the native Hive / HCatalog JsonSerDe.</p>\n */\nexport interface OpenXJsonSerDe {\n  __type?: \"OpenXJsonSerDe\";\n  /**\n   * <p>Maps column names to JSON keys that aren't identical to the column names. This is\n   *          useful when the JSON contains keys that are Hive keywords. For example,\n   *             <code>timestamp</code> is a Hive keyword. If you have a JSON key named\n   *             <code>timestamp</code>, set this parameter to <code>{\"ts\": \"timestamp\"}</code> to map\n   *          this key to a column named <code>ts</code>.</p>\n   */\n  ColumnToJsonKeyMappings?: { [key: string]: string };\n\n  /**\n   * <p>When set to <code>true</code>, which is the default, Kinesis Data Firehose converts\n   *          JSON keys to lowercase before deserializing them.</p>\n   */\n  CaseInsensitive?: boolean;\n\n  /**\n   * <p>When set to <code>true</code>, specifies that the names of the keys include dots and\n   *          that you want Kinesis Data Firehose to replace them with underscores. This is useful\n   *          because Apache Hive does not allow dots in column names. For example, if the JSON contains\n   *          a key whose name is \"a.b\", you can define the column name to be \"a_b\" when using this\n   *          option.</p>\n   *          <p>The default is <code>false</code>.</p>\n   */\n  ConvertDotsInJsonKeysToUnderscores?: boolean;\n}\n\nexport namespace OpenXJsonSerDe {\n  export const filterSensitiveLog = (obj: OpenXJsonSerDe): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is OpenXJsonSerDe => __isa(o, \"OpenXJsonSerDe\");\n}\n\nexport enum OrcCompression {\n  NONE = \"NONE\",\n  SNAPPY = \"SNAPPY\",\n  ZLIB = \"ZLIB\",\n}\n\nexport enum OrcFormatVersion {\n  V0_11 = \"V0_11\",\n  V0_12 = \"V0_12\",\n}\n\n/**\n * <p>A serializer to use for converting data to the ORC format before storing it in Amazon\n *          S3. For more information, see <a href=\"https://orc.apache.org/docs/\">Apache\n *          ORC</a>.</p>\n */\nexport interface OrcSerDe {\n  __type?: \"OrcSerDe\";\n  /**\n   * <p>The column names for which you want Kinesis Data Firehose to create bloom filters. The\n   *          default is <code>null</code>.</p>\n   */\n  BloomFilterColumns?: string[];\n\n  /**\n   * <p>A number between 0 and 1 that defines the tolerance for block padding as a decimal\n   *          fraction of stripe size. The default value is 0.05, which means 5 percent of stripe\n   *          size.</p>\n   *          <p>For the default values of 64 MiB ORC stripes and 256 MiB HDFS blocks, the default block\n   *          padding tolerance of 5 percent reserves a maximum of 3.2 MiB for padding within the 256 MiB\n   *          block. In such a case, if the available size within the block is more than 3.2 MiB, a new,\n   *          smaller stripe is inserted to fit within that space. This ensures that no stripe crosses\n   *          block boundaries and causes remote reads within a node-local task.</p>\n   *          <p>Kinesis Data Firehose ignores this parameter when <a>OrcSerDe$EnablePadding</a> is <code>false</code>.</p>\n   */\n  PaddingTolerance?: number;\n\n  /**\n   * <p>Represents the fraction of the total number of non-null rows. To turn off dictionary\n   *          encoding, set this fraction to a number that is less than the number of distinct keys in a\n   *          dictionary. To always use dictionary encoding, set this threshold to 1.</p>\n   */\n  DictionaryKeyThreshold?: number;\n\n  /**\n   * <p>The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to\n   *          copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the\n   *          minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.</p>\n   */\n  BlockSizeBytes?: number;\n\n  /**\n   * <p>The number of rows between index entries. The default is 10,000 and the minimum is\n   *          1,000.</p>\n   */\n  RowIndexStride?: number;\n\n  /**\n   * <p>The number of bytes in each stripe. The default is 64 MiB and the minimum is 8\n   *          MiB.</p>\n   */\n  StripeSizeBytes?: number;\n\n  /**\n   * <p>The version of the file to write. The possible values are <code>V0_11</code> and\n   *             <code>V0_12</code>. The default is <code>V0_12</code>.</p>\n   */\n  FormatVersion?: OrcFormatVersion | string;\n\n  /**\n   * <p>The compression code to use over data blocks. The default is <code>SNAPPY</code>.</p>\n   */\n  Compression?: OrcCompression | string;\n\n  /**\n   * <p>The Bloom filter false positive probability (FPP). The lower the FPP, the bigger the\n   *          Bloom filter. The default value is 0.05, the minimum is 0, and the maximum is 1.</p>\n   */\n  BloomFilterFalsePositiveProbability?: number;\n\n  /**\n   * <p>Set this to <code>true</code> to indicate that you want stripes to be padded to the HDFS\n   *          block boundaries. This is useful if you intend to copy the data from Amazon S3 to HDFS\n   *          before querying. The default is <code>false</code>.</p>\n   */\n  EnablePadding?: boolean;\n}\n\nexport namespace OrcSerDe {\n  export const filterSensitiveLog = (obj: OrcSerDe): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is OrcSerDe => __isa(o, \"OrcSerDe\");\n}\n\n/**\n * <p>Specifies the serializer that you want Kinesis Data Firehose to use to convert the\n *          format of your data before it writes it to Amazon S3. This parameter is required if\n *             <code>Enabled</code> is set to true.</p>\n */\nexport interface OutputFormatConfiguration {\n  __type?: \"OutputFormatConfiguration\";\n  /**\n   * <p>Specifies which serializer to use. You can choose either the ORC SerDe or the Parquet\n   *          SerDe. If both are non-null, the server rejects the request.</p>\n   */\n  Serializer?: Serializer;\n}\n\nexport namespace OutputFormatConfiguration {\n  export const filterSensitiveLog = (obj: OutputFormatConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is OutputFormatConfiguration => __isa(o, \"OutputFormatConfiguration\");\n}\n\nexport enum ParquetCompression {\n  GZIP = \"GZIP\",\n  SNAPPY = \"SNAPPY\",\n  UNCOMPRESSED = \"UNCOMPRESSED\",\n}\n\n/**\n * <p>A serializer to use for converting data to the Parquet format before storing it in\n *          Amazon S3. For more information, see <a href=\"https://parquet.apache.org/documentation/latest/\">Apache Parquet</a>.</p>\n */\nexport interface ParquetSerDe {\n  __type?: \"ParquetSerDe\";\n  /**\n   * <p>The compression code to use over data blocks. The possible values are\n   *             <code>UNCOMPRESSED</code>, <code>SNAPPY</code>, and <code>GZIP</code>, with the default\n   *          being <code>SNAPPY</code>. Use <code>SNAPPY</code> for higher decompression speed. Use\n   *             <code>GZIP</code> if the compression ratio is more important than speed.</p>\n   */\n  Compression?: ParquetCompression | string;\n\n  /**\n   * <p>The Hadoop Distributed File System (HDFS) block size. This is useful if you intend to\n   *          copy the data from Amazon S3 to HDFS before querying. The default is 256 MiB and the\n   *          minimum is 64 MiB. Kinesis Data Firehose uses this value for padding calculations.</p>\n   */\n  BlockSizeBytes?: number;\n\n  /**\n   * <p>The Parquet page size. Column chunks are divided into pages. A page is conceptually an\n   *          indivisible unit (in terms of compression and encoding). The minimum value is 64 KiB and\n   *          the default is 1 MiB.</p>\n   */\n  PageSizeBytes?: number;\n\n  /**\n   * <p>Indicates the version of row format to output. The possible values are <code>V1</code>\n   *          and <code>V2</code>. The default is <code>V1</code>.</p>\n   */\n  WriterVersion?: ParquetWriterVersion | string;\n\n  /**\n   * <p>Indicates whether to enable dictionary compression.</p>\n   */\n  EnableDictionaryCompression?: boolean;\n\n  /**\n   * <p>The maximum amount of padding to apply. This is useful if you intend to copy the data\n   *          from Amazon S3 to HDFS before querying. The default is 0.</p>\n   */\n  MaxPaddingBytes?: number;\n}\n\nexport namespace ParquetSerDe {\n  export const filterSensitiveLog = (obj: ParquetSerDe): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ParquetSerDe => __isa(o, \"ParquetSerDe\");\n}\n\nexport enum ParquetWriterVersion {\n  V1 = \"V1\",\n  V2 = \"V2\",\n}\n\n/**\n * <p>Describes a data processing configuration.</p>\n */\nexport interface ProcessingConfiguration {\n  __type?: \"ProcessingConfiguration\";\n  /**\n   * <p>Enables or disables data processing.</p>\n   */\n  Enabled?: boolean;\n\n  /**\n   * <p>The data processors.</p>\n   */\n  Processors?: Processor[];\n}\n\nexport namespace ProcessingConfiguration {\n  export const filterSensitiveLog = (obj: ProcessingConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ProcessingConfiguration => __isa(o, \"ProcessingConfiguration\");\n}\n\n/**\n * <p>Describes a data processor.</p>\n */\nexport interface Processor {\n  __type?: \"Processor\";\n  /**\n   * <p>The type of processor.</p>\n   */\n  Type: ProcessorType | string | undefined;\n\n  /**\n   * <p>The processor parameters.</p>\n   */\n  Parameters?: ProcessorParameter[];\n}\n\nexport namespace Processor {\n  export const filterSensitiveLog = (obj: Processor): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is Processor => __isa(o, \"Processor\");\n}\n\n/**\n * <p>Describes the processor parameter.</p>\n */\nexport interface ProcessorParameter {\n  __type?: \"ProcessorParameter\";\n  /**\n   * <p>The name of the parameter.</p>\n   */\n  ParameterName: ProcessorParameterName | string | undefined;\n\n  /**\n   * <p>The parameter value.</p>\n   */\n  ParameterValue: string | undefined;\n}\n\nexport namespace ProcessorParameter {\n  export const filterSensitiveLog = (obj: ProcessorParameter): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ProcessorParameter => __isa(o, \"ProcessorParameter\");\n}\n\nexport enum ProcessorParameterName {\n  BUFFER_INTERVAL_IN_SECONDS = \"BufferIntervalInSeconds\",\n  BUFFER_SIZE_IN_MB = \"BufferSizeInMBs\",\n  LAMBDA_ARN = \"LambdaArn\",\n  LAMBDA_NUMBER_OF_RETRIES = \"NumberOfRetries\",\n  ROLE_ARN = \"RoleArn\",\n}\n\nexport type ProcessorType = \"Lambda\";\n\nexport interface PutRecordBatchInput {\n  __type?: \"PutRecordBatchInput\";\n  /**\n   * <p>One or more records.</p>\n   */\n  Records: _Record[] | undefined;\n\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace PutRecordBatchInput {\n  export const filterSensitiveLog = (obj: PutRecordBatchInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is PutRecordBatchInput => __isa(o, \"PutRecordBatchInput\");\n}\n\nexport interface PutRecordBatchOutput {\n  __type?: \"PutRecordBatchOutput\";\n  /**\n   * <p>Indicates whether server-side encryption (SSE) was enabled during this operation.</p>\n   */\n  Encrypted?: boolean;\n\n  /**\n   * <p>The number of records that might have failed processing. This number might be greater\n   *          than 0 even if the <a>PutRecordBatch</a> call succeeds. Check\n   *             <code>FailedPutCount</code> to determine whether there are records that you need to\n   *          resend.</p>\n   */\n  FailedPutCount: number | undefined;\n\n  /**\n   * <p>The results array. For each record, the index of the response element is the same as\n   *          the index used in the request array.</p>\n   */\n  RequestResponses: PutRecordBatchResponseEntry[] | undefined;\n}\n\nexport namespace PutRecordBatchOutput {\n  export const filterSensitiveLog = (obj: PutRecordBatchOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is PutRecordBatchOutput => __isa(o, \"PutRecordBatchOutput\");\n}\n\n/**\n * <p>Contains the result for an individual record from a <a>PutRecordBatch</a>\n *          request. If the record is successfully added to your delivery stream, it receives a record\n *          ID. If the record fails to be added to your delivery stream, the result includes an error\n *          code and an error message.</p>\n */\nexport interface PutRecordBatchResponseEntry {\n  __type?: \"PutRecordBatchResponseEntry\";\n  /**\n   * <p>The error message for an individual record result.</p>\n   */\n  ErrorMessage?: string;\n\n  /**\n   * <p>The ID of the record.</p>\n   */\n  RecordId?: string;\n\n  /**\n   * <p>The error code for an individual record result.</p>\n   */\n  ErrorCode?: string;\n}\n\nexport namespace PutRecordBatchResponseEntry {\n  export const filterSensitiveLog = (obj: PutRecordBatchResponseEntry): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is PutRecordBatchResponseEntry => __isa(o, \"PutRecordBatchResponseEntry\");\n}\n\nexport interface PutRecordInput {\n  __type?: \"PutRecordInput\";\n  /**\n   * <p>The record.</p>\n   */\n  Record: _Record | undefined;\n\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace PutRecordInput {\n  export const filterSensitiveLog = (obj: PutRecordInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is PutRecordInput => __isa(o, \"PutRecordInput\");\n}\n\nexport interface PutRecordOutput {\n  __type?: \"PutRecordOutput\";\n  /**\n   * <p>The ID of the record.</p>\n   */\n  RecordId: string | undefined;\n\n  /**\n   * <p>Indicates whether server-side encryption (SSE) was enabled during this operation.</p>\n   */\n  Encrypted?: boolean;\n}\n\nexport namespace PutRecordOutput {\n  export const filterSensitiveLog = (obj: PutRecordOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is PutRecordOutput => __isa(o, \"PutRecordOutput\");\n}\n\n/**\n * <p>The unit of data in a delivery stream.</p>\n */\nexport interface _Record {\n  __type?: \"Record\";\n  /**\n   * <p>The data blob, which is base64-encoded when the blob is serialized. The maximum size\n   *          of the data blob, before base64-encoding, is 1,000 KiB.</p>\n   */\n  Data: Uint8Array | undefined;\n}\n\nexport namespace _Record {\n  export const filterSensitiveLog = (obj: _Record): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is _Record => __isa(o, \"Record\");\n}\n\n/**\n * <p>Describes the configuration of a destination in Amazon Redshift.</p>\n */\nexport interface RedshiftDestinationConfiguration {\n  __type?: \"RedshiftDestinationConfiguration\";\n  /**\n   * <p>The configuration for the intermediate Amazon S3 location from which Amazon Redshift\n   *          obtains data. Restrictions are described in the topic for <a>CreateDeliveryStream</a>.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          in <code>RedshiftDestinationConfiguration.S3Configuration</code> because the Amazon\n   *          Redshift <code>COPY</code> operation that reads from the S3 bucket doesn't support these\n   *          compression formats.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The name of the user.</p>\n   */\n  Username: string | undefined;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupConfiguration?: S3DestinationConfiguration;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The database connection string.</p>\n   */\n  ClusterJDBCURL: string | undefined;\n\n  /**\n   * <p>The user password.</p>\n   */\n  Password: string | undefined;\n\n  /**\n   * <p>The Amazon S3 backup mode. After you create a delivery stream, you can update it to\n   *          enable Amazon S3 backup if it is disabled. If backup is enabled, you can't update the\n   *          delivery stream to disable it. </p>\n   */\n  S3BackupMode?: RedshiftS3BackupMode | string;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon Redshift. Default value is 3600 (60 minutes).</p>\n   */\n  RetryOptions?: RedshiftRetryOptions;\n\n  /**\n   * <p>The <code>COPY</code> command.</p>\n   */\n  CopyCommand: CopyCommand | undefined;\n}\n\nexport namespace RedshiftDestinationConfiguration {\n  export const filterSensitiveLog = (obj: RedshiftDestinationConfiguration): any => ({\n    ...obj,\n    ...(obj.Username && { Username: SENSITIVE_STRING }),\n    ...(obj.Password && { Password: SENSITIVE_STRING }),\n  });\n  export const isa = (o: any): o is RedshiftDestinationConfiguration => __isa(o, \"RedshiftDestinationConfiguration\");\n}\n\n/**\n * <p>Describes a destination in Amazon Redshift.</p>\n */\nexport interface RedshiftDestinationDescription {\n  __type?: \"RedshiftDestinationDescription\";\n  /**\n   * <p>The Amazon S3 backup mode.</p>\n   */\n  S3BackupMode?: RedshiftS3BackupMode | string;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   */\n  S3DestinationDescription: S3DestinationDescription | undefined;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon Redshift. Default value is 3600 (60 minutes).</p>\n   */\n  RetryOptions?: RedshiftRetryOptions;\n\n  /**\n   * <p>The <code>COPY</code> command.</p>\n   */\n  CopyCommand: CopyCommand | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The name of the user.</p>\n   */\n  Username: string | undefined;\n\n  /**\n   * <p>The database connection string.</p>\n   */\n  ClusterJDBCURL: string | undefined;\n\n  /**\n   * <p>The configuration for backup in Amazon S3.</p>\n   */\n  S3BackupDescription?: S3DestinationDescription;\n}\n\nexport namespace RedshiftDestinationDescription {\n  export const filterSensitiveLog = (obj: RedshiftDestinationDescription): any => ({\n    ...obj,\n    ...(obj.Username && { Username: SENSITIVE_STRING }),\n  });\n  export const isa = (o: any): o is RedshiftDestinationDescription => __isa(o, \"RedshiftDestinationDescription\");\n}\n\n/**\n * <p>Describes an update for a destination in Amazon Redshift.</p>\n */\nexport interface RedshiftDestinationUpdate {\n  __type?: \"RedshiftDestinationUpdate\";\n  /**\n   * <p>The Amazon S3 destination for backup.</p>\n   */\n  S3BackupUpdate?: S3DestinationUpdate;\n\n  /**\n   * <p>The <code>COPY</code> command.</p>\n   */\n  CopyCommand?: CopyCommand;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver documents to\n   *          Amazon Redshift. Default value is 3600 (60 minutes).</p>\n   */\n  RetryOptions?: RedshiftRetryOptions;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The name of the user.</p>\n   */\n  Username?: string;\n\n  /**\n   * <p>The Amazon S3 destination.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          in <code>RedshiftDestinationUpdate.S3Update</code> because the Amazon Redshift\n   *             <code>COPY</code> operation that reads from the S3 bucket doesn't support these\n   *          compression formats.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n\n  /**\n   * <p>The user password.</p>\n   */\n  Password?: string;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The database connection string.</p>\n   */\n  ClusterJDBCURL?: string;\n\n  /**\n   * <p>You can update a delivery stream to enable Amazon S3 backup if it is disabled. If\n   *          backup is enabled, you can't update the delivery stream to disable it. </p>\n   */\n  S3BackupMode?: RedshiftS3BackupMode | string;\n}\n\nexport namespace RedshiftDestinationUpdate {\n  export const filterSensitiveLog = (obj: RedshiftDestinationUpdate): any => ({\n    ...obj,\n    ...(obj.Username && { Username: SENSITIVE_STRING }),\n    ...(obj.Password && { Password: SENSITIVE_STRING }),\n  });\n  export const isa = (o: any): o is RedshiftDestinationUpdate => __isa(o, \"RedshiftDestinationUpdate\");\n}\n\n/**\n * <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver\n *          documents to Amazon Redshift.</p>\n */\nexport interface RedshiftRetryOptions {\n  __type?: \"RedshiftRetryOptions\";\n  /**\n   * <p>The length of time during which Kinesis Data Firehose retries delivery after a\n   *          failure, starting from the initial request and including the first attempt. The default\n   *          value is 3600 seconds (60 minutes). Kinesis Data Firehose does not retry if the value of\n   *             <code>DurationInSeconds</code> is 0 (zero) or if the first delivery attempt takes longer\n   *          than the current value.</p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace RedshiftRetryOptions {\n  export const filterSensitiveLog = (obj: RedshiftRetryOptions): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is RedshiftRetryOptions => __isa(o, \"RedshiftRetryOptions\");\n}\n\nexport type RedshiftS3BackupMode = \"Disabled\" | \"Enabled\";\n\n/**\n * <p>The resource is already in use and not available for this operation.</p>\n */\nexport interface ResourceInUseException extends __SmithyException, $MetadataBearer {\n  name: \"ResourceInUseException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ResourceInUseException {\n  export const filterSensitiveLog = (obj: ResourceInUseException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ResourceInUseException => __isa(o, \"ResourceInUseException\");\n}\n\n/**\n * <p>The specified resource could not be found.</p>\n */\nexport interface ResourceNotFoundException extends __SmithyException, $MetadataBearer {\n  name: \"ResourceNotFoundException\";\n  $fault: \"client\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ResourceNotFoundException {\n  export const filterSensitiveLog = (obj: ResourceNotFoundException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ResourceNotFoundException => __isa(o, \"ResourceNotFoundException\");\n}\n\nexport type S3BackupMode = \"Disabled\" | \"Enabled\";\n\n/**\n * <p>Describes the configuration of a destination in Amazon S3.</p>\n */\nexport interface S3DestinationConfiguration {\n  __type?: \"S3DestinationConfiguration\";\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          for Amazon Redshift destinations because they are not supported by the Amazon Redshift\n   *             <code>COPY</code> operation that reads from the S3 bucket.</p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>The buffering option. If no value is specified, <code>BufferingHints</code> object\n   *          default values are used.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n}\n\nexport namespace S3DestinationConfiguration {\n  export const filterSensitiveLog = (obj: S3DestinationConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is S3DestinationConfiguration => __isa(o, \"S3DestinationConfiguration\");\n}\n\n/**\n * <p>Describes a destination in Amazon S3.</p>\n */\nexport interface S3DestinationDescription {\n  __type?: \"S3DestinationDescription\";\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN: string | undefined;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   */\n  CompressionFormat: CompressionFormat | string | undefined;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n\n  /**\n   * <p>The buffering option. If no value is specified, <code>BufferingHints</code> object\n   *          default values are used.</p>\n   */\n  BufferingHints: BufferingHints | undefined;\n\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration: EncryptionConfiguration | undefined;\n}\n\nexport namespace S3DestinationDescription {\n  export const filterSensitiveLog = (obj: S3DestinationDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is S3DestinationDescription => __isa(o, \"S3DestinationDescription\");\n}\n\n/**\n * <p>Describes an update for a destination in Amazon S3.</p>\n */\nexport interface S3DestinationUpdate {\n  __type?: \"S3DestinationUpdate\";\n  /**\n   * <p>The encryption configuration. If no value is specified, the default is no\n   *          encryption.</p>\n   */\n  EncryptionConfiguration?: EncryptionConfiguration;\n\n  /**\n   * <p>The buffering option. If no value is specified, <code>BufferingHints</code> object\n   *          default values are used.</p>\n   */\n  BufferingHints?: BufferingHints;\n\n  /**\n   * <p>The Amazon Resource Name (ARN) of the AWS credentials. For more information, see\n   *             <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>The ARN of the S3 bucket. For more information, see <a href=\"https://docs.aws.amazon.com/general/latest/gr/aws-arns-and-namespaces.html\">Amazon\n   *             Resource Names (ARNs) and AWS Service Namespaces</a>.</p>\n   */\n  BucketARN?: string;\n\n  /**\n   * <p>A prefix that Kinesis Data Firehose evaluates and adds to failed records before writing\n   *          them to S3. This prefix appears immediately following the bucket name. For information\n   *          about how to specify this prefix, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  ErrorOutputPrefix?: string;\n\n  /**\n   * <p>The compression format. If no value is specified, the default is\n   *             <code>UNCOMPRESSED</code>.</p>\n   *          <p>The compression formats <code>SNAPPY</code> or <code>ZIP</code> cannot be specified\n   *          for Amazon Redshift destinations because they are not supported by the Amazon Redshift\n   *             <code>COPY</code> operation that reads from the S3 bucket.</p>\n   */\n  CompressionFormat?: CompressionFormat | string;\n\n  /**\n   * <p>The CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The \"YYYY/MM/DD/HH\" time format prefix is automatically used for delivered Amazon S3\n   *          files. You can also specify a custom prefix, as described in <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/s3-prefixes.html\">Custom Prefixes\n   *             for Amazon S3 Objects</a>.</p>\n   */\n  Prefix?: string;\n}\n\nexport namespace S3DestinationUpdate {\n  export const filterSensitiveLog = (obj: S3DestinationUpdate): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is S3DestinationUpdate => __isa(o, \"S3DestinationUpdate\");\n}\n\n/**\n * <p>Specifies the schema to which you want Kinesis Data Firehose to configure your data\n *          before it writes it to Amazon S3. This parameter is required if <code>Enabled</code> is set\n *          to true.</p>\n */\nexport interface SchemaConfiguration {\n  __type?: \"SchemaConfiguration\";\n  /**\n   * <p>Specifies the name of the AWS Glue database that contains the schema for the output\n   *          data.</p>\n   */\n  DatabaseName?: string;\n\n  /**\n   * <p>The role that Kinesis Data Firehose can use to access AWS Glue. This role must be in\n   *          the same account you use for Kinesis Data Firehose. Cross-account roles aren't\n   *          allowed.</p>\n   */\n  RoleARN?: string;\n\n  /**\n   * <p>Specifies the AWS Glue table that contains the column information that constitutes your\n   *          data schema.</p>\n   */\n  TableName?: string;\n\n  /**\n   * <p>If you don't specify an AWS Region, the default is the current Region.</p>\n   */\n  Region?: string;\n\n  /**\n   * <p>The ID of the AWS Glue Data Catalog. If you don't supply this, the AWS account ID is\n   *          used by default.</p>\n   */\n  CatalogId?: string;\n\n  /**\n   * <p>Specifies the table version for the output data schema. If you don't specify this\n   *          version ID, or if you set it to <code>LATEST</code>, Kinesis Data Firehose uses the most\n   *          recent version. This means that any updates to the table are automatically picked\n   *          up.</p>\n   */\n  VersionId?: string;\n}\n\nexport namespace SchemaConfiguration {\n  export const filterSensitiveLog = (obj: SchemaConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is SchemaConfiguration => __isa(o, \"SchemaConfiguration\");\n}\n\n/**\n * <p>The serializer that you want Kinesis Data Firehose to use to convert data to the target\n *          format before writing it to Amazon S3. Kinesis Data Firehose supports two types of\n *          serializers: the <a href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/orc/OrcSerde.html\">ORC SerDe</a> and the <a href=\"https://hive.apache.org/javadocs/r1.2.2/api/org/apache/hadoop/hive/ql/io/parquet/serde/ParquetHiveSerDe.html\">Parquet SerDe</a>.</p>\n */\nexport interface Serializer {\n  __type?: \"Serializer\";\n  /**\n   * <p>A serializer to use for converting data to the ORC format before storing it in Amazon\n   *          S3. For more information, see <a href=\"https://orc.apache.org/docs/\">Apache\n   *          ORC</a>.</p>\n   */\n  OrcSerDe?: OrcSerDe;\n\n  /**\n   * <p>A serializer to use for converting data to the Parquet format before storing it in\n   *          Amazon S3. For more information, see <a href=\"https://parquet.apache.org/documentation/latest/\">Apache Parquet</a>.</p>\n   */\n  ParquetSerDe?: ParquetSerDe;\n}\n\nexport namespace Serializer {\n  export const filterSensitiveLog = (obj: Serializer): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is Serializer => __isa(o, \"Serializer\");\n}\n\n/**\n * <p>The service is unavailable. Back off and retry the operation. If you continue to see\n *          the exception, throughput limits for the delivery stream may have been exceeded. For more\n *          information about limits and how to request an increase, see <a href=\"https://docs.aws.amazon.com/firehose/latest/dev/limits.html\">Amazon Kinesis Data Firehose\n *          Limits</a>.</p>\n */\nexport interface ServiceUnavailableException extends __SmithyException, $MetadataBearer {\n  name: \"ServiceUnavailableException\";\n  $fault: \"server\";\n  /**\n   * <p>A message that provides information about the error.</p>\n   */\n  message?: string;\n}\n\nexport namespace ServiceUnavailableException {\n  export const filterSensitiveLog = (obj: ServiceUnavailableException): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is ServiceUnavailableException => __isa(o, \"ServiceUnavailableException\");\n}\n\n/**\n * <p>Details about a Kinesis data stream used as the source for a Kinesis Data Firehose\n *          delivery stream.</p>\n */\nexport interface SourceDescription {\n  __type?: \"SourceDescription\";\n  /**\n   * <p>The <a>KinesisStreamSourceDescription</a> value for the source Kinesis\n   *          data stream.</p>\n   */\n  KinesisStreamSourceDescription?: KinesisStreamSourceDescription;\n}\n\nexport namespace SourceDescription {\n  export const filterSensitiveLog = (obj: SourceDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is SourceDescription => __isa(o, \"SourceDescription\");\n}\n\n/**\n * <p>Describes the configuration of a destination in Splunk.</p>\n */\nexport interface SplunkDestinationConfiguration {\n  __type?: \"SplunkDestinationConfiguration\";\n  /**\n   * <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from\n   *          Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose\n   *          either tries to send the data again or considers it an error, based on your retry\n   *          settings.</p>\n   */\n  HECAcknowledgmentTimeoutInSeconds?: number;\n\n  /**\n   * <p>This is a GUID that you obtain from your Splunk cluster when you create a new HEC\n   *          endpoint.</p>\n   */\n  HECToken: string | undefined;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk,\n   *          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>\n   */\n  RetryOptions?: SplunkRetryOptions;\n\n  /**\n   * <p>This type can be either \"Raw\" or \"Event.\"</p>\n   */\n  HECEndpointType: HECEndpointType | string | undefined;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>Defines how documents should be delivered to Amazon S3. When set to\n   *             <code>FailedEventsOnly</code>, Kinesis Data Firehose writes any data that could not be\n   *          indexed to the configured Amazon S3 destination. When set to <code>AllEvents</code>,\n   *          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed\n   *          documents to Amazon S3. The default value is <code>FailedEventsOnly</code>.</p>\n   *          <p>You can update this backup mode from <code>FailedEventsOnly</code> to\n   *             <code>AllEvents</code>. You can't update it from <code>AllEvents</code> to\n   *             <code>FailedEventsOnly</code>.</p>\n   */\n  S3BackupMode?: SplunkS3BackupMode | string;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The configuration for the backup Amazon S3 location.</p>\n   */\n  S3Configuration: S3DestinationConfiguration | undefined;\n\n  /**\n   * <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your\n   *          data.</p>\n   */\n  HECEndpoint: string | undefined;\n}\n\nexport namespace SplunkDestinationConfiguration {\n  export const filterSensitiveLog = (obj: SplunkDestinationConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is SplunkDestinationConfiguration => __isa(o, \"SplunkDestinationConfiguration\");\n}\n\n/**\n * <p>Describes a destination in Splunk.</p>\n */\nexport interface SplunkDestinationDescription {\n  __type?: \"SplunkDestinationDescription\";\n  /**\n   * <p>Defines how documents should be delivered to Amazon S3. When set to\n   *             <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any data that could not\n   *          be indexed to the configured Amazon S3 destination. When set to <code>AllDocuments</code>,\n   *          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed\n   *          documents to Amazon S3. Default value is <code>FailedDocumentsOnly</code>. </p>\n   */\n  S3BackupMode?: SplunkS3BackupMode | string;\n\n  /**\n   * <p>A GUID you obtain from your Splunk cluster when you create a new HEC\n   *          endpoint.</p>\n   */\n  HECToken?: string;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk\n   *          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>\n   */\n  RetryOptions?: SplunkRetryOptions;\n\n  /**\n   * <p>This type can be either \"Raw\" or \"Event.\"</p>\n   */\n  HECEndpointType?: HECEndpointType | string;\n\n  /**\n   * <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from\n   *          Splunk after it sends it data. At the end of the timeout period, Kinesis Data Firehose\n   *          either tries to send the data again or considers it an error, based on your retry\n   *          settings.</p>\n   */\n  HECAcknowledgmentTimeoutInSeconds?: number;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your\n   *          data.</p>\n   */\n  HECEndpoint?: string;\n\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The Amazon S3 destination.></p>\n   */\n  S3DestinationDescription?: S3DestinationDescription;\n}\n\nexport namespace SplunkDestinationDescription {\n  export const filterSensitiveLog = (obj: SplunkDestinationDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is SplunkDestinationDescription => __isa(o, \"SplunkDestinationDescription\");\n}\n\n/**\n * <p>Describes an update for a destination in Splunk.</p>\n */\nexport interface SplunkDestinationUpdate {\n  __type?: \"SplunkDestinationUpdate\";\n  /**\n   * <p>The Amazon CloudWatch logging options for your delivery stream.</p>\n   */\n  CloudWatchLoggingOptions?: CloudWatchLoggingOptions;\n\n  /**\n   * <p>The HTTP Event Collector (HEC) endpoint to which Kinesis Data Firehose sends your\n   *          data.</p>\n   */\n  HECEndpoint?: string;\n\n  /**\n   * <p>The data processing configuration.</p>\n   */\n  ProcessingConfiguration?: ProcessingConfiguration;\n\n  /**\n   * <p>This type can be either \"Raw\" or \"Event.\"</p>\n   */\n  HECEndpointType?: HECEndpointType | string;\n\n  /**\n   * <p>The retry behavior in case Kinesis Data Firehose is unable to deliver data to Splunk\n   *          or if it doesn't receive an acknowledgment of receipt from Splunk.</p>\n   */\n  RetryOptions?: SplunkRetryOptions;\n\n  /**\n   * <p>The amount of time that Kinesis Data Firehose waits to receive an acknowledgment from\n   *          Splunk after it sends data. At the end of the timeout period, Kinesis Data Firehose either\n   *          tries to send the data again or considers it an error, based on your retry\n   *          settings.</p>\n   */\n  HECAcknowledgmentTimeoutInSeconds?: number;\n\n  /**\n   * <p>A GUID that you obtain from your Splunk cluster when you create a new HEC\n   *          endpoint.</p>\n   */\n  HECToken?: string;\n\n  /**\n   * <p>Your update to the configuration of the backup Amazon S3 location.</p>\n   */\n  S3Update?: S3DestinationUpdate;\n\n  /**\n   * <p>Specifies how you want Kinesis Data Firehose to back up documents to Amazon S3. When\n   *          set to <code>FailedDocumentsOnly</code>, Kinesis Data Firehose writes any data that could\n   *          not be indexed to the configured Amazon S3 destination. When set to <code>AllEvents</code>,\n   *          Kinesis Data Firehose delivers all incoming records to Amazon S3, and also writes failed\n   *          documents to Amazon S3. The default value is <code>FailedEventsOnly</code>.</p>\n   *          <p>You can update this backup mode from <code>FailedEventsOnly</code> to\n   *             <code>AllEvents</code>. You can't update it from <code>AllEvents</code> to\n   *             <code>FailedEventsOnly</code>.</p>\n   */\n  S3BackupMode?: SplunkS3BackupMode | string;\n}\n\nexport namespace SplunkDestinationUpdate {\n  export const filterSensitiveLog = (obj: SplunkDestinationUpdate): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is SplunkDestinationUpdate => __isa(o, \"SplunkDestinationUpdate\");\n}\n\n/**\n * <p>Configures retry behavior in case Kinesis Data Firehose is unable to deliver\n *          documents to Splunk, or if it doesn't receive an acknowledgment from Splunk.</p>\n */\nexport interface SplunkRetryOptions {\n  __type?: \"SplunkRetryOptions\";\n  /**\n   * <p>The total amount of time that Kinesis Data Firehose spends on retries. This duration\n   *          starts after the initial attempt to send data to Splunk fails. It doesn't include the\n   *          periods during which Kinesis Data Firehose waits for acknowledgment from Splunk after each\n   *          attempt.</p>\n   */\n  DurationInSeconds?: number;\n}\n\nexport namespace SplunkRetryOptions {\n  export const filterSensitiveLog = (obj: SplunkRetryOptions): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is SplunkRetryOptions => __isa(o, \"SplunkRetryOptions\");\n}\n\nexport type SplunkS3BackupMode = \"AllEvents\" | \"FailedEventsOnly\";\n\nexport interface StartDeliveryStreamEncryptionInput {\n  __type?: \"StartDeliveryStreamEncryptionInput\";\n  /**\n   * <p>The name of the delivery stream for which you want to enable server-side encryption\n   *          (SSE).</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>Used to specify the type and Amazon Resource Name (ARN) of the KMS key needed for\n   *          Server-Side Encryption (SSE).</p>\n   */\n  DeliveryStreamEncryptionConfigurationInput?: DeliveryStreamEncryptionConfigurationInput;\n}\n\nexport namespace StartDeliveryStreamEncryptionInput {\n  export const filterSensitiveLog = (obj: StartDeliveryStreamEncryptionInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is StartDeliveryStreamEncryptionInput =>\n    __isa(o, \"StartDeliveryStreamEncryptionInput\");\n}\n\nexport interface StartDeliveryStreamEncryptionOutput {\n  __type?: \"StartDeliveryStreamEncryptionOutput\";\n}\n\nexport namespace StartDeliveryStreamEncryptionOutput {\n  export const filterSensitiveLog = (obj: StartDeliveryStreamEncryptionOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is StartDeliveryStreamEncryptionOutput =>\n    __isa(o, \"StartDeliveryStreamEncryptionOutput\");\n}\n\nexport interface StopDeliveryStreamEncryptionInput {\n  __type?: \"StopDeliveryStreamEncryptionInput\";\n  /**\n   * <p>The name of the delivery stream for which you want to disable server-side encryption\n   *          (SSE).</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace StopDeliveryStreamEncryptionInput {\n  export const filterSensitiveLog = (obj: StopDeliveryStreamEncryptionInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is StopDeliveryStreamEncryptionInput => __isa(o, \"StopDeliveryStreamEncryptionInput\");\n}\n\nexport interface StopDeliveryStreamEncryptionOutput {\n  __type?: \"StopDeliveryStreamEncryptionOutput\";\n}\n\nexport namespace StopDeliveryStreamEncryptionOutput {\n  export const filterSensitiveLog = (obj: StopDeliveryStreamEncryptionOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is StopDeliveryStreamEncryptionOutput =>\n    __isa(o, \"StopDeliveryStreamEncryptionOutput\");\n}\n\n/**\n * <p>Metadata that you can assign to a delivery stream, consisting of a key-value\n *          pair.</p>\n */\nexport interface Tag {\n  __type?: \"Tag\";\n  /**\n   * <p>An optional string, which you can use to describe or define the tag. Maximum length:\n   *          256 characters. Valid characters: Unicode letters, digits, white space, _ . / = + - %\n   *          @</p>\n   */\n  Value?: string;\n\n  /**\n   * <p>A unique identifier for the tag. Maximum length: 128 characters. Valid characters:\n   *          Unicode letters, digits, white space, _ . / = + - % @</p>\n   */\n  Key: string | undefined;\n}\n\nexport namespace Tag {\n  export const filterSensitiveLog = (obj: Tag): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is Tag => __isa(o, \"Tag\");\n}\n\nexport interface TagDeliveryStreamInput {\n  __type?: \"TagDeliveryStreamInput\";\n  /**\n   * <p>The name of the delivery stream to which you want to add the tags.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>A set of key-value pairs to use to create the tags.</p>\n   */\n  Tags: Tag[] | undefined;\n}\n\nexport namespace TagDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: TagDeliveryStreamInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is TagDeliveryStreamInput => __isa(o, \"TagDeliveryStreamInput\");\n}\n\nexport interface TagDeliveryStreamOutput {\n  __type?: \"TagDeliveryStreamOutput\";\n}\n\nexport namespace TagDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: TagDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is TagDeliveryStreamOutput => __isa(o, \"TagDeliveryStreamOutput\");\n}\n\nexport interface UntagDeliveryStreamInput {\n  __type?: \"UntagDeliveryStreamInput\";\n  /**\n   * <p>A list of tag keys. Each corresponding tag is removed from the delivery\n   *          stream.</p>\n   */\n  TagKeys: string[] | undefined;\n\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n}\n\nexport namespace UntagDeliveryStreamInput {\n  export const filterSensitiveLog = (obj: UntagDeliveryStreamInput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is UntagDeliveryStreamInput => __isa(o, \"UntagDeliveryStreamInput\");\n}\n\nexport interface UntagDeliveryStreamOutput {\n  __type?: \"UntagDeliveryStreamOutput\";\n}\n\nexport namespace UntagDeliveryStreamOutput {\n  export const filterSensitiveLog = (obj: UntagDeliveryStreamOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is UntagDeliveryStreamOutput => __isa(o, \"UntagDeliveryStreamOutput\");\n}\n\nexport interface UpdateDestinationInput {\n  __type?: \"UpdateDestinationInput\";\n  /**\n   * <p>Describes an update to the specified HTTP endpoint destination.</p>\n   */\n  HttpEndpointDestinationUpdate?: HttpEndpointDestinationUpdate;\n\n  /**\n   * <p>The name of the delivery stream.</p>\n   */\n  DeliveryStreamName: string | undefined;\n\n  /**\n   * <p>Describes an update for a destination in Amazon ES.</p>\n   */\n  ElasticsearchDestinationUpdate?: ElasticsearchDestinationUpdate;\n\n  /**\n   * <p>Describes an update for a destination in Amazon S3.</p>\n   */\n  ExtendedS3DestinationUpdate?: ExtendedS3DestinationUpdate;\n\n  /**\n   * <p>[Deprecated] Describes an update for a destination in Amazon S3.</p>\n   */\n  S3DestinationUpdate?: S3DestinationUpdate;\n\n  /**\n   * <p>Describes an update for a destination in Amazon Redshift.</p>\n   */\n  RedshiftDestinationUpdate?: RedshiftDestinationUpdate;\n\n  /**\n   * <p>Obtain this value from the <code>VersionId</code> result of <a>DeliveryStreamDescription</a>. This value is required, and helps the service\n   *          perform conditional operations. For example, if there is an interleaving update and this\n   *          value is null, then the update destination fails. After the update is successful, the\n   *             <code>VersionId</code> value is updated. The service then performs a merge of the old\n   *          configuration with the new configuration.</p>\n   */\n  CurrentDeliveryStreamVersionId: string | undefined;\n\n  /**\n   * <p>Describes an update for a destination in Splunk.</p>\n   */\n  SplunkDestinationUpdate?: SplunkDestinationUpdate;\n\n  /**\n   * <p>The ID of the destination.</p>\n   */\n  DestinationId: string | undefined;\n}\n\nexport namespace UpdateDestinationInput {\n  export const filterSensitiveLog = (obj: UpdateDestinationInput): any => ({\n    ...obj,\n    ...(obj.HttpEndpointDestinationUpdate && {\n      HttpEndpointDestinationUpdate: HttpEndpointDestinationUpdate.filterSensitiveLog(\n        obj.HttpEndpointDestinationUpdate\n      ),\n    }),\n    ...(obj.RedshiftDestinationUpdate && {\n      RedshiftDestinationUpdate: RedshiftDestinationUpdate.filterSensitiveLog(obj.RedshiftDestinationUpdate),\n    }),\n  });\n  export const isa = (o: any): o is UpdateDestinationInput => __isa(o, \"UpdateDestinationInput\");\n}\n\nexport interface UpdateDestinationOutput {\n  __type?: \"UpdateDestinationOutput\";\n}\n\nexport namespace UpdateDestinationOutput {\n  export const filterSensitiveLog = (obj: UpdateDestinationOutput): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is UpdateDestinationOutput => __isa(o, \"UpdateDestinationOutput\");\n}\n\n/**\n * <p>The details of the VPC of the Amazon ES destination.</p>\n */\nexport interface VpcConfiguration {\n  __type?: \"VpcConfiguration\";\n  /**\n   * <p>The IDs of the security groups that you want Kinesis Data Firehose to use when it\n   *          creates ENIs in the VPC of the Amazon ES destination. You can use the same security group\n   *          that the Amazon ES domain uses or different ones. If you specify different security groups\n   *          here, ensure that they allow outbound HTTPS traffic to the Amazon ES domain's security\n   *          group. Also ensure that the Amazon ES domain's security group allows HTTPS traffic from the\n   *          security groups specified here. If you use the same security group for both your delivery\n   *          stream and the Amazon ES domain, make sure the security group inbound rule allows HTTPS\n   *          traffic. For more information about security group rules, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules\">Security group rules</a> in the Amazon VPC documentation.</p>\n   */\n  SecurityGroupIds: string[] | undefined;\n\n  /**\n   * <p>The IDs of the subnets that you want Kinesis Data Firehose to use to create ENIs in the\n   *          VPC of the Amazon ES destination. Make sure that the routing tables and inbound and\n   *          outbound rules allow traffic to flow from the subnets whose IDs are specified here to the\n   *          subnets that have the destination Amazon ES endpoints. Kinesis Data Firehose creates at\n   *          least one ENI in each of the subnets that are specified here. Do not delete or modify these\n   *          ENIs.</p>\n   *          <p>The number of ENIs that Kinesis Data Firehose creates in the subnets specified here\n   *          scales up and down automatically based on throughput. To enable Kinesis Data Firehose to\n   *          scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To\n   *          help you calculate the quota you need, assume that Kinesis Data Firehose can create up to\n   *          three ENIs for this delivery stream for each of the subnets specified here. For more\n   *          information about ENI quota, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis\">Network Interfaces </a> in the Amazon VPC Quotas topic.</p>\n   */\n  SubnetIds: string[] | undefined;\n\n  /**\n   * <p>The ARN of the IAM role that you want the delivery stream to use to create endpoints in\n   *          the destination VPC. You can use your existing Kinesis Data Firehose delivery role or you\n   *          can specify a new role. In either case, make sure that the role trusts the Kinesis Data\n   *          Firehose service principal and that it grants the following permissions:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcs</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcAttribute</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSubnets</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSecurityGroups</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeNetworkInterfaces</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterfacePermission</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DeleteNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *          </ul>\n   *          <p>If you revoke these permissions after you create the delivery stream, Kinesis Data\n   *          Firehose can't scale out by creating more ENIs when necessary. You might therefore see a\n   *          degradation in performance.</p>\n   */\n  RoleARN: string | undefined;\n}\n\nexport namespace VpcConfiguration {\n  export const filterSensitiveLog = (obj: VpcConfiguration): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is VpcConfiguration => __isa(o, \"VpcConfiguration\");\n}\n\n/**\n * <p>The details of the VPC of the Amazon ES destination.</p>\n */\nexport interface VpcConfigurationDescription {\n  __type?: \"VpcConfigurationDescription\";\n  /**\n   * <p>The IDs of the subnets that Kinesis Data Firehose uses to create ENIs in the VPC of the\n   *          Amazon ES destination. Make sure that the routing tables and inbound and outbound rules\n   *          allow traffic to flow from the subnets whose IDs are specified here to the subnets that\n   *          have the destination Amazon ES endpoints. Kinesis Data Firehose creates at least one ENI in\n   *          each of the subnets that are specified here. Do not delete or modify these ENIs.</p>\n   *          <p>The number of ENIs that Kinesis Data Firehose creates in the subnets specified here\n   *          scales up and down automatically based on throughput. To enable Kinesis Data Firehose to\n   *          scale up the number of ENIs to match throughput, ensure that you have sufficient quota. To\n   *          help you calculate the quota you need, assume that Kinesis Data Firehose can create up to\n   *          three ENIs for this delivery stream for each of the subnets specified here. For more\n   *          information about ENI quota, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/amazon-vpc-limits.html#vpc-limits-enis\">Network Interfaces </a> in the Amazon VPC Quotas topic.</p>\n   */\n  SubnetIds: string[] | undefined;\n\n  /**\n   * <p>The IDs of the security groups that Kinesis Data Firehose uses when it creates ENIs in\n   *          the VPC of the Amazon ES destination. You can use the same security group that the Amazon\n   *          ES domain uses or different ones. If you specify different security groups, ensure that\n   *          they allow outbound HTTPS traffic to the Amazon ES domain's security group. Also ensure\n   *          that the Amazon ES domain's security group allows HTTPS traffic from the security groups\n   *          specified here. If you use the same security group for both your delivery stream and the\n   *          Amazon ES domain, make sure the security group inbound rule allows HTTPS traffic. For more\n   *          information about security group rules, see <a href=\"https://docs.aws.amazon.com/vpc/latest/userguide/VPC_SecurityGroups.html#SecurityGroupRules\">Security group rules</a> in the Amazon VPC documentation.</p>\n   */\n  SecurityGroupIds: string[] | undefined;\n\n  /**\n   * <p>The ARN of the IAM role that the delivery stream uses to create endpoints in the\n   *          destination VPC. You can use your existing Kinesis Data Firehose delivery role or you can\n   *          specify a new role. In either case, make sure that the role trusts the Kinesis Data\n   *          Firehose service principal and that it grants the following permissions:</p>\n   *          <ul>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcs</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeVpcAttribute</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSubnets</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeSecurityGroups</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DescribeNetworkInterfaces</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:CreateNetworkInterfacePermission</code>\n   *                </p>\n   *             </li>\n   *             <li>\n   *                <p>\n   *                   <code>ec2:DeleteNetworkInterface</code>\n   *                </p>\n   *             </li>\n   *          </ul>\n   *          <p>If you revoke these permissions after you create the delivery stream, Kinesis Data\n   *          Firehose can't scale out by creating more ENIs when necessary. You might therefore see a\n   *          degradation in performance.</p>\n   */\n  RoleARN: string | undefined;\n\n  /**\n   * <p>The ID of the Amazon ES destination's VPC.</p>\n   */\n  VpcId: string | undefined;\n}\n\nexport namespace VpcConfigurationDescription {\n  export const filterSensitiveLog = (obj: VpcConfigurationDescription): any => ({\n    ...obj,\n  });\n  export const isa = (o: any): o is VpcConfigurationDescription => __isa(o, \"VpcConfigurationDescription\");\n}\n"],"mappings":";AAAA,SAASA,gBAAgB,EAAwCC,GAAG,IAAIC,KAAK,QAAQ,wBAAwB;AAgC7G,OAAM,IAAWC,cAAc;AAA/B,WAAiBA,cAAc;EAChBA,cAAA,CAAAC,kBAAkB,GAAG,UAACC,GAAmB;IAAU,OAAAC,QAAA,KAC3DD,GAAG;EADwD,CAE9D;EACWF,cAAA,CAAAF,GAAG,GAAG,UAACM,CAAM;IAA0B,OAAAL,KAAK,CAACK,CAAC,EAAE,gBAAgB,CAAC;EAA1B,CAA0B;AAChF,CAAC,EALgBJ,cAAc,KAAdA,cAAc;AA8B/B,OAAM,IAAWK,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAJ,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACWG,wBAAA,CAAAP,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgBC,wBAAwB,KAAxBA,wBAAwB;AAOzC,WAAYC,iBAMX;AAND,WAAYA,iBAAiB;EAC3BA,iBAAA,iBAAa;EACbA,iBAAA,mCAA+B;EAC/BA,iBAAA,qBAAiB;EACjBA,iBAAA,iCAA6B;EAC7BA,iBAAA,eAAW;AACb,CAAC,EANWA,iBAAiB,KAAjBA,iBAAiB;AAqB7B,OAAM,IAAWC,+BAA+B;AAAhD,WAAiBA,+BAA+B;EACjCA,+BAAA,CAAAN,kBAAkB,GAAG,UAACC,GAAoC;IAAU,OAAAC,QAAA,KAC5ED,GAAG;EADyE,CAE/E;EACWK,+BAAA,CAAAT,GAAG,GAAG,UAACM,CAAM;IAA2C,OAAAL,KAAK,CAACK,CAAC,EAAE,iCAAiC,CAAC;EAA3C,CAA2C;AAClH,CAAC,EALgBG,+BAA+B,KAA/BA,+BAA+B;AAOhD,WAAYC,eAGX;AAHD,WAAYA,eAAe;EACzBA,eAAA,iBAAa;EACbA,eAAA,iBAAa;AACf,CAAC,EAHWA,eAAe,KAAfA,eAAe;AA6C3B,OAAM,IAAWC,WAAW;AAA5B,WAAiBA,WAAW;EACbA,WAAA,CAAAR,kBAAkB,GAAG,UAACC,GAAgB;IAAU,OAAAC,QAAA,KACxDD,GAAG;EADqD,CAE3D;EACWO,WAAA,CAAAX,GAAG,GAAG,UAACM,CAAM;IAAuB,OAAAL,KAAK,CAACK,CAAC,EAAE,aAAa,CAAC;EAAvB,CAAuB;AAC1E,CAAC,EALgBK,WAAW,KAAXA,WAAW;AA0F5B,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAT,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACS,gCAAgC,IAAI;MAC1CA,gCAAgC,EAAEA,gCAAgC,CAACV,kBAAkB,CACnFC,GAAG,CAACS,gCAAgC;KAEvC,CAAC,EACET,GAAG,CAACU,oCAAoC,IAAI;MAC9CA,oCAAoC,EAAEA,oCAAoC,CAACX,kBAAkB,CAC3FC,GAAG,CAACU,oCAAoC;KAE3C,CAAC;EAXuE,CAYzE;EACWF,yBAAA,CAAAZ,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EAfgBM,yBAAyB,KAAzBA,yBAAyB;AAyB1C,OAAM,IAAWG,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAAZ,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;EACWW,0BAAA,CAAAf,GAAG,GAAG,UAACM,CAAM;IAAsC,OAAAL,KAAK,CAACK,CAAC,EAAE,4BAA4B,CAAC;EAAtC,CAAsC;AACxG,CAAC,EALgBS,0BAA0B,KAA1BA,0BAA0B;AA2C3C,OAAM,IAAWC,iCAAiC;AAAlD,WAAiBA,iCAAiC;EACnCA,iCAAA,CAAAb,kBAAkB,GAAG,UAACC,GAAsC;IAAU,OAAAC,QAAA,KAC9ED,GAAG;EAD2E,CAEjF;EACWY,iCAAA,CAAAhB,GAAG,GAAG,UAACM,CAAM;IAA6C,OAAAL,KAAK,CAACK,CAAC,EAAE,mCAAmC,CAAC;EAA7C,CAA6C;AACtH,CAAC,EALgBU,iCAAiC,KAAjCA,iCAAiC;AA0BlD,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAd,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;EACWa,yBAAA,CAAAjB,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EALgBW,yBAAyB,KAAzBA,yBAAyB;AAW1C,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAAf,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;EACWc,0BAAA,CAAAlB,GAAG,GAAG,UAACM,CAAM;IAAsC,OAAAL,KAAK,CAACK,CAAC,EAAE,4BAA4B,CAAC;EAAtC,CAAsC;AACxG,CAAC,EALgBY,0BAA0B,KAA1BA,0BAA0B;AA+F3C,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAhB,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACgB,YAAY,IAAI;MACtBA,YAAY,EAAEhB,GAAG,CAACgB,YAAY,CAACC,GAAG,CAAC,UAACC,IAAI;QAAK,OAAAC,sBAAsB,CAACpB,kBAAkB,CAACmB,IAAI,CAAC;MAA/C,CAA+C;KAC7F,CAAC;EAJuE,CAKzE;EACWH,yBAAA,CAAAnB,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EARgBa,yBAAyB,KAAzBA,yBAAyB;AA+C1C,OAAM,IAAWK,qCAAqC;AAAtD,WAAiBA,qCAAqC;EACvCA,qCAAA,CAAArB,kBAAkB,GAAG,UAACC,GAA0C;IAAU,OAAAC,QAAA,KAClFD,GAAG;EAD+E,CAErF;EACWoB,qCAAA,CAAAxB,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,uCAAuC,CAAC;EAAjD,CAAiD;AACrD,CAAC,EANgBkB,qCAAqC,KAArCA,qCAAqC;AA4CtD,OAAM,IAAWC,0CAA0C;AAA3D,WAAiBA,0CAA0C;EAC5CA,0CAAA,CAAAtB,kBAAkB,GAAG,UAACC,GAA+C;IAAU,OAAAC,QAAA,KACvFD,GAAG;EADoF,CAE1F;EACWqB,0CAAA,CAAAzB,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,4CAA4C,CAAC;EAAtD,CAAsD;AAC1D,CAAC,EANgBmB,0CAA0C,KAA1CA,0CAA0C;AAQ3D,WAAYC,8BAOX;AAPD,WAAYA,8BAA8B;EACxCA,8BAAA,yBAAqB;EACrBA,8BAAA,2BAAuB;EACvBA,8BAAA,yCAAqC;EACrCA,8BAAA,uBAAmB;EACnBA,8BAAA,yBAAqB;EACrBA,8BAAA,uCAAmC;AACrC,CAAC,EAPWA,8BAA8B,KAA9BA,8BAA8B;AAS1C,WAAYC,yBAgBX;AAhBD,WAAYA,yBAAyB;EACnCA,yBAAA,2CAAuC;EACvCA,yBAAA,uDAAmD;EACnDA,yBAAA,2CAAuC;EACvCA,yBAAA,yCAAqC;EACrCA,yBAAA,2CAAuC;EACvCA,yBAAA,uCAAmC;EACnCA,yBAAA,2CAAuC;EACvCA,yBAAA,2CAAuC;EACvCA,yBAAA,+CAA2C;EAC3CA,yBAAA,uDAAmD;EACnDA,yBAAA,iEAA6D;EAC7DA,yBAAA,yDAAqD;EACrDA,yBAAA,iDAA6C;EAC7CA,yBAAA,yCAAqC;EACrCA,yBAAA,mCAA+B;AACjC,CAAC,EAhBWA,yBAAyB,KAAzBA,yBAAyB;AAkBrC,WAAYC,oBAMX;AAND,WAAYA,oBAAoB;EAC9BA,oBAAA,qBAAiB;EACjBA,oBAAA,yBAAqB;EACrBA,oBAAA,uCAAmC;EACnCA,oBAAA,yBAAqB;EACrBA,oBAAA,uCAAmC;AACrC,CAAC,EANWA,oBAAoB,KAApBA,oBAAoB;AA8BhC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA1B,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACWyB,2BAAA,CAAA7B,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgBuB,2BAA2B,KAA3BA,2BAA2B;AAe5C,OAAM,IAAWC,4BAA4B;AAA7C,WAAiBA,4BAA4B;EAC9BA,4BAAA,CAAA3B,kBAAkB,GAAG,UAACC,GAAiC;IAAU,OAAAC,QAAA,CAAAA,QAAA,KACzED,GAAG,GACFA,GAAG,CAACe,yBAAyB,IAAI;MACnCA,yBAAyB,EAAEA,yBAAyB,CAAChB,kBAAkB,CAACC,GAAG,CAACe,yBAAyB;KACtG,CAAC;EAJ0E,CAK5E;EACWW,4BAAA,CAAA9B,GAAG,GAAG,UAACM,CAAM;IAAwC,OAAAL,KAAK,CAACK,CAAC,EAAE,8BAA8B,CAAC;EAAxC,CAAwC;AAC5G,CAAC,EARgBwB,4BAA4B,KAA5BA,4BAA4B;AAmC7C,OAAM,IAAWC,YAAY;AAA7B,WAAiBA,YAAY;EACdA,YAAA,CAAA5B,kBAAkB,GAAG,UAACC,GAAiB;IAAU,OAAAC,QAAA,KACzDD,GAAG;EADsD,CAE5D;EACW2B,YAAA,CAAA/B,GAAG,GAAG,UAACM,CAAM;IAAwB,OAAAL,KAAK,CAACK,CAAC,EAAE,cAAc,CAAC;EAAxB,CAAwB;AAC5E,CAAC,EALgByB,YAAY,KAAZA,YAAY;AAgD7B,OAAM,IAAWR,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAApB,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACnED,GAAG,GACFA,GAAG,CAAC4B,8BAA8B,IAAI;MACxCA,8BAA8B,EAAEA,8BAA8B,CAAC7B,kBAAkB,CAC/EC,GAAG,CAAC4B,8BAA8B;KAErC,CAAC,EACE5B,GAAG,CAAC6B,kCAAkC,IAAI;MAC5CA,kCAAkC,EAAEA,kCAAkC,CAAC9B,kBAAkB,CACvFC,GAAG,CAAC6B,kCAAkC;KAEzC,CAAC;EAXoE,CAYtE;EACWV,sBAAA,CAAAvB,GAAG,GAAG,UAACM,CAAM;IAAkC,OAAAL,KAAK,CAACK,CAAC,EAAE,wBAAwB,CAAC;EAAlC,CAAkC;AAChG,CAAC,EAfgBiB,sBAAsB,KAAtBA,sBAAsB;AAuCvC,OAAM,IAAWW,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA/B,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACW8B,2BAAA,CAAAlC,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgB4B,2BAA2B,KAA3BA,2BAA2B;AA2G5C,OAAM,IAAWC,qCAAqC;AAAtD,WAAiBA,qCAAqC;EACvCA,qCAAA,CAAAhC,kBAAkB,GAAG,UAACC,GAA0C;IAAU,OAAAC,QAAA,KAClFD,GAAG;EAD+E,CAErF;EACW+B,qCAAA,CAAAnC,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,uCAAuC,CAAC;EAAjD,CAAiD;AACrD,CAAC,EANgB6B,qCAAqC,KAArCA,qCAAqC;AAuFtD,OAAM,IAAWC,mCAAmC;AAApD,WAAiBA,mCAAmC;EACrCA,mCAAA,CAAAjC,kBAAkB,GAAG,UAACC,GAAwC;IAAU,OAAAC,QAAA,KAChFD,GAAG;EAD6E,CAEnF;EACWgC,mCAAA,CAAApC,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,qCAAqC,CAAC;EAA/C,CAA+C;AACnD,CAAC,EANgB8B,mCAAmC,KAAnCA,mCAAmC;AA4FpD,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAAlC,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;EACWiC,8BAAA,CAAArC,GAAG,GAAG,UAACM,CAAM;IAA0C,OAAAL,KAAK,CAACK,CAAC,EAAE,gCAAgC,CAAC;EAA1C,CAA0C;AAChH,CAAC,EALgB+B,8BAA8B,KAA9BA,8BAA8B;AAwB/C,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAnC,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;EACWkC,yBAAA,CAAAtC,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EALgBgC,yBAAyB,KAAzBA,yBAAyB;AA0B1C,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAApC,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;EACWmC,uBAAA,CAAAvC,GAAG,GAAG,UAACM,CAAM;IAAmC,OAAAL,KAAK,CAACK,CAAC,EAAE,yBAAyB,CAAC;EAAnC,CAAmC;AAClG,CAAC,EALgBiC,uBAAuB,KAAvBA,uBAAuB;AAqFxC,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAArC,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,KAC/ED,GAAG;EAD4E,CAElF;EACWoC,kCAAA,CAAAxC,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,oCAAoC,CAAC;EAA9C,CAA8C;AAClD,CAAC,EANgBkC,kCAAkC,KAAlCA,kCAAkC;AAoFnD,OAAM,IAAWC,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAAtC,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,KAC7ED,GAAG;EAD0E,CAEhF;EACWqC,gCAAA,CAAAzC,GAAG,GAAG,UAACM,CAAM;IAA4C,OAAAL,KAAK,CAACK,CAAC,EAAE,kCAAkC,CAAC;EAA5C,CAA4C;AACpH,CAAC,EALgBmC,gCAAgC,KAAhCA,gCAAgC;AAoFjD,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAvC,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACWsC,2BAAA,CAAA1C,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgBoC,2BAA2B,KAA3BA,2BAA2B;AAyB5C,OAAM,IAAWC,kBAAkB;AAAnC,WAAiBA,kBAAkB;EACpBA,kBAAA,CAAAxC,kBAAkB,GAAG,UAACC,GAAuB;IAAU,OAAAC,QAAA,KAC/DD,GAAG;EAD4D,CAElE;EACWuC,kBAAA,CAAA3C,GAAG,GAAG,UAACM,CAAM;IAA8B,OAAAL,KAAK,CAACK,CAAC,EAAE,oBAAoB,CAAC;EAA9B,CAA8B;AACxF,CAAC,EALgBqC,kBAAkB,KAAlBA,kBAAkB;AA2BnC,OAAM,IAAWC,aAAa;AAA9B,WAAiBA,aAAa;EACfA,aAAA,CAAAzC,kBAAkB,GAAG,UAACC,GAAkB;IAAU,OAAAC,QAAA,KAC1DD,GAAG;EADuD,CAE7D;EACWwC,aAAA,CAAA5C,GAAG,GAAG,UAACM,CAAM;IAAyB,OAAAL,KAAK,CAACK,CAAC,EAAE,eAAe,CAAC;EAAzB,CAAyB;AAC9E,CAAC,EALgBsC,aAAa,KAAbA,aAAa;AAgC9B,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAA1C,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;EACWyC,0BAAA,CAAA7C,GAAG,GAAG,UAACM,CAAM;IAAsC,OAAAL,KAAK,CAACK,CAAC,EAAE,4BAA4B,CAAC;EAAtC,CAAsC;AACxG,CAAC,EALgBuC,0BAA0B,KAA1BA,0BAA0B;AAwB3C,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA3C,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACxED,GAAG,GACFA,GAAG,CAAC2C,aAAa,IAAI;MAAEA,aAAa,EAAEhD;IAAgB,CAAE,CAAC,EACzDK,GAAG,CAAC4C,cAAc,IAAI;MAAEA,cAAc,EAAEjD;IAAgB,CAAE,CAAC;EAHY,CAI3E;EACW+C,2BAAA,CAAA9C,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EAPgBwC,2BAA2B,KAA3BA,2BAA2B;AAgC5C,OAAM,IAAWG,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA9C,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAAC8C,SAAS,IAAI;MAAEA,SAAS,EAAEnD;IAAgB,CAAE,CAAC,EACjDK,GAAG,CAAC+C,GAAG,IAAI;MAAEA,GAAG,EAAEpD;IAAgB,CAAE,CAAC;EAHgC,CAIzE;EACWkD,yBAAA,CAAAjD,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EAPgB2C,yBAAyB,KAAzBA,yBAAyB;AAyB1C,OAAM,IAAWG,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAAjD,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,CAAAA,QAAA,KACpED,GAAG,GACFA,GAAG,CAAC+C,GAAG,IAAI;MAAEA,GAAG,EAAEpD;IAAgB,CAAE,CAAC;EAF8B,CAGvE;EACWqD,uBAAA,CAAApD,GAAG,GAAG,UAACM,CAAM;IAAmC,OAAAL,KAAK,CAACK,CAAC,EAAE,yBAAyB,CAAC;EAAnC,CAAmC;AAClG,CAAC,EANgB8C,uBAAuB,KAAvBA,uBAAuB;AAsExC,OAAM,IAAWtC,oCAAoC;AAArD,WAAiBA,oCAAoC;EACtCA,oCAAA,CAAAX,kBAAkB,GAAG,UAACC,GAAyC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACjFD,GAAG,GACFA,GAAG,CAACiD,qBAAqB,IAAI;MAC/BA,qBAAqB,EAAEJ,yBAAyB,CAAC9C,kBAAkB,CAACC,GAAG,CAACiD,qBAAqB;KAC9F,CAAC,EACEjD,GAAG,CAACkD,oBAAoB,IAAI;MAC9BA,oBAAoB,EAAEC,gCAAgC,CAACpD,kBAAkB,CAACC,GAAG,CAACkD,oBAAoB;KACnG,CAAC;EAPkF,CAQpF;EACWxC,oCAAA,CAAAd,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,sCAAsC,CAAC;EAAhD,CAAgD;AACpD,CAAC,EAZgBQ,oCAAoC,KAApCA,oCAAoC;AA4ErD,OAAM,IAAWmB,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAA9B,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KAC/ED,GAAG,GACFA,GAAG,CAACkD,oBAAoB,IAAI;MAC9BA,oBAAoB,EAAEC,gCAAgC,CAACpD,kBAAkB,CAACC,GAAG,CAACkD,oBAAoB;KACnG,CAAC,EACElD,GAAG,CAACiD,qBAAqB,IAAI;MAC/BA,qBAAqB,EAAED,uBAAuB,CAACjD,kBAAkB,CAACC,GAAG,CAACiD,qBAAqB;KAC5F,CAAC;EAPgF,CAQlF;EACWpB,kCAAA,CAAAjC,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,oCAAoC,CAAC;EAA9C,CAA8C;AAClD,CAAC,EAZgB2B,kCAAkC,KAAlCA,kCAAkC;AA4EnD,OAAM,IAAWuB,6BAA6B;AAA9C,WAAiBA,6BAA6B;EAC/BA,6BAAA,CAAArD,kBAAkB,GAAG,UAACC,GAAkC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KAC1ED,GAAG,GACFA,GAAG,CAACiD,qBAAqB,IAAI;MAC/BA,qBAAqB,EAAEJ,yBAAyB,CAAC9C,kBAAkB,CAACC,GAAG,CAACiD,qBAAqB;KAC9F,CAAC,EACEjD,GAAG,CAACkD,oBAAoB,IAAI;MAC9BA,oBAAoB,EAAEC,gCAAgC,CAACpD,kBAAkB,CAACC,GAAG,CAACkD,oBAAoB;KACnG,CAAC;EAP2E,CAQ7E;EACWE,6BAAA,CAAAxD,GAAG,GAAG,UAACM,CAAM;IAAyC,OAAAL,KAAK,CAACK,CAAC,EAAE,+BAA+B,CAAC;EAAzC,CAAyC;AAC9G,CAAC,EAXgBkD,6BAA6B,KAA7BA,6BAA6B;AA8B9C,OAAM,IAAWD,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAApD,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,CAAAA,QAAA,KAC7ED,GAAG,GACFA,GAAG,CAACqD,gBAAgB,IAAI;MAC1BA,gBAAgB,EAAErD,GAAG,CAACqD,gBAAgB,CAACpC,GAAG,CAAC,UAACC,IAAI;QAAK,OAAAwB,2BAA2B,CAAC3C,kBAAkB,CAACmB,IAAI,CAAC;MAApD,CAAoD;KAC1G,CAAC;EAJ8E,CAKhF;EACWiC,gCAAA,CAAAvD,GAAG,GAAG,UAACM,CAAM;IAA4C,OAAAL,KAAK,CAACK,CAAC,EAAE,kCAAkC,CAAC;EAA5C,CAA4C;AACpH,CAAC,EARgBiD,gCAAgC,KAAhCA,gCAAgC;AA0BjD,OAAM,IAAWG,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAvD,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACWsD,wBAAA,CAAA1D,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgBoD,wBAAwB,KAAxBA,wBAAwB;AAsBzC,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAxD,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACWuD,wBAAA,CAAA3D,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgBqD,wBAAwB,KAAxBA,wBAAwB;AAmBzC,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAzD,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACWwD,wBAAA,CAAA5D,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgBsD,wBAAwB,KAAxBA,wBAAwB;AAqBzC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAA1D,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACWyD,2BAAA,CAAA7D,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgBuD,2BAA2B,KAA3BA,2BAA2B;AAO5C,WAAYC,OAGX;AAHD,WAAYA,OAAO;EACjBA,OAAA,mCAA+B;EAC/BA,OAAA,iDAA6C;AAC/C,CAAC,EAHWA,OAAO,KAAPA,OAAO;AAuBnB,OAAM,IAAWC,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAA5D,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,KAC7ED,GAAG;EAD0E,CAEhF;EACW2D,gCAAA,CAAA/D,GAAG,GAAG,UAACM,CAAM;IAA4C,OAAAL,KAAK,CAACK,CAAC,EAAE,kCAAkC,CAAC;EAA5C,CAA4C;AACpH,CAAC,EALgByD,gCAAgC,KAAhCA,gCAAgC;AAgCjD,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAA7D,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;EACW4D,8BAAA,CAAAhE,GAAG,GAAG,UAACM,CAAM;IAA0C,OAAAL,KAAK,CAACK,CAAC,EAAE,gCAAgC,CAAC;EAA1C,CAA0C;AAChH,CAAC,EALgB0D,8BAA8B,KAA9BA,8BAA8B;AAoB/C,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAA9D,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;EACW6D,mBAAA,CAAAjE,GAAG,GAAG,UAACM,CAAM;IAA+B,OAAAL,KAAK,CAACK,CAAC,EAAE,qBAAqB,CAAC;EAA/B,CAA+B;AAC1F,CAAC,EALgB2D,mBAAmB,KAAnBA,mBAAmB;AAmBpC,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAA/D,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,KACnED,GAAG;EADgE,CAEtE;EACW8D,sBAAA,CAAAlE,GAAG,GAAG,UAACM,CAAM;IAAkC,OAAAL,KAAK,CAACK,CAAC,EAAE,wBAAwB,CAAC;EAAlC,CAAkC;AAChG,CAAC,EALgB4D,sBAAsB,KAAtBA,sBAAsB;AA0CvC,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAAhE,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACW+D,wBAAA,CAAAnE,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgB6D,wBAAwB,KAAxBA,wBAAwB;AAoBzC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAjE,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;EACWgE,yBAAA,CAAApE,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EALgB8D,yBAAyB,KAAzBA,yBAAyB;AA8B1C,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAAlE,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;EACWiE,8BAAA,CAAArE,GAAG,GAAG,UAACM,CAAM;IAA0C,OAAAL,KAAK,CAACK,CAAC,EAAE,gCAAgC,CAAC;EAA1C,CAA0C;AAChH,CAAC,EALgB+D,8BAA8B,KAA9BA,8BAA8B;AAwB/C,OAAM,IAAWC,+BAA+B;AAAhD,WAAiBA,+BAA+B;EACjCA,+BAAA,CAAAnE,kBAAkB,GAAG,UAACC,GAAoC;IAAU,OAAAC,QAAA,KAC5ED,GAAG;EADyE,CAE/E;EACWkE,+BAAA,CAAAtE,GAAG,GAAG,UAACM,CAAM;IAA2C,OAAAL,KAAK,CAACK,CAAC,EAAE,iCAAiC,CAAC;EAA3C,CAA2C;AAClH,CAAC,EALgBgE,+BAA+B,KAA/BA,+BAA+B;AA2ChD,OAAM,IAAWC,cAAc;AAA/B,WAAiBA,cAAc;EAChBA,cAAA,CAAApE,kBAAkB,GAAG,UAACC,GAAmB;IAAU,OAAAC,QAAA,KAC3DD,GAAG;EADwD,CAE9D;EACWmE,cAAA,CAAAvE,GAAG,GAAG,UAACM,CAAM;IAA0B,OAAAL,KAAK,CAACK,CAAC,EAAE,gBAAgB,CAAC;EAA1B,CAA0B;AAChF,CAAC,EALgBiE,cAAc,KAAdA,cAAc;AAO/B,WAAYC,cAIX;AAJD,WAAYA,cAAc;EACxBA,cAAA,iBAAa;EACbA,cAAA,qBAAiB;EACjBA,cAAA,iBAAa;AACf,CAAC,EAJWA,cAAc,KAAdA,cAAc;AAM1B,WAAYC,gBAGX;AAHD,WAAYA,gBAAgB;EAC1BA,gBAAA,mBAAe;EACfA,gBAAA,mBAAe;AACjB,CAAC,EAHWA,gBAAgB,KAAhBA,gBAAgB;AAkF5B,OAAM,IAAWC,QAAQ;AAAzB,WAAiBA,QAAQ;EACVA,QAAA,CAAAvE,kBAAkB,GAAG,UAACC,GAAa;IAAU,OAAAC,QAAA,KACrDD,GAAG;EADkD,CAExD;EACWsE,QAAA,CAAA1E,GAAG,GAAG,UAACM,CAAM;IAAoB,OAAAL,KAAK,CAACK,CAAC,EAAE,UAAU,CAAC;EAApB,CAAoB;AACpE,CAAC,EALgBoE,QAAQ,KAARA,QAAQ;AAqBzB,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAxE,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;EACWuE,yBAAA,CAAA3E,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EALgBqE,yBAAyB,KAAzBA,yBAAyB;AAO1C,WAAYC,kBAIX;AAJD,WAAYA,kBAAkB;EAC5BA,kBAAA,iBAAa;EACbA,kBAAA,qBAAiB;EACjBA,kBAAA,iCAA6B;AAC/B,CAAC,EAJWA,kBAAkB,KAAlBA,kBAAkB;AAoD9B,OAAM,IAAWC,YAAY;AAA7B,WAAiBA,YAAY;EACdA,YAAA,CAAA1E,kBAAkB,GAAG,UAACC,GAAiB;IAAU,OAAAC,QAAA,KACzDD,GAAG;EADsD,CAE5D;EACWyE,YAAA,CAAA7E,GAAG,GAAG,UAACM,CAAM;IAAwB,OAAAL,KAAK,CAACK,CAAC,EAAE,cAAc,CAAC;EAAxB,CAAwB;AAC5E,CAAC,EALgBuE,YAAY,KAAZA,YAAY;AAO7B,WAAYC,oBAGX;AAHD,WAAYA,oBAAoB;EAC9BA,oBAAA,aAAS;EACTA,oBAAA,aAAS;AACX,CAAC,EAHWA,oBAAoB,KAApBA,oBAAoB;AAqBhC,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAA5E,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;EACW2E,uBAAA,CAAA/E,GAAG,GAAG,UAACM,CAAM;IAAmC,OAAAL,KAAK,CAACK,CAAC,EAAE,yBAAyB,CAAC;EAAnC,CAAmC;AAClG,CAAC,EALgByE,uBAAuB,KAAvBA,uBAAuB;AAuBxC,OAAM,IAAWC,SAAS;AAA1B,WAAiBA,SAAS;EACXA,SAAA,CAAA7E,kBAAkB,GAAG,UAACC,GAAc;IAAU,OAAAC,QAAA,KACtDD,GAAG;EADmD,CAEzD;EACW4E,SAAA,CAAAhF,GAAG,GAAG,UAACM,CAAM;IAAqB,OAAAL,KAAK,CAACK,CAAC,EAAE,WAAW,CAAC;EAArB,CAAqB;AACtE,CAAC,EALgB0E,SAAS,KAATA,SAAS;AAuB1B,OAAM,IAAWC,kBAAkB;AAAnC,WAAiBA,kBAAkB;EACpBA,kBAAA,CAAA9E,kBAAkB,GAAG,UAACC,GAAuB;IAAU,OAAAC,QAAA,KAC/DD,GAAG;EAD4D,CAElE;EACW6E,kBAAA,CAAAjF,GAAG,GAAG,UAACM,CAAM;IAA8B,OAAAL,KAAK,CAACK,CAAC,EAAE,oBAAoB,CAAC;EAA9B,CAA8B;AACxF,CAAC,EALgB2E,kBAAkB,KAAlBA,kBAAkB;AAOnC,WAAYC,sBAMX;AAND,WAAYA,sBAAsB;EAChCA,sBAAA,0DAAsD;EACtDA,sBAAA,yCAAqC;EACrCA,sBAAA,4BAAwB;EACxBA,sBAAA,gDAA4C;EAC5CA,sBAAA,wBAAoB;AACtB,CAAC,EANWA,sBAAsB,KAAtBA,sBAAsB;AAuBlC,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAAhF,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;EACW+E,mBAAA,CAAAnF,GAAG,GAAG,UAACM,CAAM;IAA+B,OAAAL,KAAK,CAACK,CAAC,EAAE,qBAAqB,CAAC;EAA/B,CAA+B;AAC1F,CAAC,EALgB6E,mBAAmB,KAAnBA,mBAAmB;AA6BpC,OAAM,IAAWC,oBAAoB;AAArC,WAAiBA,oBAAoB;EACtBA,oBAAA,CAAAjF,kBAAkB,GAAG,UAACC,GAAyB;IAAU,OAAAC,QAAA,KACjED,GAAG;EAD8D,CAEpE;EACWgF,oBAAA,CAAApF,GAAG,GAAG,UAACM,CAAM;IAAgC,OAAAL,KAAK,CAACK,CAAC,EAAE,sBAAsB,CAAC;EAAhC,CAAgC;AAC5F,CAAC,EALgB8E,oBAAoB,KAApBA,oBAAoB;AA+BrC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAlF,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACWiF,2BAAA,CAAArF,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgB+E,2BAA2B,KAA3BA,2BAA2B;AAoB5C,OAAM,IAAWC,cAAc;AAA/B,WAAiBA,cAAc;EAChBA,cAAA,CAAAnF,kBAAkB,GAAG,UAACC,GAAmB;IAAU,OAAAC,QAAA,KAC3DD,GAAG;EADwD,CAE9D;EACWkF,cAAA,CAAAtF,GAAG,GAAG,UAACM,CAAM;IAA0B,OAAAL,KAAK,CAACK,CAAC,EAAE,gBAAgB,CAAC;EAA1B,CAA0B;AAChF,CAAC,EALgBgF,cAAc,KAAdA,cAAc;AAoB/B,OAAM,IAAWC,eAAe;AAAhC,WAAiBA,eAAe;EACjBA,eAAA,CAAApF,kBAAkB,GAAG,UAACC,GAAoB;IAAU,OAAAC,QAAA,KAC5DD,GAAG;EADyD,CAE/D;EACWmF,eAAA,CAAAvF,GAAG,GAAG,UAACM,CAAM;IAA2B,OAAAL,KAAK,CAACK,CAAC,EAAE,iBAAiB,CAAC;EAA3B,CAA2B;AAClF,CAAC,EALgBiF,eAAe,KAAfA,eAAe;AAmBhC,OAAM,IAAWC,OAAO;AAAxB,WAAiBA,OAAO;EACTA,OAAA,CAAArF,kBAAkB,GAAG,UAACC,GAAY;IAAU,OAAAC,QAAA,KACpDD,GAAG;EADiD,CAEvD;EACWoF,OAAA,CAAAxF,GAAG,GAAG,UAACM,CAAM;IAAmB,OAAAL,KAAK,CAACK,CAAC,EAAE,QAAQ,CAAC;EAAlB,CAAkB;AACjE,CAAC,EALgBkF,OAAO,KAAPA,OAAO;AA6ExB,OAAM,IAAW3E,gCAAgC;AAAjD,WAAiBA,gCAAgC;EAClCA,gCAAA,CAAAV,kBAAkB,GAAG,UAACC,GAAqC;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KAC7ED,GAAG,GACFA,GAAG,CAACqF,QAAQ,IAAI;MAAEA,QAAQ,EAAE1F;IAAgB,CAAE,CAAC,EAC/CK,GAAG,CAACsF,QAAQ,IAAI;MAAEA,QAAQ,EAAE3F;IAAgB,CAAE,CAAC;EAH6B,CAIhF;EACWc,gCAAA,CAAAb,GAAG,GAAG,UAACM,CAAM;IAA4C,OAAAL,KAAK,CAACK,CAAC,EAAE,kCAAkC,CAAC;EAA5C,CAA4C;AACpH,CAAC,EAPgBO,gCAAgC,KAAhCA,gCAAgC;AAmEjD,OAAM,IAAWmB,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAA7B,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,CAAAA,QAAA,KAC3ED,GAAG,GACFA,GAAG,CAACqF,QAAQ,IAAI;MAAEA,QAAQ,EAAE1F;IAAgB,CAAE,CAAC;EAF2B,CAG9E;EACWiC,8BAAA,CAAAhC,GAAG,GAAG,UAACM,CAAM;IAA0C,OAAAL,KAAK,CAACK,CAAC,EAAE,gCAAgC,CAAC;EAA1C,CAA0C;AAChH,CAAC,EANgB0B,8BAA8B,KAA9BA,8BAA8B;AA4E/C,OAAM,IAAW2D,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAAxF,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACtED,GAAG,GACFA,GAAG,CAACqF,QAAQ,IAAI;MAAEA,QAAQ,EAAE1F;IAAgB,CAAE,CAAC,EAC/CK,GAAG,CAACsF,QAAQ,IAAI;MAAEA,QAAQ,EAAE3F;IAAgB,CAAE,CAAC;EAHsB,CAIzE;EACW4F,yBAAA,CAAA3F,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EAPgBqF,yBAAyB,KAAzBA,yBAAyB;AAyB1C,OAAM,IAAWC,oBAAoB;AAArC,WAAiBA,oBAAoB;EACtBA,oBAAA,CAAAzF,kBAAkB,GAAG,UAACC,GAAyB;IAAU,OAAAC,QAAA,KACjED,GAAG;EAD8D,CAEpE;EACWwF,oBAAA,CAAA5F,GAAG,GAAG,UAACM,CAAM;IAAgC,OAAAL,KAAK,CAACK,CAAC,EAAE,sBAAsB,CAAC;EAAhC,CAAgC;AAC5F,CAAC,EALgBsF,oBAAoB,KAApBA,oBAAoB;AAqBrC,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAA1F,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,KACnED,GAAG;EADgE,CAEtE;EACWyF,sBAAA,CAAA7F,GAAG,GAAG,UAACM,CAAM;IAAkC,OAAAL,KAAK,CAACK,CAAC,EAAE,wBAAwB,CAAC;EAAlC,CAAkC;AAChG,CAAC,EALgBuF,sBAAsB,KAAtBA,sBAAsB;AAmBvC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA3F,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;EACW0F,yBAAA,CAAA9F,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EALgBwF,yBAAyB,KAAzBA,yBAAyB;AAoE1C,OAAM,IAAWC,0BAA0B;AAA3C,WAAiBA,0BAA0B;EAC5BA,0BAAA,CAAA5F,kBAAkB,GAAG,UAACC,GAA+B;IAAU,OAAAC,QAAA,KACvED,GAAG;EADoE,CAE1E;EACW2F,0BAAA,CAAA/F,GAAG,GAAG,UAACM,CAAM;IAAsC,OAAAL,KAAK,CAACK,CAAC,EAAE,4BAA4B,CAAC;EAAtC,CAAsC;AACxG,CAAC,EALgByF,0BAA0B,KAA1BA,0BAA0B;AA+D3C,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAA7F,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACW4F,wBAAA,CAAAhG,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgB0F,wBAAwB,KAAxBA,wBAAwB;AAkEzC,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAA9F,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;EACW6F,mBAAA,CAAAjG,GAAG,GAAG,UAACM,CAAM;IAA+B,OAAAL,KAAK,CAACK,CAAC,EAAE,qBAAqB,CAAC;EAA/B,CAA+B;AAC1F,CAAC,EALgB2F,mBAAmB,KAAnBA,mBAAmB;AAqDpC,OAAM,IAAWC,mBAAmB;AAApC,WAAiBA,mBAAmB;EACrBA,mBAAA,CAAA/F,kBAAkB,GAAG,UAACC,GAAwB;IAAU,OAAAC,QAAA,KAChED,GAAG;EAD6D,CAEnE;EACW8F,mBAAA,CAAAlG,GAAG,GAAG,UAACM,CAAM;IAA+B,OAAAL,KAAK,CAACK,CAAC,EAAE,qBAAqB,CAAC;EAA/B,CAA+B;AAC1F,CAAC,EALgB4F,mBAAmB,KAAnBA,mBAAmB;AA4BpC,OAAM,IAAWC,UAAU;AAA3B,WAAiBA,UAAU;EACZA,UAAA,CAAAhG,kBAAkB,GAAG,UAACC,GAAe;IAAU,OAAAC,QAAA,KACvDD,GAAG;EADoD,CAE1D;EACW+F,UAAA,CAAAnG,GAAG,GAAG,UAACM,CAAM;IAAsB,OAAAL,KAAK,CAACK,CAAC,EAAE,YAAY,CAAC;EAAtB,CAAsB;AACxE,CAAC,EALgB6F,UAAU,KAAVA,UAAU;AAsB3B,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAjG,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACWgG,2BAAA,CAAApG,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgB8F,2BAA2B,KAA3BA,2BAA2B;AAoB5C,OAAM,IAAWC,iBAAiB;AAAlC,WAAiBA,iBAAiB;EACnBA,iBAAA,CAAAlG,kBAAkB,GAAG,UAACC,GAAsB;IAAU,OAAAC,QAAA,KAC9DD,GAAG;EAD2D,CAEjE;EACWiG,iBAAA,CAAArG,GAAG,GAAG,UAACM,CAAM;IAA6B,OAAAL,KAAK,CAACK,CAAC,EAAE,mBAAmB,CAAC;EAA7B,CAA6B;AACtF,CAAC,EALgB+F,iBAAiB,KAAjBA,iBAAiB;AAuElC,OAAM,IAAWC,8BAA8B;AAA/C,WAAiBA,8BAA8B;EAChCA,8BAAA,CAAAnG,kBAAkB,GAAG,UAACC,GAAmC;IAAU,OAAAC,QAAA,KAC3ED,GAAG;EADwE,CAE9E;EACWkG,8BAAA,CAAAtG,GAAG,GAAG,UAACM,CAAM;IAA0C,OAAAL,KAAK,CAACK,CAAC,EAAE,gCAAgC,CAAC;EAA1C,CAA0C;AAChH,CAAC,EALgBgG,8BAA8B,KAA9BA,8BAA8B;AAoE/C,OAAM,IAAWC,4BAA4B;AAA7C,WAAiBA,4BAA4B;EAC9BA,4BAAA,CAAApG,kBAAkB,GAAG,UAACC,GAAiC;IAAU,OAAAC,QAAA,KACzED,GAAG;EADsE,CAE5E;EACWmG,4BAAA,CAAAvG,GAAG,GAAG,UAACM,CAAM;IAAwC,OAAAL,KAAK,CAACK,CAAC,EAAE,8BAA8B,CAAC;EAAxC,CAAwC;AAC5G,CAAC,EALgBiG,4BAA4B,KAA5BA,4BAA4B;AAuE7C,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAArG,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;EACWoG,uBAAA,CAAAxG,GAAG,GAAG,UAACM,CAAM;IAAmC,OAAAL,KAAK,CAACK,CAAC,EAAE,yBAAyB,CAAC;EAAnC,CAAmC;AAClG,CAAC,EALgBkG,uBAAuB,KAAvBA,uBAAuB;AAsBxC,OAAM,IAAWC,kBAAkB;AAAnC,WAAiBA,kBAAkB;EACpBA,kBAAA,CAAAtG,kBAAkB,GAAG,UAACC,GAAuB;IAAU,OAAAC,QAAA,KAC/DD,GAAG;EAD4D,CAElE;EACWqG,kBAAA,CAAAzG,GAAG,GAAG,UAACM,CAAM;IAA8B,OAAAL,KAAK,CAACK,CAAC,EAAE,oBAAoB,CAAC;EAA9B,CAA8B;AACxF,CAAC,EALgBmG,kBAAkB,KAAlBA,kBAAkB;AAwBnC,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAAvG,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,KAC/ED,GAAG;EAD4E,CAElF;EACWsG,kCAAA,CAAA1G,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,oCAAoC,CAAC;EAA9C,CAA8C;AAClD,CAAC,EANgBoG,kCAAkC,KAAlCA,kCAAkC;AAYnD,OAAM,IAAWC,mCAAmC;AAApD,WAAiBA,mCAAmC;EACrCA,mCAAA,CAAAxG,kBAAkB,GAAG,UAACC,GAAwC;IAAU,OAAAC,QAAA,KAChFD,GAAG;EAD6E,CAEnF;EACWuG,mCAAA,CAAA3G,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,qCAAqC,CAAC;EAA/C,CAA+C;AACnD,CAAC,EANgBqG,mCAAmC,KAAnCA,mCAAmC;AAiBpD,OAAM,IAAWC,iCAAiC;AAAlD,WAAiBA,iCAAiC;EACnCA,iCAAA,CAAAzG,kBAAkB,GAAG,UAACC,GAAsC;IAAU,OAAAC,QAAA,KAC9ED,GAAG;EAD2E,CAEjF;EACWwG,iCAAA,CAAA5G,GAAG,GAAG,UAACM,CAAM;IAA6C,OAAAL,KAAK,CAACK,CAAC,EAAE,mCAAmC,CAAC;EAA7C,CAA6C;AACtH,CAAC,EALgBsG,iCAAiC,KAAjCA,iCAAiC;AAWlD,OAAM,IAAWC,kCAAkC;AAAnD,WAAiBA,kCAAkC;EACpCA,kCAAA,CAAA1G,kBAAkB,GAAG,UAACC,GAAuC;IAAU,OAAAC,QAAA,KAC/ED,GAAG;EAD4E,CAElF;EACWyG,kCAAA,CAAA7G,GAAG,GAAG,UAACM,CAAM;IACxB,OAAAL,KAAK,CAACK,CAAC,EAAE,oCAAoC,CAAC;EAA9C,CAA8C;AAClD,CAAC,EANgBuG,kCAAkC,KAAlCA,kCAAkC;AA4BnD,OAAM,IAAWC,GAAG;AAApB,WAAiBA,GAAG;EACLA,GAAA,CAAA3G,kBAAkB,GAAG,UAACC,GAAQ;IAAU,OAAAC,QAAA,KAChDD,GAAG;EAD6C,CAEnD;EACW0G,GAAA,CAAA9G,GAAG,GAAG,UAACM,CAAM;IAAe,OAAAL,KAAK,CAACK,CAAC,EAAE,KAAK,CAAC;EAAf,CAAe;AAC1D,CAAC,EALgBwG,GAAG,KAAHA,GAAG;AAoBpB,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAA5G,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,KACnED,GAAG;EADgE,CAEtE;EACW2G,sBAAA,CAAA/G,GAAG,GAAG,UAACM,CAAM;IAAkC,OAAAL,KAAK,CAACK,CAAC,EAAE,wBAAwB,CAAC;EAAlC,CAAkC;AAChG,CAAC,EALgByG,sBAAsB,KAAtBA,sBAAsB;AAWvC,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAA7G,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;EACW4G,uBAAA,CAAAhH,GAAG,GAAG,UAACM,CAAM;IAAmC,OAAAL,KAAK,CAACK,CAAC,EAAE,yBAAyB,CAAC;EAAnC,CAAmC;AAClG,CAAC,EALgB0G,uBAAuB,KAAvBA,uBAAuB;AAqBxC,OAAM,IAAWC,wBAAwB;AAAzC,WAAiBA,wBAAwB;EAC1BA,wBAAA,CAAA9G,kBAAkB,GAAG,UAACC,GAA6B;IAAU,OAAAC,QAAA,KACrED,GAAG;EADkE,CAExE;EACW6G,wBAAA,CAAAjH,GAAG,GAAG,UAACM,CAAM;IAAoC,OAAAL,KAAK,CAACK,CAAC,EAAE,0BAA0B,CAAC;EAApC,CAAoC;AACpG,CAAC,EALgB2G,wBAAwB,KAAxBA,wBAAwB;AAWzC,OAAM,IAAWC,yBAAyB;AAA1C,WAAiBA,yBAAyB;EAC3BA,yBAAA,CAAA/G,kBAAkB,GAAG,UAACC,GAA8B;IAAU,OAAAC,QAAA,KACtED,GAAG;EADmE,CAEzE;EACW8G,yBAAA,CAAAlH,GAAG,GAAG,UAACM,CAAM;IAAqC,OAAAL,KAAK,CAACK,CAAC,EAAE,2BAA2B,CAAC;EAArC,CAAqC;AACtG,CAAC,EALgB4G,yBAAyB,KAAzBA,yBAAyB;AA2D1C,OAAM,IAAWC,sBAAsB;AAAvC,WAAiBA,sBAAsB;EACxBA,sBAAA,CAAAhH,kBAAkB,GAAG,UAACC,GAA2B;IAAU,OAAAC,QAAA,CAAAA,QAAA,CAAAA,QAAA,KACnED,GAAG,GACFA,GAAG,CAACoD,6BAA6B,IAAI;MACvCA,6BAA6B,EAAEA,6BAA6B,CAACrD,kBAAkB,CAC7EC,GAAG,CAACoD,6BAA6B;KAEpC,CAAC,EACEpD,GAAG,CAACuF,yBAAyB,IAAI;MACnCA,yBAAyB,EAAEA,yBAAyB,CAACxF,kBAAkB,CAACC,GAAG,CAACuF,yBAAyB;KACtG,CAAC;EAToE,CAUtE;EACWwB,sBAAA,CAAAnH,GAAG,GAAG,UAACM,CAAM;IAAkC,OAAAL,KAAK,CAACK,CAAC,EAAE,wBAAwB,CAAC;EAAlC,CAAkC;AAChG,CAAC,EAbgB6G,sBAAsB,KAAtBA,sBAAsB;AAmBvC,OAAM,IAAWC,uBAAuB;AAAxC,WAAiBA,uBAAuB;EACzBA,uBAAA,CAAAjH,kBAAkB,GAAG,UAACC,GAA4B;IAAU,OAAAC,QAAA,KACpED,GAAG;EADiE,CAEvE;EACWgH,uBAAA,CAAApH,GAAG,GAAG,UAACM,CAAM;IAAmC,OAAAL,KAAK,CAACK,CAAC,EAAE,yBAAyB,CAAC;EAAnC,CAAmC;AAClG,CAAC,EALgB8G,uBAAuB,KAAvBA,uBAAuB;AA8FxC,OAAM,IAAWC,gBAAgB;AAAjC,WAAiBA,gBAAgB;EAClBA,gBAAA,CAAAlH,kBAAkB,GAAG,UAACC,GAAqB;IAAU,OAAAC,QAAA,KAC7DD,GAAG;EAD0D,CAEhE;EACWiH,gBAAA,CAAArH,GAAG,GAAG,UAACM,CAAM;IAA4B,OAAAL,KAAK,CAACK,CAAC,EAAE,kBAAkB,CAAC;EAA5B,CAA4B;AACpF,CAAC,EALgB+G,gBAAgB,KAAhBA,gBAAgB;AAkGjC,OAAM,IAAWC,2BAA2B;AAA5C,WAAiBA,2BAA2B;EAC7BA,2BAAA,CAAAnH,kBAAkB,GAAG,UAACC,GAAgC;IAAU,OAAAC,QAAA,KACxED,GAAG;EADqE,CAE3E;EACWkH,2BAAA,CAAAtH,GAAG,GAAG,UAACM,CAAM;IAAuC,OAAAL,KAAK,CAACK,CAAC,EAAE,6BAA6B,CAAC;EAAvC,CAAuC;AAC1G,CAAC,EALgBgH,2BAA2B,KAA3BA,2BAA2B"},"metadata":{},"sourceType":"module","externalDependencies":[]}